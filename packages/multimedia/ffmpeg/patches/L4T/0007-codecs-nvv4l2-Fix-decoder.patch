From 1cfe8230253195c5d4516ff236c1cd4e5ea4bd16 Mon Sep 17 00:00:00 2001
From: CTCaer <ctcaer@gmail.com>
Date: Fri, 5 Nov 2021 22:03:10 +0000
Subject: [PATCH 7/7] codecs: nvv4l2: Fix decoder

- Make Codec important (removed avoid probing)
- Set proper frame format as per context. Fixes NV12 support.
- Set pixel format as YUV420P if empty. (Can only happen if something manages to call the codec directly. Normal calls do not reach that because codec id/name gets reset.)
- Add proper timestamping of frames and correct its storage size. That's mandatory and fixes every single app that tries to use FFmpeg and fails to play content because it depends on the decoded frame for syncing.
- Return actual processed size instead of packet size. Fixes skipping on full buffer
- Properly inform FFmpeg and apps that use its API when a decode process fails.
- Report properly if decoder got a new decoded frame or not. Before it would always report got_frame.
- HACK: Add frame seeking detection and drain the whole stack in order to speed it up. Avoids syncing issues with some players
---
 libavcodec/nvv4l2_dec.c | 77 ++++++++++++++++++++++++++---------------
 libavcodec/nvv4l2_dec.h |  7 ++--
 2 files changed, 54 insertions(+), 30 deletions(-)

diff --git a/libavcodec/nvv4l2_dec.c b/libavcodec/nvv4l2_dec.c
index d5cb7246d7..4451799a53 100644
--- a/libavcodec/nvv4l2_dec.c
+++ b/libavcodec/nvv4l2_dec.c
@@ -1,5 +1,6 @@
 /*
- * Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.
+ * Copyright (c) 2020, NVIDIA CORPORATION
+ * Copyright (c) 2021, CTCaer
  *
  * Permission is hereby granted, free of charge, to any person obtaining a
  * copy of this software and associated documentation files (the "Software"),
@@ -915,6 +916,8 @@ static void *capture_thread(void *arg)
             if (ctx->out_pixfmt == V4L2_PIX_FMT_YUV420M) {
                 ctx->frame_linesize[2] = parm.width[2];
                 ctx->frame_size[2] = parm.psize[2];
+            } else if (ctx->out_pixfmt == V4L2_PIX_FMT_NV12M) {
+                ctx->frame_linesize[1] *= 2;
             }
 
             if (ret_val != 0) {
@@ -931,7 +934,8 @@ static void *capture_thread(void *arg)
                              parm.height[2], ctx->bufptr_2[buf_index]);
             }
             push(ctx->avctx, ctx->frame_pools, buf_index);
-            ctx->timestamp[buf_index] = v4l2_buf.timestamp.tv_usec;
+            ctx->timestamp[buf_index] = (v4l2_buf.timestamp.tv_sec * 1000000) +
+                                         v4l2_buf.timestamp.tv_usec;
 
             buf_index = (buf_index + 1) % MAX_BUFFERS;
             pthread_mutex_unlock(&ctx->queue_lock);
@@ -961,11 +965,10 @@ static void *capture_thread(void *arg)
 int nvv4l2dec_decoder_get_frame(AVCodecContext * avctx, context_t * ctx,
                                 nvFrame * frame)
 {
-
     int picture_index;
 
     if (ctx->frame_pools->capacity == 0)
-        return -1;
+        return AVERROR(EAGAIN);
 
     picture_index = ctx->frame_pools->front;
     pop(avctx, ctx->frame_pools);
@@ -1013,9 +1016,10 @@ int nvv4l2_decode_process(AVCodecContext * avctx, context_t * ctx,
             av_log(avctx, AV_LOG_ERROR,
                    "Error DQing buffer at output plane\n");
             ctx->in_error = 1;
-            return 0;
+            return -1;
         }
     }
+
     memcpy(buffer->planes[0].data, packet->payload, packet->payload_size);
     buffer->planes[0].bytesused = packet->payload_size;
 
@@ -1025,14 +1029,15 @@ int nvv4l2_decode_process(AVCodecContext * avctx, context_t * ctx,
     }
     queue_v4l2_buf_op.m.planes[0].bytesused = buffer->planes[0].bytesused;
     queue_v4l2_buf_op.flags |= V4L2_BUF_FLAG_TIMESTAMP_COPY;
-    queue_v4l2_buf_op.timestamp.tv_usec = packet->pts;
+    queue_v4l2_buf_op.timestamp.tv_sec = packet->pts / 1000000;
+    queue_v4l2_buf_op.timestamp.tv_usec = packet->pts % 1000000;
 
     ret = q_buffer(ctx, &queue_v4l2_buf_op, buffer,
                    ctx->op_buf_type, ctx->op_mem_type, ctx->op_num_planes);
     if (ret) {
         av_log(avctx, AV_LOG_ERROR, "Error Qing buffer at output plane\n");
         ctx->in_error = 1;
-        return 0;
+        return -1;
     }
     if (ctx->index < ctx->op_num_buffers) {
         ctx->index++;
@@ -1300,28 +1305,37 @@ static int nvv4l2dec_init_decoder(AVCodecContext * avctx)
     nvv4l2DecodeContext *nvv4l2_context = avctx->priv_data;
     nvCodingType nv_codec_type;
     nv_codec_type = map_avcodec_id(avctx->codec_id);
+
     if (nv_codec_type < 0) {
         av_log(avctx, AV_LOG_ERROR, "Unsupported codec ID\n");
-        ret = AVERROR_BUG;
-        return ret;
+        return AVERROR_BUG;
+    }
+
+    if (avctx->pix_fmt == AV_PIX_FMT_NONE)
+        avctx->pix_fmt = AV_PIX_FMT_YUV420P;
+    else if (avctx->pix_fmt != AV_PIX_FMT_YUV420P &&
+               avctx->pix_fmt != AV_PIX_FMT_NV12) {
+        av_log(avctx, AV_LOG_ERROR, "Unsupported pixel format\n");
+        return AVERROR_BUG;
     }
 
     nvv4l2_context->ctx =
         nvv4l2dec_create_decoder(avctx, nv_codec_type,
+                                 avctx->pix_fmt == AV_PIX_FMT_NV12 ?
+                                 V4L2_PIX_FMT_NV12M :
                                  V4L2_PIX_FMT_YUV420M);
 
     if (!nvv4l2_context->ctx) {
         av_log(avctx, AV_LOG_ERROR,
                "Failed to nvv4l2dec_create_decoder (code = %d).\n", ret);
-        ret = AVERROR_UNKNOWN;
-        return ret;
+        return AVERROR_UNKNOWN;
     }
+
     return ret;
 }
 
 static int nvv4l2dec_close(AVCodecContext * avctx)
 {
-
     nvv4l2DecodeContext *nvv4l2_context = avctx->priv_data;
     return nvv4l2dec_decoder_close(avctx, nvv4l2_context->ctx);
 }
@@ -1332,25 +1346,33 @@ static int nvv4l2dec_decode(AVCodecContext * avctx, void *data,
     nvv4l2DecodeContext *nvv4l2_context = avctx->priv_data;
     AVFrame *frame = (AVFrame *) data;
     nvFrame _nvframe = { 0 };
-    nvPacket packet;
     uint8_t *ptrs[3];
-    int res, linesize[3];
+    int linesize[3];
+    int processed_size = 0;
 
-    if (avpkt->size) {
+    if (avpkt && avpkt->size) {
+        nvPacket packet;
         packet.payload_size = avpkt->size;
         packet.payload = avpkt->data;
         packet.pts = avpkt->pts;
-        res = nvv4l2_decode_process(avctx, nvv4l2_context->ctx, &packet);
+        if (!nvv4l2_decode_process(avctx, nvv4l2_context->ctx, &packet))
+            processed_size = avpkt->size;
+    }
+ 
+    if (nvv4l2dec_decoder_get_frame(avctx, nvv4l2_context->ctx, &_nvframe) == AVERROR(EAGAIN))
+    {
+        *got_frame = 0;
+        return processed_size;
     }
-    res =
-        nvv4l2dec_decoder_get_frame(avctx, nvv4l2_context->ctx, &_nvframe);
 
-    if (res < 0)
-        return avpkt->size;
+    /* HACK: Detect seeking and drain the whole stack to avoid issues with bad players. */
+    if (abs(avpkt->pts - _nvframe.timestamp) > 5000000) {
+         while (nvv4l2dec_decoder_get_frame(avctx, nvv4l2_context->ctx, &_nvframe) != AVERROR(EAGAIN));
+         _nvframe.timestamp = avpkt->pts;
+    }
 
-    if (ff_get_buffer(avctx, frame, 0) < 0) {
+    if (ff_get_buffer(avctx, frame, 0) < 0)
         return AVERROR(ENOMEM);
-    }
 
     linesize[0] = _nvframe.linesize[0];
     linesize[1] = _nvframe.linesize[1];
@@ -1367,7 +1389,7 @@ static int nvv4l2dec_decode(AVCodecContext * avctx, void *data,
     frame->width = _nvframe.width;
     frame->height = _nvframe.height;
 
-    frame->format = AV_PIX_FMT_YUV420P;
+    frame->format = avctx->pix_fmt;
     frame->pts = _nvframe.timestamp;
     frame->pkt_dts = AV_NOPTS_VALUE;
 
@@ -1378,7 +1400,7 @@ static int nvv4l2dec_decode(AVCodecContext * avctx, void *data,
 
     *got_frame = 1;
 
-    return avpkt->size;
+    return processed_size;
 }
 
 #define nvv4l2dec_DEC_CLASS(NAME) \
@@ -1399,14 +1421,15 @@ static int nvv4l2dec_decode(AVCodecContext * avctx, void *data,
 		.close          = nvv4l2dec_close, \
 		.decode         = nvv4l2dec_decode, \
 		.priv_class     = &nvv4l2dec_##NAME##_dec_class, \
-		.capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AVOID_PROBING | AV_CODEC_CAP_HARDWARE, \
-		.pix_fmts	=(const enum AVPixelFormat[]){AV_PIX_FMT_YUV420P,AV_PIX_FMT_NV12,AV_PIX_FMT_NONE},\
+		.capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_HARDWARE, \
+		.pix_fmts	=(const enum AVPixelFormat[]){ AV_PIX_FMT_YUV420P, \
+                                                   AV_PIX_FMT_NV12, \
+                                                   AV_PIX_FMT_NONE},\
 		.bsfs           = BSFS, \
 		.wrapper_name   = "nvv4l2dec", \
 	};
 
 
-
 nvv4l2dec_DEC(h264, AV_CODEC_ID_H264, "h264_mp4toannexb");
 nvv4l2dec_DEC(hevc, AV_CODEC_ID_HEVC, "hevc_mp4toannexb");
 nvv4l2dec_DEC(mpeg2, AV_CODEC_ID_MPEG2VIDEO, NULL);
diff --git a/libavcodec/nvv4l2_dec.h b/libavcodec/nvv4l2_dec.h
index f18f5d6d12..1098c9568e 100644
--- a/libavcodec/nvv4l2_dec.h
+++ b/libavcodec/nvv4l2_dec.h
@@ -1,5 +1,6 @@
 /*
- * Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.
+ * Copyright (c) 2020, NVIDIA CORPORATION
+ * Copyright (c) 2021, CTCaer
  *
  * Permission is hereby granted, free of charge, to any person obtaining a
  * copy of this software and associated documentation files (the "Software"),
@@ -59,7 +60,7 @@ typedef struct _NVPACKET {
     unsigned long flags;
     unsigned long payload_size;
     unsigned char *payload;
-    unsigned long pts;
+    unsigned long long pts;
 } nvPacket;
 
 typedef struct _NVFRAME {
@@ -70,7 +71,7 @@ typedef struct _NVFRAME {
     nvPixFormat type;
     unsigned int width;
     unsigned int height;
-    time_t timestamp;
+    unsigned long long timestamp;
 } nvFrame;
 
 
-- 
2.25.1

