diff -Naur ffmpeg-4.4-N-Alpha1/configure ffmpeg-4.4-N-Alpha1-2/configure
--- ffmpeg-4.4-N-Alpha1/configure	2022-04-20 03:47:14.088506869 +0200
+++ ffmpeg-4.4-N-Alpha1-2/configure	2022-04-20 03:52:16.943386154 +0200
@@ -334,6 +334,7 @@
   --enable-cuda-nvcc       enable Nvidia CUDA compiler [no]
   --disable-cuda-llvm      disable CUDA compilation using clang [autodetect]
   --disable-cuvid          disable Nvidia CUVID support [autodetect]
+  --enable-nvv4l2          enable Nvidia Tegra NVV4L2 support [no]
   --disable-d3d11va        disable Microsoft Direct3D 11 video acceleration code [autodetect]
   --disable-dxva2          disable Microsoft DirectX 9 video acceleration code [autodetect]
   --disable-ffnvcodec      disable dynamically linked Nvidia code [autodetect]
@@ -1846,6 +1847,7 @@
     ffnvcodec
     nvdec
     nvenc
+    nvv4l2
     vaapi
     vdpau
     videotoolbox
@@ -3065,7 +3067,8 @@
 qsvvpp_select="qsv"
 vaapi_encode_deps="vaapi"
 v4l2_m2m_deps="linux_videodev2_h sem_timedwait"
-
+nvv4l2_deps="pthreads"
+nvv4l2_extralibs="-lnvbuf_utils -lv4l2"
 hwupload_cuda_filter_deps="ffnvcodec"
 scale_npp_filter_deps="ffnvcodec libnpp"
 scale_cuda_filter_deps="ffnvcodec"
@@ -3080,6 +3083,9 @@
 nvenc_deps="ffnvcodec"
 nvenc_deps_any="libdl LoadLibrary"
 nvenc_encoder_deps="nvenc"
+h264_nvv4l2_encoder_deps="nvv4l2"
+h264_nvv4l2_decoder_deps="nvv4l2"
+h264_nvv4l2_decoder_select="h264_mp4toannexb_bsf"
 
 aac_mf_encoder_deps="mediafoundation"
 ac3_mf_encoder_deps="mediafoundation"
@@ -3112,6 +3118,9 @@
 hevc_mediacodec_decoder_select="hevc_mp4toannexb_bsf hevc_parser"
 hevc_mf_encoder_deps="mediafoundation"
 hevc_nvenc_encoder_deps="nvenc"
+hevc_nvv4l2_encoder_deps="nvv4l2"
+hevc_nvv4l2_decoder_deps="nvv4l2"
+hevc_nvv4l2_decoder_select="hevc_mp4toannexb_bsf"
 hevc_nvenc_encoder_select="atsc_a53"
 hevc_qsv_decoder_select="hevc_mp4toannexb_bsf qsvdec"
 hevc_qsv_encoder_select="hevcparse qsvenc"
@@ -3135,6 +3144,7 @@
 mpeg2_cuvid_decoder_deps="cuvid"
 mpeg2_mmal_decoder_deps="mmal"
 mpeg2_mediacodec_decoder_deps="mediacodec"
+mpeg2_nvv4l2_decoder_deps="nvv4l2"
 mpeg2_qsv_decoder_select="qsvdec"
 mpeg2_qsv_encoder_select="qsvenc"
 mpeg2_vaapi_encoder_select="cbs_mpeg2 vaapi_encode"
@@ -3143,6 +3153,7 @@
 mpeg4_cuvid_decoder_deps="cuvid"
 mpeg4_mediacodec_decoder_deps="mediacodec"
 mpeg4_mmal_decoder_deps="mmal"
+mpeg4_nvv4l2_decoder_deps="nvv4l2"
 mpeg4_omx_encoder_deps="omx"
 mpeg4_v4l2m2m_decoder_deps="v4l2_m2m mpeg4_v4l2_m2m"
 mpeg4_v4l2m2m_encoder_deps="v4l2_m2m mpeg4_v4l2_m2m"
@@ -3156,6 +3167,7 @@
 vc1_v4l2m2m_decoder_deps="v4l2_m2m vc1_v4l2_m2m"
 vp8_cuvid_decoder_deps="cuvid"
 vp8_mediacodec_decoder_deps="mediacodec"
+vp8_nvv4l2_decoder_deps="nvv4l2"
 vp8_qsv_decoder_select="qsvdec"
 vp8_rkmpp_decoder_deps="rkmpp"
 vp8_vaapi_encoder_deps="VAEncPictureParameterBufferVP8"
@@ -3164,6 +3176,7 @@
 vp8_v4l2m2m_encoder_deps="v4l2_m2m vp8_v4l2_m2m"
 vp9_cuvid_decoder_deps="cuvid"
 vp9_mediacodec_decoder_deps="mediacodec"
+vp9_nvv4l2_decoder_deps="nvv4l2"
 vp9_qsv_decoder_select="qsvdec"
 vp9_rkmpp_decoder_deps="rkmpp"
 vp9_vaapi_encoder_deps="VAEncPictureParameterBufferVP9"
@@ -3440,6 +3453,7 @@
 lavfi_indev_deps="avfilter"
 libcdio_indev_deps="libcdio"
 libdc1394_indev_deps="libdc1394"
+nvv4l2_indev_deps="v4l2"
 openal_indev_deps="openal"
 opengl_outdev_deps="opengl"
 opengl_outdev_suggest="sdl2"
@@ -6810,6 +6824,8 @@
     check_type "ffnvcodec/dynlink_cuda.h ffnvcodec/dynlink_cuviddec.h" "CUVIDAV1PICPARAMS"
 fi
 
+enabled nvv4l2 && add_ldflags "-L/usr/lib/aarch64-linux-gnu/tegra"
+
 enabled amf &&
     check_cpp_condition amf "AMF/core/Version.h" \
         "(AMF_VERSION_MAJOR << 48 | AMF_VERSION_MINOR << 32 | AMF_VERSION_RELEASE << 16 | AMF_VERSION_BUILD_NUM) >= 0x0001000400090000"
diff -Naur ffmpeg-4.4-N-Alpha1/fftools/ffmpeg_opt.c ffmpeg-4.4-N-Alpha1-2/fftools/ffmpeg_opt.c
--- ffmpeg-4.4-N-Alpha1/fftools/ffmpeg_opt.c	2022-04-20 03:47:13.896503418 +0200
+++ ffmpeg-4.4-N-Alpha1-2/fftools/ffmpeg_opt.c	2022-04-20 03:49:31.086968147 +0200
@@ -771,6 +771,25 @@
     char *codec_name = NULL;
 
     MATCH_PER_STREAM_OPT(codec_names, str, codec_name, s, st);
+
+#if CONFIG_NVV4L2
+    /* Reset requested decoder in order to enforce NVV4L2 if possible. */
+    if (codec_name) {
+        if (strcmp(codec_name, "h264") == 0)
+            return avcodec_find_decoder(st->codecpar->codec_id);   
+        else if (strcmp(codec_name, "hevc") == 0)
+            return avcodec_find_decoder(st->codecpar->codec_id); 
+        else if (strcmp(codec_name, "mpeg2video") == 0)
+            return avcodec_find_decoder(st->codecpar->codec_id);
+        else if (strcmp(codec_name, "mpeg4") == 0)
+            return avcodec_find_decoder(st->codecpar->codec_id);
+        else if (strcmp(codec_name, "vp8") == 0)
+            return avcodec_find_decoder(st->codecpar->codec_id);
+        else if (strcmp(codec_name, "vp9") == 0 && st->codecpar->format != AV_PIX_FMT_YUV420P10)
+            return avcodec_find_decoder(st->codecpar->codec_id);
+    }
+#endif
+
     if (codec_name) {
         const AVCodec *codec = find_codec_or_die(codec_name, st->codecpar->codec_type, 0);
         st->codecpar->codec_id = codec->id;
diff -Naur ffmpeg-4.4-N-Alpha1/fftools/ffmpeg_opt.c.orig ffmpeg-4.4-N-Alpha1-2/fftools/ffmpeg_opt.c.orig
--- ffmpeg-4.4-N-Alpha1/fftools/ffmpeg_opt.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ ffmpeg-4.4-N-Alpha1-2/fftools/ffmpeg_opt.c.orig	2022-04-20 03:48:51.822262975 +0200
@@ -0,0 +1,3827 @@
+
+/*
+ * ffmpeg option parsing
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stdint.h>
+
+#include "ffmpeg.h"
+#include "cmdutils.h"
+
+#include "libavformat/avformat.h"
+
+#include "libavcodec/avcodec.h"
+
+#include "libavfilter/avfilter.h"
+
+#include "libavutil/avassert.h"
+#include "libavutil/avstring.h"
+#include "libavutil/avutil.h"
+#include "libavutil/channel_layout.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/fifo.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/opt.h"
+#include "libavutil/parseutils.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+
+#define DEFAULT_PASS_LOGFILENAME_PREFIX "ffmpeg2pass"
+
+#define SPECIFIER_OPT_FMT_str  "%s"
+#define SPECIFIER_OPT_FMT_i    "%i"
+#define SPECIFIER_OPT_FMT_i64  "%"PRId64
+#define SPECIFIER_OPT_FMT_ui64 "%"PRIu64
+#define SPECIFIER_OPT_FMT_f    "%f"
+#define SPECIFIER_OPT_FMT_dbl  "%lf"
+
+static const char *const opt_name_codec_names[]               = {"c", "codec", "acodec", "vcodec", "scodec", "dcodec", NULL};
+static const char *const opt_name_audio_channels[]            = {"ac", NULL};
+static const char *const opt_name_audio_sample_rate[]         = {"ar", NULL};
+static const char *const opt_name_frame_rates[]               = {"r", NULL};
+static const char *const opt_name_max_frame_rates[]           = {"fpsmax", NULL};
+static const char *const opt_name_frame_sizes[]               = {"s", NULL};
+static const char *const opt_name_frame_pix_fmts[]            = {"pix_fmt", NULL};
+static const char *const opt_name_ts_scale[]                  = {"itsscale", NULL};
+static const char *const opt_name_hwaccels[]                  = {"hwaccel", NULL};
+static const char *const opt_name_hwaccel_devices[]           = {"hwaccel_device", NULL};
+static const char *const opt_name_hwaccel_output_formats[]    = {"hwaccel_output_format", NULL};
+static const char *const opt_name_autorotate[]                = {"autorotate", NULL};
+static const char *const opt_name_autoscale[]                 = {"autoscale", NULL};
+static const char *const opt_name_max_frames[]                = {"frames", "aframes", "vframes", "dframes", NULL};
+static const char *const opt_name_bitstream_filters[]         = {"bsf", "absf", "vbsf", NULL};
+static const char *const opt_name_codec_tags[]                = {"tag", "atag", "vtag", "stag", NULL};
+static const char *const opt_name_sample_fmts[]               = {"sample_fmt", NULL};
+static const char *const opt_name_qscale[]                    = {"q", "qscale", NULL};
+static const char *const opt_name_forced_key_frames[]         = {"forced_key_frames", NULL};
+static const char *const opt_name_force_fps[]                 = {"force_fps", NULL};
+static const char *const opt_name_frame_aspect_ratios[]       = {"aspect", NULL};
+static const char *const opt_name_rc_overrides[]              = {"rc_override", NULL};
+static const char *const opt_name_intra_matrices[]            = {"intra_matrix", NULL};
+static const char *const opt_name_inter_matrices[]            = {"inter_matrix", NULL};
+static const char *const opt_name_chroma_intra_matrices[]     = {"chroma_intra_matrix", NULL};
+static const char *const opt_name_top_field_first[]           = {"top", NULL};
+static const char *const opt_name_presets[]                   = {"pre", "apre", "vpre", "spre", NULL};
+static const char *const opt_name_copy_initial_nonkeyframes[] = {"copyinkfr", NULL};
+static const char *const opt_name_copy_prior_start[]          = {"copypriorss", NULL};
+static const char *const opt_name_filters[]                   = {"filter", "af", "vf", NULL};
+static const char *const opt_name_filter_scripts[]            = {"filter_script", NULL};
+static const char *const opt_name_reinit_filters[]            = {"reinit_filter", NULL};
+static const char *const opt_name_fix_sub_duration[]          = {"fix_sub_duration", NULL};
+static const char *const opt_name_canvas_sizes[]              = {"canvas_size", NULL};
+static const char *const opt_name_pass[]                      = {"pass", NULL};
+static const char *const opt_name_passlogfiles[]              = {"passlogfile", NULL};
+static const char *const opt_name_max_muxing_queue_size[]     = {"max_muxing_queue_size", NULL};
+static const char *const opt_name_muxing_queue_data_threshold[] = {"muxing_queue_data_threshold", NULL};
+static const char *const opt_name_guess_layout_max[]          = {"guess_layout_max", NULL};
+static const char *const opt_name_apad[]                      = {"apad", NULL};
+static const char *const opt_name_discard[]                   = {"discard", NULL};
+static const char *const opt_name_disposition[]               = {"disposition", NULL};
+static const char *const opt_name_time_bases[]                = {"time_base", NULL};
+static const char *const opt_name_enc_time_bases[]            = {"enc_time_base", NULL};
+
+#define WARN_MULTIPLE_OPT_USAGE(name, type, so, st)\
+{\
+    char namestr[128] = "";\
+    const char *spec = so->specifier && so->specifier[0] ? so->specifier : "";\
+    for (i = 0; opt_name_##name[i]; i++)\
+        av_strlcatf(namestr, sizeof(namestr), "-%s%s", opt_name_##name[i], opt_name_##name[i+1] ? (opt_name_##name[i+2] ? ", " : " or ") : "");\
+    av_log(NULL, AV_LOG_WARNING, "Multiple %s options specified for stream %d, only the last option '-%s%s%s "SPECIFIER_OPT_FMT_##type"' will be used.\n",\
+           namestr, st->index, opt_name_##name[0], spec[0] ? ":" : "", spec, so->u.type);\
+}
+
+#define MATCH_PER_STREAM_OPT(name, type, outvar, fmtctx, st)\
+{\
+    int i, ret, matches = 0;\
+    SpecifierOpt *so;\
+    for (i = 0; i < o->nb_ ## name; i++) {\
+        char *spec = o->name[i].specifier;\
+        if ((ret = check_stream_specifier(fmtctx, st, spec)) > 0) {\
+            outvar = o->name[i].u.type;\
+            so = &o->name[i];\
+            matches++;\
+        } else if (ret < 0)\
+            exit_program(1);\
+    }\
+    if (matches > 1)\
+       WARN_MULTIPLE_OPT_USAGE(name, type, so, st);\
+}
+
+#define MATCH_PER_TYPE_OPT(name, type, outvar, fmtctx, mediatype)\
+{\
+    int i;\
+    for (i = 0; i < o->nb_ ## name; i++) {\
+        char *spec = o->name[i].specifier;\
+        if (!strcmp(spec, mediatype))\
+            outvar = o->name[i].u.type;\
+    }\
+}
+
+const HWAccel hwaccels[] = {
+#if CONFIG_VIDEOTOOLBOX
+    { "videotoolbox", videotoolbox_init, HWACCEL_VIDEOTOOLBOX, AV_PIX_FMT_VIDEOTOOLBOX },
+#endif
+#if CONFIG_LIBMFX
+    { "qsv",   qsv_init,   HWACCEL_QSV,   AV_PIX_FMT_QSV },
+#endif
+    { 0 },
+};
+HWDevice *filter_hw_device;
+
+char *vstats_filename;
+char *sdp_filename;
+
+float audio_drift_threshold = 0.1;
+float dts_delta_threshold   = 10;
+float dts_error_threshold   = 3600*30;
+
+int audio_volume      = 256;
+int audio_sync_method = 0;
+int video_sync_method = VSYNC_AUTO;
+float frame_drop_threshold = 0;
+int do_deinterlace    = 0;
+int do_benchmark      = 0;
+int do_benchmark_all  = 0;
+int do_hex_dump       = 0;
+int do_pkt_dump       = 0;
+int copy_ts           = 0;
+int start_at_zero     = 0;
+int copy_tb           = -1;
+int debug_ts          = 0;
+int exit_on_error     = 0;
+int abort_on_flags    = 0;
+int print_stats       = -1;
+int qp_hist           = 0;
+int stdin_interaction = 1;
+int frame_bits_per_raw_sample = 0;
+float max_error_rate  = 2.0/3;
+int filter_nbthreads = 0;
+int filter_complex_nbthreads = 0;
+int vstats_version = 2;
+int auto_conversion_filters = 1;
+int64_t stats_period = 500000;
+
+
+static int intra_only         = 0;
+static int file_overwrite     = 0;
+static int no_file_overwrite  = 0;
+static int do_psnr            = 0;
+static int input_sync;
+static int input_stream_potentially_available = 0;
+static int ignore_unknown_streams = 0;
+static int copy_unknown_streams = 0;
+static int find_stream_info = 1;
+
+static void uninit_options(OptionsContext *o)
+{
+    const OptionDef *po = options;
+    int i;
+
+    /* all OPT_SPEC and OPT_STRING can be freed in generic way */
+    while (po->name) {
+        void *dst = (uint8_t*)o + po->u.off;
+
+        if (po->flags & OPT_SPEC) {
+            SpecifierOpt **so = dst;
+            int i, *count = (int*)(so + 1);
+            for (i = 0; i < *count; i++) {
+                av_freep(&(*so)[i].specifier);
+                if (po->flags & OPT_STRING)
+                    av_freep(&(*so)[i].u.str);
+            }
+            av_freep(so);
+            *count = 0;
+        } else if (po->flags & OPT_OFFSET && po->flags & OPT_STRING)
+            av_freep(dst);
+        po++;
+    }
+
+    for (i = 0; i < o->nb_stream_maps; i++)
+        av_freep(&o->stream_maps[i].linklabel);
+    av_freep(&o->stream_maps);
+    av_freep(&o->audio_channel_maps);
+    av_freep(&o->streamid_map);
+    av_freep(&o->attachments);
+}
+
+static void init_options(OptionsContext *o)
+{
+    memset(o, 0, sizeof(*o));
+
+    o->stop_time = INT64_MAX;
+    o->mux_max_delay  = 0.7;
+    o->start_time     = AV_NOPTS_VALUE;
+    o->start_time_eof = AV_NOPTS_VALUE;
+    o->recording_time = INT64_MAX;
+    o->limit_filesize = UINT64_MAX;
+    o->chapters_input_file = INT_MAX;
+    o->accurate_seek  = 1;
+    o->thread_queue_size = -1;
+}
+
+static int show_hwaccels(void *optctx, const char *opt, const char *arg)
+{
+    enum AVHWDeviceType type = AV_HWDEVICE_TYPE_NONE;
+
+    printf("Hardware acceleration methods:\n");
+    while ((type = av_hwdevice_iterate_types(type)) !=
+           AV_HWDEVICE_TYPE_NONE)
+        printf("%s\n", av_hwdevice_get_type_name(type));
+    printf("\n");
+    return 0;
+}
+
+/* return a copy of the input with the stream specifiers removed from the keys */
+static AVDictionary *strip_specifiers(AVDictionary *dict)
+{
+    AVDictionaryEntry *e = NULL;
+    AVDictionary    *ret = NULL;
+
+    while ((e = av_dict_get(dict, "", e, AV_DICT_IGNORE_SUFFIX))) {
+        char *p = strchr(e->key, ':');
+
+        if (p)
+            *p = 0;
+        av_dict_set(&ret, e->key, e->value, 0);
+        if (p)
+            *p = ':';
+    }
+    return ret;
+}
+
+static int opt_abort_on(void *optctx, const char *opt, const char *arg)
+{
+    static const AVOption opts[] = {
+        { "abort_on"           , NULL, 0, AV_OPT_TYPE_FLAGS, { .i64 = 0 }, INT64_MIN, INT64_MAX,           .unit = "flags" },
+        { "empty_output"       , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = ABORT_ON_FLAG_EMPTY_OUTPUT        }, .unit = "flags" },
+        { "empty_output_stream", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = ABORT_ON_FLAG_EMPTY_OUTPUT_STREAM }, .unit = "flags" },
+        { NULL },
+    };
+    static const AVClass class = {
+        .class_name = "",
+        .item_name  = av_default_item_name,
+        .option     = opts,
+        .version    = LIBAVUTIL_VERSION_INT,
+    };
+    const AVClass *pclass = &class;
+
+    return av_opt_eval_flags(&pclass, &opts[0], arg, &abort_on_flags);
+}
+
+static int opt_stats_period(void *optctx, const char *opt, const char *arg)
+{
+    int64_t user_stats_period = parse_time_or_die(opt, arg, 1);
+
+    if (user_stats_period <= 0) {
+        av_log(NULL, AV_LOG_ERROR, "stats_period %s must be positive.\n", arg);
+        return AVERROR(EINVAL);
+    }
+
+    stats_period = user_stats_period;
+    av_log(NULL, AV_LOG_INFO, "ffmpeg stats and -progress period set to %s.\n", arg);
+
+    return 0;
+}
+
+static int opt_sameq(void *optctx, const char *opt, const char *arg)
+{
+    av_log(NULL, AV_LOG_ERROR, "Option '%s' was removed. "
+           "If you are looking for an option to preserve the quality (which is not "
+           "what -%s was for), use -qscale 0 or an equivalent quality factor option.\n",
+           opt, opt);
+    return AVERROR(EINVAL);
+}
+
+static int opt_video_channel(void *optctx, const char *opt, const char *arg)
+{
+    av_log(NULL, AV_LOG_WARNING, "This option is deprecated, use -channel.\n");
+    return opt_default(optctx, "channel", arg);
+}
+
+static int opt_video_standard(void *optctx, const char *opt, const char *arg)
+{
+    av_log(NULL, AV_LOG_WARNING, "This option is deprecated, use -standard.\n");
+    return opt_default(optctx, "standard", arg);
+}
+
+static int opt_audio_codec(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "codec:a", arg, options);
+}
+
+static int opt_video_codec(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "codec:v", arg, options);
+}
+
+static int opt_subtitle_codec(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "codec:s", arg, options);
+}
+
+static int opt_data_codec(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "codec:d", arg, options);
+}
+
+static int opt_map(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    StreamMap *m = NULL;
+    int i, negative = 0, file_idx, disabled = 0;
+    int sync_file_idx = -1, sync_stream_idx = 0;
+    char *p, *sync;
+    char *map;
+    char *allow_unused;
+
+    if (*arg == '-') {
+        negative = 1;
+        arg++;
+    }
+    map = av_strdup(arg);
+    if (!map)
+        return AVERROR(ENOMEM);
+
+    /* parse sync stream first, just pick first matching stream */
+    if (sync = strchr(map, ',')) {
+        *sync = 0;
+        sync_file_idx = strtol(sync + 1, &sync, 0);
+        if (sync_file_idx >= nb_input_files || sync_file_idx < 0) {
+            av_log(NULL, AV_LOG_FATAL, "Invalid sync file index: %d.\n", sync_file_idx);
+            exit_program(1);
+        }
+        if (*sync)
+            sync++;
+        for (i = 0; i < input_files[sync_file_idx]->nb_streams; i++)
+            if (check_stream_specifier(input_files[sync_file_idx]->ctx,
+                                       input_files[sync_file_idx]->ctx->streams[i], sync) == 1) {
+                sync_stream_idx = i;
+                break;
+            }
+        if (i == input_files[sync_file_idx]->nb_streams) {
+            av_log(NULL, AV_LOG_FATAL, "Sync stream specification in map %s does not "
+                                       "match any streams.\n", arg);
+            exit_program(1);
+        }
+        if (input_streams[input_files[sync_file_idx]->ist_index + sync_stream_idx]->user_set_discard == AVDISCARD_ALL) {
+            av_log(NULL, AV_LOG_FATAL, "Sync stream specification in map %s matches a disabled input "
+                                       "stream.\n", arg);
+            exit_program(1);
+        }
+    }
+
+
+    if (map[0] == '[') {
+        /* this mapping refers to lavfi output */
+        const char *c = map + 1;
+        GROW_ARRAY(o->stream_maps, o->nb_stream_maps);
+        m = &o->stream_maps[o->nb_stream_maps - 1];
+        m->linklabel = av_get_token(&c, "]");
+        if (!m->linklabel) {
+            av_log(NULL, AV_LOG_ERROR, "Invalid output link label: %s.\n", map);
+            exit_program(1);
+        }
+    } else {
+        if (allow_unused = strchr(map, '?'))
+            *allow_unused = 0;
+        file_idx = strtol(map, &p, 0);
+        if (file_idx >= nb_input_files || file_idx < 0) {
+            av_log(NULL, AV_LOG_FATAL, "Invalid input file index: %d.\n", file_idx);
+            exit_program(1);
+        }
+        if (negative)
+            /* disable some already defined maps */
+            for (i = 0; i < o->nb_stream_maps; i++) {
+                m = &o->stream_maps[i];
+                if (file_idx == m->file_index &&
+                    check_stream_specifier(input_files[m->file_index]->ctx,
+                                           input_files[m->file_index]->ctx->streams[m->stream_index],
+                                           *p == ':' ? p + 1 : p) > 0)
+                    m->disabled = 1;
+            }
+        else
+            for (i = 0; i < input_files[file_idx]->nb_streams; i++) {
+                if (check_stream_specifier(input_files[file_idx]->ctx, input_files[file_idx]->ctx->streams[i],
+                            *p == ':' ? p + 1 : p) <= 0)
+                    continue;
+                if (input_streams[input_files[file_idx]->ist_index + i]->user_set_discard == AVDISCARD_ALL) {
+                    disabled = 1;
+                    continue;
+                }
+                GROW_ARRAY(o->stream_maps, o->nb_stream_maps);
+                m = &o->stream_maps[o->nb_stream_maps - 1];
+
+                m->file_index   = file_idx;
+                m->stream_index = i;
+
+                if (sync_file_idx >= 0) {
+                    m->sync_file_index   = sync_file_idx;
+                    m->sync_stream_index = sync_stream_idx;
+                } else {
+                    m->sync_file_index   = file_idx;
+                    m->sync_stream_index = i;
+                }
+            }
+    }
+
+    if (!m) {
+        if (allow_unused) {
+            av_log(NULL, AV_LOG_VERBOSE, "Stream map '%s' matches no streams; ignoring.\n", arg);
+        } else if (disabled) {
+            av_log(NULL, AV_LOG_FATAL, "Stream map '%s' matches disabled streams.\n"
+                                       "To ignore this, add a trailing '?' to the map.\n", arg);
+            exit_program(1);
+        } else {
+            av_log(NULL, AV_LOG_FATAL, "Stream map '%s' matches no streams.\n"
+                                       "To ignore this, add a trailing '?' to the map.\n", arg);
+            exit_program(1);
+        }
+    }
+
+    av_freep(&map);
+    return 0;
+}
+
+static int opt_attach(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    GROW_ARRAY(o->attachments, o->nb_attachments);
+    o->attachments[o->nb_attachments - 1] = arg;
+    return 0;
+}
+
+static int opt_map_channel(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    int n;
+    AVStream *st;
+    AudioChannelMap *m;
+    char *allow_unused;
+    char *mapchan;
+    mapchan = av_strdup(arg);
+    if (!mapchan)
+        return AVERROR(ENOMEM);
+
+    GROW_ARRAY(o->audio_channel_maps, o->nb_audio_channel_maps);
+    m = &o->audio_channel_maps[o->nb_audio_channel_maps - 1];
+
+    /* muted channel syntax */
+    n = sscanf(arg, "%d:%d.%d", &m->channel_idx, &m->ofile_idx, &m->ostream_idx);
+    if ((n == 1 || n == 3) && m->channel_idx == -1) {
+        m->file_idx = m->stream_idx = -1;
+        if (n == 1)
+            m->ofile_idx = m->ostream_idx = -1;
+        av_free(mapchan);
+        return 0;
+    }
+
+    /* normal syntax */
+    n = sscanf(arg, "%d.%d.%d:%d.%d",
+               &m->file_idx,  &m->stream_idx, &m->channel_idx,
+               &m->ofile_idx, &m->ostream_idx);
+
+    if (n != 3 && n != 5) {
+        av_log(NULL, AV_LOG_FATAL, "Syntax error, mapchan usage: "
+               "[file.stream.channel|-1][:syncfile:syncstream]\n");
+        exit_program(1);
+    }
+
+    if (n != 5) // only file.stream.channel specified
+        m->ofile_idx = m->ostream_idx = -1;
+
+    /* check input */
+    if (m->file_idx < 0 || m->file_idx >= nb_input_files) {
+        av_log(NULL, AV_LOG_FATAL, "mapchan: invalid input file index: %d\n",
+               m->file_idx);
+        exit_program(1);
+    }
+    if (m->stream_idx < 0 ||
+        m->stream_idx >= input_files[m->file_idx]->nb_streams) {
+        av_log(NULL, AV_LOG_FATAL, "mapchan: invalid input file stream index #%d.%d\n",
+               m->file_idx, m->stream_idx);
+        exit_program(1);
+    }
+    st = input_files[m->file_idx]->ctx->streams[m->stream_idx];
+    if (st->codecpar->codec_type != AVMEDIA_TYPE_AUDIO) {
+        av_log(NULL, AV_LOG_FATAL, "mapchan: stream #%d.%d is not an audio stream.\n",
+               m->file_idx, m->stream_idx);
+        exit_program(1);
+    }
+    /* allow trailing ? to map_channel */
+    if (allow_unused = strchr(mapchan, '?'))
+        *allow_unused = 0;
+    if (m->channel_idx < 0 || m->channel_idx >= st->codecpar->channels ||
+        input_streams[input_files[m->file_idx]->ist_index + m->stream_idx]->user_set_discard == AVDISCARD_ALL) {
+        if (allow_unused) {
+            av_log(NULL, AV_LOG_VERBOSE, "mapchan: invalid audio channel #%d.%d.%d\n",
+                    m->file_idx, m->stream_idx, m->channel_idx);
+        } else {
+            av_log(NULL, AV_LOG_FATAL,  "mapchan: invalid audio channel #%d.%d.%d\n"
+                    "To ignore this, add a trailing '?' to the map_channel.\n",
+                    m->file_idx, m->stream_idx, m->channel_idx);
+            exit_program(1);
+        }
+
+    }
+    av_free(mapchan);
+    return 0;
+}
+
+static int opt_sdp_file(void *optctx, const char *opt, const char *arg)
+{
+    av_free(sdp_filename);
+    sdp_filename = av_strdup(arg);
+    return 0;
+}
+
+#if CONFIG_VAAPI
+static int opt_vaapi_device(void *optctx, const char *opt, const char *arg)
+{
+    const char *prefix = "vaapi:";
+    char *tmp;
+    int err;
+    tmp = av_asprintf("%s%s", prefix, arg);
+    if (!tmp)
+        return AVERROR(ENOMEM);
+    err = hw_device_init_from_string(tmp, NULL);
+    av_free(tmp);
+    return err;
+}
+#endif
+
+static int opt_init_hw_device(void *optctx, const char *opt, const char *arg)
+{
+    if (!strcmp(arg, "list")) {
+        enum AVHWDeviceType type = AV_HWDEVICE_TYPE_NONE;
+        printf("Supported hardware device types:\n");
+        while ((type = av_hwdevice_iterate_types(type)) !=
+               AV_HWDEVICE_TYPE_NONE)
+            printf("%s\n", av_hwdevice_get_type_name(type));
+        printf("\n");
+        exit_program(0);
+    } else {
+        return hw_device_init_from_string(arg, NULL);
+    }
+}
+
+static int opt_filter_hw_device(void *optctx, const char *opt, const char *arg)
+{
+    if (filter_hw_device) {
+        av_log(NULL, AV_LOG_ERROR, "Only one filter device can be used.\n");
+        return AVERROR(EINVAL);
+    }
+    filter_hw_device = hw_device_get_by_name(arg);
+    if (!filter_hw_device) {
+        av_log(NULL, AV_LOG_ERROR, "Invalid filter device %s.\n", arg);
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+/**
+ * Parse a metadata specifier passed as 'arg' parameter.
+ * @param arg  metadata string to parse
+ * @param type metadata type is written here -- g(lobal)/s(tream)/c(hapter)/p(rogram)
+ * @param index for type c/p, chapter/program index is written here
+ * @param stream_spec for type s, the stream specifier is written here
+ */
+static void parse_meta_type(char *arg, char *type, int *index, const char **stream_spec)
+{
+    if (*arg) {
+        *type = *arg;
+        switch (*arg) {
+        case 'g':
+            break;
+        case 's':
+            if (*(++arg) && *arg != ':') {
+                av_log(NULL, AV_LOG_FATAL, "Invalid metadata specifier %s.\n", arg);
+                exit_program(1);
+            }
+            *stream_spec = *arg == ':' ? arg + 1 : "";
+            break;
+        case 'c':
+        case 'p':
+            if (*(++arg) == ':')
+                *index = strtol(++arg, NULL, 0);
+            break;
+        default:
+            av_log(NULL, AV_LOG_FATAL, "Invalid metadata type %c.\n", *arg);
+            exit_program(1);
+        }
+    } else
+        *type = 'g';
+}
+
+static int copy_metadata(char *outspec, char *inspec, AVFormatContext *oc, AVFormatContext *ic, OptionsContext *o)
+{
+    AVDictionary **meta_in = NULL;
+    AVDictionary **meta_out = NULL;
+    int i, ret = 0;
+    char type_in, type_out;
+    const char *istream_spec = NULL, *ostream_spec = NULL;
+    int idx_in = 0, idx_out = 0;
+
+    parse_meta_type(inspec,  &type_in,  &idx_in,  &istream_spec);
+    parse_meta_type(outspec, &type_out, &idx_out, &ostream_spec);
+
+    if (!ic) {
+        if (type_out == 'g' || !*outspec)
+            o->metadata_global_manual = 1;
+        if (type_out == 's' || !*outspec)
+            o->metadata_streams_manual = 1;
+        if (type_out == 'c' || !*outspec)
+            o->metadata_chapters_manual = 1;
+        return 0;
+    }
+
+    if (type_in == 'g' || type_out == 'g')
+        o->metadata_global_manual = 1;
+    if (type_in == 's' || type_out == 's')
+        o->metadata_streams_manual = 1;
+    if (type_in == 'c' || type_out == 'c')
+        o->metadata_chapters_manual = 1;
+
+    /* ic is NULL when just disabling automatic mappings */
+    if (!ic)
+        return 0;
+
+#define METADATA_CHECK_INDEX(index, nb_elems, desc)\
+    if ((index) < 0 || (index) >= (nb_elems)) {\
+        av_log(NULL, AV_LOG_FATAL, "Invalid %s index %d while processing metadata maps.\n",\
+                (desc), (index));\
+        exit_program(1);\
+    }
+
+#define SET_DICT(type, meta, context, index)\
+        switch (type) {\
+        case 'g':\
+            meta = &context->metadata;\
+            break;\
+        case 'c':\
+            METADATA_CHECK_INDEX(index, context->nb_chapters, "chapter")\
+            meta = &context->chapters[index]->metadata;\
+            break;\
+        case 'p':\
+            METADATA_CHECK_INDEX(index, context->nb_programs, "program")\
+            meta = &context->programs[index]->metadata;\
+            break;\
+        case 's':\
+            break; /* handled separately below */ \
+        default: av_assert0(0);\
+        }\
+
+    SET_DICT(type_in, meta_in, ic, idx_in);
+    SET_DICT(type_out, meta_out, oc, idx_out);
+
+    /* for input streams choose first matching stream */
+    if (type_in == 's') {
+        for (i = 0; i < ic->nb_streams; i++) {
+            if ((ret = check_stream_specifier(ic, ic->streams[i], istream_spec)) > 0) {
+                meta_in = &ic->streams[i]->metadata;
+                break;
+            } else if (ret < 0)
+                exit_program(1);
+        }
+        if (!meta_in) {
+            av_log(NULL, AV_LOG_FATAL, "Stream specifier %s does not match  any streams.\n", istream_spec);
+            exit_program(1);
+        }
+    }
+
+    if (type_out == 's') {
+        for (i = 0; i < oc->nb_streams; i++) {
+            if ((ret = check_stream_specifier(oc, oc->streams[i], ostream_spec)) > 0) {
+                meta_out = &oc->streams[i]->metadata;
+                av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);
+            } else if (ret < 0)
+                exit_program(1);
+        }
+    } else
+        av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);
+
+    return 0;
+}
+
+static int opt_recording_timestamp(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    char buf[128];
+    int64_t recording_timestamp = parse_time_or_die(opt, arg, 0) / 1E6;
+    struct tm time = *gmtime((time_t*)&recording_timestamp);
+    if (!strftime(buf, sizeof(buf), "creation_time=%Y-%m-%dT%H:%M:%S%z", &time))
+        return -1;
+    parse_option(o, "metadata", buf, options);
+
+    av_log(NULL, AV_LOG_WARNING, "%s is deprecated, set the 'creation_time' metadata "
+                                 "tag instead.\n", opt);
+    return 0;
+}
+
+static AVCodec *find_codec_or_die(const char *name, enum AVMediaType type, int encoder)
+{
+    const AVCodecDescriptor *desc;
+    const char *codec_string = encoder ? "encoder" : "decoder";
+    AVCodec *codec;
+
+    codec = encoder ?
+        avcodec_find_encoder_by_name(name) :
+        avcodec_find_decoder_by_name(name);
+
+    if (!codec && (desc = avcodec_descriptor_get_by_name(name))) {
+        codec = encoder ? avcodec_find_encoder(desc->id) :
+                          avcodec_find_decoder(desc->id);
+        if (codec)
+            av_log(NULL, AV_LOG_VERBOSE, "Matched %s '%s' for codec '%s'.\n",
+                   codec_string, codec->name, desc->name);
+    }
+
+    if (!codec) {
+        av_log(NULL, AV_LOG_FATAL, "Unknown %s '%s'\n", codec_string, name);
+        exit_program(1);
+    }
+    if (codec->type != type) {
+        av_log(NULL, AV_LOG_FATAL, "Invalid %s type '%s'\n", codec_string, name);
+        exit_program(1);
+    }
+    return codec;
+}
+
+static const AVCodec *choose_decoder(OptionsContext *o, AVFormatContext *s, AVStream *st)
+{
+    char *codec_name = NULL;
+
+    MATCH_PER_STREAM_OPT(codec_names, str, codec_name, s, st);
+    if (codec_name) {
+        const AVCodec *codec = find_codec_or_die(codec_name, st->codecpar->codec_type, 0);
+        st->codecpar->codec_id = codec->id;
+        return codec;
+    } else
+        return avcodec_find_decoder(st->codecpar->codec_id);
+}
+
+/* Add all the streams from the given input file to the global
+ * list of input streams. */
+static void add_input_streams(OptionsContext *o, AVFormatContext *ic)
+{
+    int i, ret;
+
+    for (i = 0; i < ic->nb_streams; i++) {
+        AVStream *st = ic->streams[i];
+        AVCodecParameters *par = st->codecpar;
+        InputStream *ist = av_mallocz(sizeof(*ist));
+        char *framerate = NULL, *hwaccel_device = NULL;
+        const char *hwaccel = NULL;
+        char *hwaccel_output_format = NULL;
+        char *codec_tag = NULL;
+        char *next;
+        char *discard_str = NULL;
+        const AVClass *cc = avcodec_get_class();
+        const AVOption *discard_opt = av_opt_find(&cc, "skip_frame", NULL, 0, 0);
+
+        if (!ist)
+            exit_program(1);
+
+        GROW_ARRAY(input_streams, nb_input_streams);
+        input_streams[nb_input_streams - 1] = ist;
+
+        ist->st = st;
+        ist->file_index = nb_input_files;
+        ist->discard = 1;
+        st->discard  = AVDISCARD_ALL;
+        ist->nb_samples = 0;
+        ist->min_pts = INT64_MAX;
+        ist->max_pts = INT64_MIN;
+
+        ist->ts_scale = 1.0;
+        MATCH_PER_STREAM_OPT(ts_scale, dbl, ist->ts_scale, ic, st);
+
+        ist->autorotate = 1;
+        MATCH_PER_STREAM_OPT(autorotate, i, ist->autorotate, ic, st);
+
+        MATCH_PER_STREAM_OPT(codec_tags, str, codec_tag, ic, st);
+        if (codec_tag) {
+            uint32_t tag = strtol(codec_tag, &next, 0);
+            if (*next)
+                tag = AV_RL32(codec_tag);
+            st->codecpar->codec_tag = tag;
+        }
+
+        ist->dec = choose_decoder(o, ic, st);
+        ist->decoder_opts = filter_codec_opts(o->g->codec_opts, ist->st->codecpar->codec_id, ic, st, ist->dec);
+
+        ist->reinit_filters = -1;
+        MATCH_PER_STREAM_OPT(reinit_filters, i, ist->reinit_filters, ic, st);
+
+        MATCH_PER_STREAM_OPT(discard, str, discard_str, ic, st);
+        ist->user_set_discard = AVDISCARD_NONE;
+
+        if ((o->video_disable && ist->st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) ||
+            (o->audio_disable && ist->st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) ||
+            (o->subtitle_disable && ist->st->codecpar->codec_type == AVMEDIA_TYPE_SUBTITLE) ||
+            (o->data_disable && ist->st->codecpar->codec_type == AVMEDIA_TYPE_DATA))
+                ist->user_set_discard = AVDISCARD_ALL;
+
+        if (discard_str && av_opt_eval_int(&cc, discard_opt, discard_str, &ist->user_set_discard) < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error parsing discard %s.\n",
+                    discard_str);
+            exit_program(1);
+        }
+
+        ist->filter_in_rescale_delta_last = AV_NOPTS_VALUE;
+
+        ist->dec_ctx = avcodec_alloc_context3(ist->dec);
+        if (!ist->dec_ctx) {
+            av_log(NULL, AV_LOG_ERROR, "Error allocating the decoder context.\n");
+            exit_program(1);
+        }
+
+        ret = avcodec_parameters_to_context(ist->dec_ctx, par);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error initializing the decoder context.\n");
+            exit_program(1);
+        }
+
+        if (o->bitexact)
+            ist->dec_ctx->flags |= AV_CODEC_FLAG_BITEXACT;
+
+        switch (par->codec_type) {
+        case AVMEDIA_TYPE_VIDEO:
+            if(!ist->dec)
+                ist->dec = avcodec_find_decoder(par->codec_id);
+
+            // avformat_find_stream_info() doesn't set this for us anymore.
+            ist->dec_ctx->framerate = st->avg_frame_rate;
+
+            MATCH_PER_STREAM_OPT(frame_rates, str, framerate, ic, st);
+            if (framerate && av_parse_video_rate(&ist->framerate,
+                                                 framerate) < 0) {
+                av_log(NULL, AV_LOG_ERROR, "Error parsing framerate %s.\n",
+                       framerate);
+                exit_program(1);
+            }
+
+            ist->top_field_first = -1;
+            MATCH_PER_STREAM_OPT(top_field_first, i, ist->top_field_first, ic, st);
+
+            MATCH_PER_STREAM_OPT(hwaccels, str, hwaccel, ic, st);
+            MATCH_PER_STREAM_OPT(hwaccel_output_formats, str,
+                                 hwaccel_output_format, ic, st);
+
+            if (!hwaccel_output_format && hwaccel && !strcmp(hwaccel, "cuvid")) {
+                av_log(NULL, AV_LOG_WARNING,
+                    "WARNING: defaulting hwaccel_output_format to cuda for compatibility "
+                    "with old commandlines. This behaviour is DEPRECATED and will be removed "
+                    "in the future. Please explicitly set \"-hwaccel_output_format cuda\".\n");
+                ist->hwaccel_output_format = AV_PIX_FMT_CUDA;
+            } else if (hwaccel_output_format) {
+                ist->hwaccel_output_format = av_get_pix_fmt(hwaccel_output_format);
+                if (ist->hwaccel_output_format == AV_PIX_FMT_NONE) {
+                    av_log(NULL, AV_LOG_FATAL, "Unrecognised hwaccel output "
+                           "format: %s", hwaccel_output_format);
+                }
+            } else {
+                ist->hwaccel_output_format = AV_PIX_FMT_NONE;
+            }
+
+            if (hwaccel) {
+                // The NVDEC hwaccels use a CUDA device, so remap the name here.
+                if (!strcmp(hwaccel, "nvdec") || !strcmp(hwaccel, "cuvid"))
+                    hwaccel = "cuda";
+
+                if (!strcmp(hwaccel, "none"))
+                    ist->hwaccel_id = HWACCEL_NONE;
+                else if (!strcmp(hwaccel, "auto"))
+                    ist->hwaccel_id = HWACCEL_AUTO;
+                else {
+                    enum AVHWDeviceType type;
+                    int i;
+                    for (i = 0; hwaccels[i].name; i++) {
+                        if (!strcmp(hwaccels[i].name, hwaccel)) {
+                            ist->hwaccel_id = hwaccels[i].id;
+                            break;
+                        }
+                    }
+
+                    if (!ist->hwaccel_id) {
+                        type = av_hwdevice_find_type_by_name(hwaccel);
+                        if (type != AV_HWDEVICE_TYPE_NONE) {
+                            ist->hwaccel_id = HWACCEL_GENERIC;
+                            ist->hwaccel_device_type = type;
+                        }
+                    }
+
+                    if (!ist->hwaccel_id) {
+                        av_log(NULL, AV_LOG_FATAL, "Unrecognized hwaccel: %s.\n",
+                               hwaccel);
+                        av_log(NULL, AV_LOG_FATAL, "Supported hwaccels: ");
+                        type = AV_HWDEVICE_TYPE_NONE;
+                        while ((type = av_hwdevice_iterate_types(type)) !=
+                               AV_HWDEVICE_TYPE_NONE)
+                            av_log(NULL, AV_LOG_FATAL, "%s ",
+                                   av_hwdevice_get_type_name(type));
+                        av_log(NULL, AV_LOG_FATAL, "\n");
+                        exit_program(1);
+                    }
+                }
+            }
+
+            MATCH_PER_STREAM_OPT(hwaccel_devices, str, hwaccel_device, ic, st);
+            if (hwaccel_device) {
+                ist->hwaccel_device = av_strdup(hwaccel_device);
+                if (!ist->hwaccel_device)
+                    exit_program(1);
+            }
+
+            ist->hwaccel_pix_fmt = AV_PIX_FMT_NONE;
+
+            break;
+        case AVMEDIA_TYPE_AUDIO:
+            ist->guess_layout_max = INT_MAX;
+            MATCH_PER_STREAM_OPT(guess_layout_max, i, ist->guess_layout_max, ic, st);
+            guess_input_channel_layout(ist);
+            break;
+        case AVMEDIA_TYPE_DATA:
+        case AVMEDIA_TYPE_SUBTITLE: {
+            char *canvas_size = NULL;
+            if(!ist->dec)
+                ist->dec = avcodec_find_decoder(par->codec_id);
+            MATCH_PER_STREAM_OPT(fix_sub_duration, i, ist->fix_sub_duration, ic, st);
+            MATCH_PER_STREAM_OPT(canvas_sizes, str, canvas_size, ic, st);
+            if (canvas_size &&
+                av_parse_video_size(&ist->dec_ctx->width, &ist->dec_ctx->height, canvas_size) < 0) {
+                av_log(NULL, AV_LOG_FATAL, "Invalid canvas size: %s.\n", canvas_size);
+                exit_program(1);
+            }
+            break;
+        }
+        case AVMEDIA_TYPE_ATTACHMENT:
+        case AVMEDIA_TYPE_UNKNOWN:
+            break;
+        default:
+            abort();
+        }
+
+        ret = avcodec_parameters_from_context(par, ist->dec_ctx);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error initializing the decoder context.\n");
+            exit_program(1);
+        }
+    }
+}
+
+static void assert_file_overwrite(const char *filename)
+{
+    const char *proto_name = avio_find_protocol_name(filename);
+
+    if (file_overwrite && no_file_overwrite) {
+        fprintf(stderr, "Error, both -y and -n supplied. Exiting.\n");
+        exit_program(1);
+    }
+
+    if (!file_overwrite) {
+        if (proto_name && !strcmp(proto_name, "file") && avio_check(filename, 0) == 0) {
+            if (stdin_interaction && !no_file_overwrite) {
+                fprintf(stderr,"File '%s' already exists. Overwrite? [y/N] ", filename);
+                fflush(stderr);
+                term_exit();
+                signal(SIGINT, SIG_DFL);
+                if (!read_yesno()) {
+                    av_log(NULL, AV_LOG_FATAL, "Not overwriting - exiting\n");
+                    exit_program(1);
+                }
+                term_init();
+            }
+            else {
+                av_log(NULL, AV_LOG_FATAL, "File '%s' already exists. Exiting.\n", filename);
+                exit_program(1);
+            }
+        }
+    }
+
+    if (proto_name && !strcmp(proto_name, "file")) {
+        for (int i = 0; i < nb_input_files; i++) {
+             InputFile *file = input_files[i];
+             if (file->ctx->iformat->flags & AVFMT_NOFILE)
+                 continue;
+             if (!strcmp(filename, file->ctx->url)) {
+                 av_log(NULL, AV_LOG_FATAL, "Output %s same as Input #%d - exiting\n", filename, i);
+                 av_log(NULL, AV_LOG_WARNING, "FFmpeg cannot edit existing files in-place.\n");
+                 exit_program(1);
+             }
+        }
+    }
+}
+
+static void dump_attachment(AVStream *st, const char *filename)
+{
+    int ret;
+    AVIOContext *out = NULL;
+    AVDictionaryEntry *e;
+
+    if (!st->codecpar->extradata_size) {
+        av_log(NULL, AV_LOG_WARNING, "No extradata to dump in stream #%d:%d.\n",
+               nb_input_files - 1, st->index);
+        return;
+    }
+    if (!*filename && (e = av_dict_get(st->metadata, "filename", NULL, 0)))
+        filename = e->value;
+    if (!*filename) {
+        av_log(NULL, AV_LOG_FATAL, "No filename specified and no 'filename' tag"
+               "in stream #%d:%d.\n", nb_input_files - 1, st->index);
+        exit_program(1);
+    }
+
+    assert_file_overwrite(filename);
+
+    if ((ret = avio_open2(&out, filename, AVIO_FLAG_WRITE, &int_cb, NULL)) < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Could not open file %s for writing.\n",
+               filename);
+        exit_program(1);
+    }
+
+    avio_write(out, st->codecpar->extradata, st->codecpar->extradata_size);
+    avio_flush(out);
+    avio_close(out);
+}
+
+static int open_input_file(OptionsContext *o, const char *filename)
+{
+    InputFile *f;
+    AVFormatContext *ic;
+    AVInputFormat *file_iformat = NULL;
+    int err, i, ret;
+    int64_t timestamp;
+    AVDictionary *unused_opts = NULL;
+    AVDictionaryEntry *e = NULL;
+    char *   video_codec_name = NULL;
+    char *   audio_codec_name = NULL;
+    char *subtitle_codec_name = NULL;
+    char *    data_codec_name = NULL;
+    int scan_all_pmts_set = 0;
+
+    if (o->stop_time != INT64_MAX && o->recording_time != INT64_MAX) {
+        o->stop_time = INT64_MAX;
+        av_log(NULL, AV_LOG_WARNING, "-t and -to cannot be used together; using -t.\n");
+    }
+
+    if (o->stop_time != INT64_MAX && o->recording_time == INT64_MAX) {
+        int64_t start_time = o->start_time == AV_NOPTS_VALUE ? 0 : o->start_time;
+        if (o->stop_time <= start_time) {
+            av_log(NULL, AV_LOG_ERROR, "-to value smaller than -ss; aborting.\n");
+            exit_program(1);
+        } else {
+            o->recording_time = o->stop_time - start_time;
+        }
+    }
+
+    if (o->format) {
+        if (!(file_iformat = av_find_input_format(o->format))) {
+            av_log(NULL, AV_LOG_FATAL, "Unknown input format: '%s'\n", o->format);
+            exit_program(1);
+        }
+    }
+
+    if (!strcmp(filename, "-"))
+        filename = "pipe:";
+
+    stdin_interaction &= strncmp(filename, "pipe:", 5) &&
+                         strcmp(filename, "/dev/stdin");
+
+    /* get default parameters from command line */
+    ic = avformat_alloc_context();
+    if (!ic) {
+        print_error(filename, AVERROR(ENOMEM));
+        exit_program(1);
+    }
+    if (o->nb_audio_sample_rate) {
+        av_dict_set_int(&o->g->format_opts, "sample_rate", o->audio_sample_rate[o->nb_audio_sample_rate - 1].u.i, 0);
+    }
+    if (o->nb_audio_channels) {
+        /* because we set audio_channels based on both the "ac" and
+         * "channel_layout" options, we need to check that the specified
+         * demuxer actually has the "channels" option before setting it */
+        if (file_iformat && file_iformat->priv_class &&
+            av_opt_find(&file_iformat->priv_class, "channels", NULL, 0,
+                        AV_OPT_SEARCH_FAKE_OBJ)) {
+            av_dict_set_int(&o->g->format_opts, "channels", o->audio_channels[o->nb_audio_channels - 1].u.i, 0);
+        }
+    }
+    if (o->nb_frame_rates) {
+        /* set the format-level framerate option;
+         * this is important for video grabbers, e.g. x11 */
+        if (file_iformat && file_iformat->priv_class &&
+            av_opt_find(&file_iformat->priv_class, "framerate", NULL, 0,
+                        AV_OPT_SEARCH_FAKE_OBJ)) {
+            av_dict_set(&o->g->format_opts, "framerate",
+                        o->frame_rates[o->nb_frame_rates - 1].u.str, 0);
+        }
+    }
+    if (o->nb_frame_sizes) {
+        av_dict_set(&o->g->format_opts, "video_size", o->frame_sizes[o->nb_frame_sizes - 1].u.str, 0);
+    }
+    if (o->nb_frame_pix_fmts)
+        av_dict_set(&o->g->format_opts, "pixel_format", o->frame_pix_fmts[o->nb_frame_pix_fmts - 1].u.str, 0);
+
+    MATCH_PER_TYPE_OPT(codec_names, str,    video_codec_name, ic, "v");
+    MATCH_PER_TYPE_OPT(codec_names, str,    audio_codec_name, ic, "a");
+    MATCH_PER_TYPE_OPT(codec_names, str, subtitle_codec_name, ic, "s");
+    MATCH_PER_TYPE_OPT(codec_names, str,     data_codec_name, ic, "d");
+
+    if (video_codec_name)
+        ic->video_codec    = find_codec_or_die(video_codec_name   , AVMEDIA_TYPE_VIDEO   , 0);
+    if (audio_codec_name)
+        ic->audio_codec    = find_codec_or_die(audio_codec_name   , AVMEDIA_TYPE_AUDIO   , 0);
+    if (subtitle_codec_name)
+        ic->subtitle_codec = find_codec_or_die(subtitle_codec_name, AVMEDIA_TYPE_SUBTITLE, 0);
+    if (data_codec_name)
+        ic->data_codec     = find_codec_or_die(data_codec_name    , AVMEDIA_TYPE_DATA    , 0);
+
+    ic->video_codec_id     = video_codec_name    ? ic->video_codec->id    : AV_CODEC_ID_NONE;
+    ic->audio_codec_id     = audio_codec_name    ? ic->audio_codec->id    : AV_CODEC_ID_NONE;
+    ic->subtitle_codec_id  = subtitle_codec_name ? ic->subtitle_codec->id : AV_CODEC_ID_NONE;
+    ic->data_codec_id      = data_codec_name     ? ic->data_codec->id     : AV_CODEC_ID_NONE;
+
+    ic->flags |= AVFMT_FLAG_NONBLOCK;
+    if (o->bitexact)
+        ic->flags |= AVFMT_FLAG_BITEXACT;
+    ic->interrupt_callback = int_cb;
+
+    if (!av_dict_get(o->g->format_opts, "scan_all_pmts", NULL, AV_DICT_MATCH_CASE)) {
+        av_dict_set(&o->g->format_opts, "scan_all_pmts", "1", AV_DICT_DONT_OVERWRITE);
+        scan_all_pmts_set = 1;
+    }
+    /* open the input file with generic avformat function */
+    err = avformat_open_input(&ic, filename, file_iformat, &o->g->format_opts);
+    if (err < 0) {
+        print_error(filename, err);
+        if (err == AVERROR_PROTOCOL_NOT_FOUND)
+            av_log(NULL, AV_LOG_ERROR, "Did you mean file:%s?\n", filename);
+        exit_program(1);
+    }
+    if (scan_all_pmts_set)
+        av_dict_set(&o->g->format_opts, "scan_all_pmts", NULL, AV_DICT_MATCH_CASE);
+    remove_avoptions(&o->g->format_opts, o->g->codec_opts);
+    assert_avoptions(o->g->format_opts);
+
+    /* apply forced codec ids */
+    for (i = 0; i < ic->nb_streams; i++)
+        choose_decoder(o, ic, ic->streams[i]);
+
+    if (find_stream_info) {
+        AVDictionary **opts = setup_find_stream_info_opts(ic, o->g->codec_opts);
+        int orig_nb_streams = ic->nb_streams;
+
+        /* If not enough info to get the stream parameters, we decode the
+           first frames to get it. (used in mpeg case for example) */
+        ret = avformat_find_stream_info(ic, opts);
+
+        for (i = 0; i < orig_nb_streams; i++)
+            av_dict_free(&opts[i]);
+        av_freep(&opts);
+
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_FATAL, "%s: could not find codec parameters\n", filename);
+            if (ic->nb_streams == 0) {
+                avformat_close_input(&ic);
+                exit_program(1);
+            }
+        }
+    }
+
+    if (o->start_time != AV_NOPTS_VALUE && o->start_time_eof != AV_NOPTS_VALUE) {
+        av_log(NULL, AV_LOG_WARNING, "Cannot use -ss and -sseof both, using -ss for %s\n", filename);
+        o->start_time_eof = AV_NOPTS_VALUE;
+    }
+
+    if (o->start_time_eof != AV_NOPTS_VALUE) {
+        if (o->start_time_eof >= 0) {
+            av_log(NULL, AV_LOG_ERROR, "-sseof value must be negative; aborting\n");
+            exit_program(1);
+        }
+        if (ic->duration > 0) {
+            o->start_time = o->start_time_eof + ic->duration;
+            if (o->start_time < 0) {
+                av_log(NULL, AV_LOG_WARNING, "-sseof value seeks to before start of file %s; ignored\n", filename);
+                o->start_time = AV_NOPTS_VALUE;
+            }
+        } else
+            av_log(NULL, AV_LOG_WARNING, "Cannot use -sseof, duration of %s not known\n", filename);
+    }
+    timestamp = (o->start_time == AV_NOPTS_VALUE) ? 0 : o->start_time;
+    /* add the stream start time */
+    if (!o->seek_timestamp && ic->start_time != AV_NOPTS_VALUE)
+        timestamp += ic->start_time;
+
+    /* if seeking requested, we execute it */
+    if (o->start_time != AV_NOPTS_VALUE) {
+        int64_t seek_timestamp = timestamp;
+
+        if (!(ic->iformat->flags & AVFMT_SEEK_TO_PTS)) {
+            int dts_heuristic = 0;
+            for (i=0; i<ic->nb_streams; i++) {
+                const AVCodecParameters *par = ic->streams[i]->codecpar;
+                if (par->video_delay) {
+                    dts_heuristic = 1;
+                    break;
+                }
+            }
+            if (dts_heuristic) {
+                seek_timestamp -= 3*AV_TIME_BASE / 23;
+            }
+        }
+        ret = avformat_seek_file(ic, -1, INT64_MIN, seek_timestamp, seek_timestamp, 0);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_WARNING, "%s: could not seek to position %0.3f\n",
+                   filename, (double)timestamp / AV_TIME_BASE);
+        }
+    }
+
+    /* update the current parameters so that they match the one of the input stream */
+    add_input_streams(o, ic);
+
+    /* dump the file content */
+    av_dump_format(ic, nb_input_files, filename, 0);
+
+    GROW_ARRAY(input_files, nb_input_files);
+    f = av_mallocz(sizeof(*f));
+    if (!f)
+        exit_program(1);
+    input_files[nb_input_files - 1] = f;
+
+    f->ctx        = ic;
+    f->ist_index  = nb_input_streams - ic->nb_streams;
+    f->start_time = o->start_time;
+    f->recording_time = o->recording_time;
+    f->input_ts_offset = o->input_ts_offset;
+    f->ts_offset  = o->input_ts_offset - (copy_ts ? (start_at_zero && ic->start_time != AV_NOPTS_VALUE ? ic->start_time : 0) : timestamp);
+    f->nb_streams = ic->nb_streams;
+    f->rate_emu   = o->rate_emu;
+    f->accurate_seek = o->accurate_seek;
+    f->loop = o->loop;
+    f->duration = 0;
+    f->time_base = (AVRational){ 1, 1 };
+    f->pkt = av_packet_alloc();
+    if (!f->pkt)
+        exit_program(1);
+#if HAVE_THREADS
+    f->thread_queue_size = o->thread_queue_size;
+#endif
+
+    /* check if all codec options have been used */
+    unused_opts = strip_specifiers(o->g->codec_opts);
+    for (i = f->ist_index; i < nb_input_streams; i++) {
+        e = NULL;
+        while ((e = av_dict_get(input_streams[i]->decoder_opts, "", e,
+                                AV_DICT_IGNORE_SUFFIX)))
+            av_dict_set(&unused_opts, e->key, NULL, 0);
+    }
+
+    e = NULL;
+    while ((e = av_dict_get(unused_opts, "", e, AV_DICT_IGNORE_SUFFIX))) {
+        const AVClass *class = avcodec_get_class();
+        const AVOption *option = av_opt_find(&class, e->key, NULL, 0,
+                                             AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ);
+        const AVClass *fclass = avformat_get_class();
+        const AVOption *foption = av_opt_find(&fclass, e->key, NULL, 0,
+                                             AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ);
+        if (!option || foption)
+            continue;
+
+
+        if (!(option->flags & AV_OPT_FLAG_DECODING_PARAM)) {
+            av_log(NULL, AV_LOG_ERROR, "Codec AVOption %s (%s) specified for "
+                   "input file #%d (%s) is not a decoding option.\n", e->key,
+                   option->help ? option->help : "", nb_input_files - 1,
+                   filename);
+            exit_program(1);
+        }
+
+        av_log(NULL, AV_LOG_WARNING, "Codec AVOption %s (%s) specified for "
+               "input file #%d (%s) has not been used for any stream. The most "
+               "likely reason is either wrong type (e.g. a video option with "
+               "no video streams) or that it is a private option of some decoder "
+               "which was not actually used for any stream.\n", e->key,
+               option->help ? option->help : "", nb_input_files - 1, filename);
+    }
+    av_dict_free(&unused_opts);
+
+    for (i = 0; i < o->nb_dump_attachment; i++) {
+        int j;
+
+        for (j = 0; j < ic->nb_streams; j++) {
+            AVStream *st = ic->streams[j];
+
+            if (check_stream_specifier(ic, st, o->dump_attachment[i].specifier) == 1)
+                dump_attachment(st, o->dump_attachment[i].u.str);
+        }
+    }
+
+    input_stream_potentially_available = 1;
+
+    return 0;
+}
+
+static uint8_t *get_line(AVIOContext *s)
+{
+    AVIOContext *line;
+    uint8_t *buf;
+    char c;
+
+    if (avio_open_dyn_buf(&line) < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Could not alloc buffer for reading preset.\n");
+        exit_program(1);
+    }
+
+    while ((c = avio_r8(s)) && c != '\n')
+        avio_w8(line, c);
+    avio_w8(line, 0);
+    avio_close_dyn_buf(line, &buf);
+
+    return buf;
+}
+
+static int get_preset_file_2(const char *preset_name, const char *codec_name, AVIOContext **s)
+{
+    int i, ret = -1;
+    char filename[1000];
+    const char *base[3] = { getenv("AVCONV_DATADIR"),
+                            getenv("HOME"),
+                            AVCONV_DATADIR,
+                            };
+
+    for (i = 0; i < FF_ARRAY_ELEMS(base) && ret < 0; i++) {
+        if (!base[i])
+            continue;
+        if (codec_name) {
+            snprintf(filename, sizeof(filename), "%s%s/%s-%s.avpreset", base[i],
+                     i != 1 ? "" : "/.avconv", codec_name, preset_name);
+            ret = avio_open2(s, filename, AVIO_FLAG_READ, &int_cb, NULL);
+        }
+        if (ret < 0) {
+            snprintf(filename, sizeof(filename), "%s%s/%s.avpreset", base[i],
+                     i != 1 ? "" : "/.avconv", preset_name);
+            ret = avio_open2(s, filename, AVIO_FLAG_READ, &int_cb, NULL);
+        }
+    }
+    return ret;
+}
+
+static int choose_encoder(OptionsContext *o, AVFormatContext *s, OutputStream *ost)
+{
+    enum AVMediaType type = ost->st->codecpar->codec_type;
+    char *codec_name = NULL;
+
+    if (type == AVMEDIA_TYPE_VIDEO || type == AVMEDIA_TYPE_AUDIO || type == AVMEDIA_TYPE_SUBTITLE) {
+        MATCH_PER_STREAM_OPT(codec_names, str, codec_name, s, ost->st);
+        if (!codec_name) {
+            ost->st->codecpar->codec_id = av_guess_codec(s->oformat, NULL, s->url,
+                                                         NULL, ost->st->codecpar->codec_type);
+            ost->enc = avcodec_find_encoder(ost->st->codecpar->codec_id);
+            if (!ost->enc) {
+                av_log(NULL, AV_LOG_FATAL, "Automatic encoder selection failed for "
+                       "output stream #%d:%d. Default encoder for format %s (codec %s) is "
+                       "probably disabled. Please choose an encoder manually.\n",
+                       ost->file_index, ost->index, s->oformat->name,
+                       avcodec_get_name(ost->st->codecpar->codec_id));
+                return AVERROR_ENCODER_NOT_FOUND;
+            }
+        } else if (!strcmp(codec_name, "copy"))
+            ost->stream_copy = 1;
+        else {
+            ost->enc = find_codec_or_die(codec_name, ost->st->codecpar->codec_type, 1);
+            ost->st->codecpar->codec_id = ost->enc->id;
+        }
+        ost->encoding_needed = !ost->stream_copy;
+    } else {
+        /* no encoding supported for other media types */
+        ost->stream_copy     = 1;
+        ost->encoding_needed = 0;
+    }
+
+    return 0;
+}
+
+static OutputStream *new_output_stream(OptionsContext *o, AVFormatContext *oc, enum AVMediaType type, int source_index)
+{
+    OutputStream *ost;
+    AVStream *st = avformat_new_stream(oc, NULL);
+    int idx      = oc->nb_streams - 1, ret = 0;
+    const char *bsfs = NULL, *time_base = NULL;
+    char *next, *codec_tag = NULL;
+    double qscale = -1;
+    int i;
+
+    if (!st) {
+        av_log(NULL, AV_LOG_FATAL, "Could not alloc stream.\n");
+        exit_program(1);
+    }
+
+    if (oc->nb_streams - 1 < o->nb_streamid_map)
+        st->id = o->streamid_map[oc->nb_streams - 1];
+
+    GROW_ARRAY(output_streams, nb_output_streams);
+    if (!(ost = av_mallocz(sizeof(*ost))))
+        exit_program(1);
+    output_streams[nb_output_streams - 1] = ost;
+
+    ost->file_index = nb_output_files - 1;
+    ost->index      = idx;
+    ost->st         = st;
+    ost->forced_kf_ref_pts = AV_NOPTS_VALUE;
+    st->codecpar->codec_type = type;
+
+    ret = choose_encoder(o, oc, ost);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Error selecting an encoder for stream "
+               "%d:%d\n", ost->file_index, ost->index);
+        exit_program(1);
+    }
+
+    ost->enc_ctx = avcodec_alloc_context3(ost->enc);
+    if (!ost->enc_ctx) {
+        av_log(NULL, AV_LOG_ERROR, "Error allocating the encoding context.\n");
+        exit_program(1);
+    }
+    ost->enc_ctx->codec_type = type;
+
+    ost->ref_par = avcodec_parameters_alloc();
+    if (!ost->ref_par) {
+        av_log(NULL, AV_LOG_ERROR, "Error allocating the encoding parameters.\n");
+        exit_program(1);
+    }
+
+    if (ost->enc) {
+        AVIOContext *s = NULL;
+        char *buf = NULL, *arg = NULL, *preset = NULL;
+
+        ost->encoder_opts  = filter_codec_opts(o->g->codec_opts, ost->enc->id, oc, st, ost->enc);
+
+        MATCH_PER_STREAM_OPT(presets, str, preset, oc, st);
+        ost->autoscale = 1;
+        MATCH_PER_STREAM_OPT(autoscale, i, ost->autoscale, oc, st);
+        if (preset && (!(ret = get_preset_file_2(preset, ost->enc->name, &s)))) {
+            do  {
+                buf = get_line(s);
+                if (!buf[0] || buf[0] == '#') {
+                    av_free(buf);
+                    continue;
+                }
+                if (!(arg = strchr(buf, '='))) {
+                    av_log(NULL, AV_LOG_FATAL, "Invalid line found in the preset file.\n");
+                    exit_program(1);
+                }
+                *arg++ = 0;
+                av_dict_set(&ost->encoder_opts, buf, arg, AV_DICT_DONT_OVERWRITE);
+                av_free(buf);
+            } while (!s->eof_reached);
+            avio_closep(&s);
+        }
+        if (ret) {
+            av_log(NULL, AV_LOG_FATAL,
+                   "Preset %s specified for stream %d:%d, but could not be opened.\n",
+                   preset, ost->file_index, ost->index);
+            exit_program(1);
+        }
+    } else {
+        ost->encoder_opts = filter_codec_opts(o->g->codec_opts, AV_CODEC_ID_NONE, oc, st, NULL);
+    }
+
+
+    if (o->bitexact)
+        ost->enc_ctx->flags |= AV_CODEC_FLAG_BITEXACT;
+
+    MATCH_PER_STREAM_OPT(time_bases, str, time_base, oc, st);
+    if (time_base) {
+        AVRational q;
+        if (av_parse_ratio(&q, time_base, INT_MAX, 0, NULL) < 0 ||
+            q.num <= 0 || q.den <= 0) {
+            av_log(NULL, AV_LOG_FATAL, "Invalid time base: %s\n", time_base);
+            exit_program(1);
+        }
+        st->time_base = q;
+    }
+
+    MATCH_PER_STREAM_OPT(enc_time_bases, str, time_base, oc, st);
+    if (time_base) {
+        AVRational q;
+        if (av_parse_ratio(&q, time_base, INT_MAX, 0, NULL) < 0 ||
+            q.den <= 0) {
+            av_log(NULL, AV_LOG_FATAL, "Invalid time base: %s\n", time_base);
+            exit_program(1);
+        }
+        ost->enc_timebase = q;
+    }
+
+    ost->max_frames = INT64_MAX;
+    MATCH_PER_STREAM_OPT(max_frames, i64, ost->max_frames, oc, st);
+    for (i = 0; i<o->nb_max_frames; i++) {
+        char *p = o->max_frames[i].specifier;
+        if (!*p && type != AVMEDIA_TYPE_VIDEO) {
+            av_log(NULL, AV_LOG_WARNING, "Applying unspecific -frames to non video streams, maybe you meant -vframes ?\n");
+            break;
+        }
+    }
+
+    ost->copy_prior_start = -1;
+    MATCH_PER_STREAM_OPT(copy_prior_start, i, ost->copy_prior_start, oc ,st);
+
+    MATCH_PER_STREAM_OPT(bitstream_filters, str, bsfs, oc, st);
+    if (bsfs && *bsfs) {
+        ret = av_bsf_list_parse_str(bsfs, &ost->bsf_ctx);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error parsing bitstream filter sequence '%s': %s\n", bsfs, av_err2str(ret));
+            exit_program(1);
+        }
+    }
+
+    MATCH_PER_STREAM_OPT(codec_tags, str, codec_tag, oc, st);
+    if (codec_tag) {
+        uint32_t tag = strtol(codec_tag, &next, 0);
+        if (*next)
+            tag = AV_RL32(codec_tag);
+        ost->st->codecpar->codec_tag =
+        ost->enc_ctx->codec_tag = tag;
+    }
+
+    MATCH_PER_STREAM_OPT(qscale, dbl, qscale, oc, st);
+    if (qscale >= 0) {
+        ost->enc_ctx->flags |= AV_CODEC_FLAG_QSCALE;
+        ost->enc_ctx->global_quality = FF_QP2LAMBDA * qscale;
+    }
+
+    MATCH_PER_STREAM_OPT(disposition, str, ost->disposition, oc, st);
+    ost->disposition = av_strdup(ost->disposition);
+
+    ost->max_muxing_queue_size = 128;
+    MATCH_PER_STREAM_OPT(max_muxing_queue_size, i, ost->max_muxing_queue_size, oc, st);
+    ost->max_muxing_queue_size *= sizeof(ost->pkt);
+
+    ost->muxing_queue_data_size = 0;
+
+    ost->muxing_queue_data_threshold = 50*1024*1024;
+    MATCH_PER_STREAM_OPT(muxing_queue_data_threshold, i, ost->muxing_queue_data_threshold, oc, st);
+
+    if (oc->oformat->flags & AVFMT_GLOBALHEADER)
+        ost->enc_ctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
+
+    av_dict_copy(&ost->sws_dict, o->g->sws_dict, 0);
+
+    av_dict_copy(&ost->swr_opts, o->g->swr_opts, 0);
+    if (ost->enc && av_get_exact_bits_per_sample(ost->enc->id) == 24)
+        av_dict_set(&ost->swr_opts, "output_sample_bits", "24", 0);
+
+    av_dict_copy(&ost->resample_opts, o->g->resample_opts, 0);
+
+    ost->source_index = source_index;
+    if (source_index >= 0) {
+        ost->sync_ist = input_streams[source_index];
+        input_streams[source_index]->discard = 0;
+        input_streams[source_index]->st->discard = input_streams[source_index]->user_set_discard;
+    }
+    ost->last_mux_dts = AV_NOPTS_VALUE;
+
+    ost->muxing_queue = av_fifo_alloc(8 * sizeof(AVPacket));
+    if (!ost->muxing_queue)
+        exit_program(1);
+
+    return ost;
+}
+
+static void parse_matrix_coeffs(uint16_t *dest, const char *str)
+{
+    int i;
+    const char *p = str;
+    for (i = 0;; i++) {
+        dest[i] = atoi(p);
+        if (i == 63)
+            break;
+        p = strchr(p, ',');
+        if (!p) {
+            av_log(NULL, AV_LOG_FATAL, "Syntax error in matrix \"%s\" at coeff %d\n", str, i);
+            exit_program(1);
+        }
+        p++;
+    }
+}
+
+/* read file contents into a string */
+static uint8_t *read_file(const char *filename)
+{
+    AVIOContext *pb      = NULL;
+    AVIOContext *dyn_buf = NULL;
+    int ret = avio_open(&pb, filename, AVIO_FLAG_READ);
+    uint8_t buf[1024], *str;
+
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Error opening file %s.\n", filename);
+        return NULL;
+    }
+
+    ret = avio_open_dyn_buf(&dyn_buf);
+    if (ret < 0) {
+        avio_closep(&pb);
+        return NULL;
+    }
+    while ((ret = avio_read(pb, buf, sizeof(buf))) > 0)
+        avio_write(dyn_buf, buf, ret);
+    avio_w8(dyn_buf, 0);
+    avio_closep(&pb);
+
+    ret = avio_close_dyn_buf(dyn_buf, &str);
+    if (ret < 0)
+        return NULL;
+    return str;
+}
+
+static char *get_ost_filters(OptionsContext *o, AVFormatContext *oc,
+                             OutputStream *ost)
+{
+    AVStream *st = ost->st;
+
+    if (ost->filters_script && ost->filters) {
+        av_log(NULL, AV_LOG_ERROR, "Both -filter and -filter_script set for "
+               "output stream #%d:%d.\n", nb_output_files, st->index);
+        exit_program(1);
+    }
+
+    if (ost->filters_script)
+        return read_file(ost->filters_script);
+    else if (ost->filters)
+        return av_strdup(ost->filters);
+
+    return av_strdup(st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO ?
+                     "null" : "anull");
+}
+
+static void check_streamcopy_filters(OptionsContext *o, AVFormatContext *oc,
+                                     const OutputStream *ost, enum AVMediaType type)
+{
+    if (ost->filters_script || ost->filters) {
+        av_log(NULL, AV_LOG_ERROR,
+               "%s '%s' was defined for %s output stream %d:%d but codec copy was selected.\n"
+               "Filtering and streamcopy cannot be used together.\n",
+               ost->filters ? "Filtergraph" : "Filtergraph script",
+               ost->filters ? ost->filters : ost->filters_script,
+               av_get_media_type_string(type), ost->file_index, ost->index);
+        exit_program(1);
+    }
+}
+
+static OutputStream *new_video_stream(OptionsContext *o, AVFormatContext *oc, int source_index)
+{
+    AVStream *st;
+    OutputStream *ost;
+    AVCodecContext *video_enc;
+    char *frame_rate = NULL, *max_frame_rate = NULL, *frame_aspect_ratio = NULL;
+
+    ost = new_output_stream(o, oc, AVMEDIA_TYPE_VIDEO, source_index);
+    st  = ost->st;
+    video_enc = ost->enc_ctx;
+
+    MATCH_PER_STREAM_OPT(frame_rates, str, frame_rate, oc, st);
+    if (frame_rate && av_parse_video_rate(&ost->frame_rate, frame_rate) < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Invalid framerate value: %s\n", frame_rate);
+        exit_program(1);
+    }
+
+    MATCH_PER_STREAM_OPT(max_frame_rates, str, max_frame_rate, oc, st);
+    if (max_frame_rate && av_parse_video_rate(&ost->max_frame_rate, max_frame_rate) < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Invalid maximum framerate value: %s\n", max_frame_rate);
+        exit_program(1);
+    }
+
+    if (frame_rate && max_frame_rate) {
+        av_log(NULL, AV_LOG_ERROR, "Only one of -fpsmax and -r can be set for a stream.\n");
+        exit_program(1);
+    }
+
+    if ((frame_rate || max_frame_rate) &&
+        video_sync_method == VSYNC_PASSTHROUGH)
+        av_log(NULL, AV_LOG_ERROR, "Using -vsync 0 and -r/-fpsmax can produce invalid output files\n");
+
+    MATCH_PER_STREAM_OPT(frame_aspect_ratios, str, frame_aspect_ratio, oc, st);
+    if (frame_aspect_ratio) {
+        AVRational q;
+        if (av_parse_ratio(&q, frame_aspect_ratio, 255, 0, NULL) < 0 ||
+            q.num <= 0 || q.den <= 0) {
+            av_log(NULL, AV_LOG_FATAL, "Invalid aspect ratio: %s\n", frame_aspect_ratio);
+            exit_program(1);
+        }
+        ost->frame_aspect_ratio = q;
+    }
+
+    MATCH_PER_STREAM_OPT(filter_scripts, str, ost->filters_script, oc, st);
+    MATCH_PER_STREAM_OPT(filters,        str, ost->filters,        oc, st);
+
+    if (!ost->stream_copy) {
+        const char *p = NULL;
+        char *frame_size = NULL;
+        char *frame_pix_fmt = NULL;
+        char *intra_matrix = NULL, *inter_matrix = NULL;
+        char *chroma_intra_matrix = NULL;
+        int do_pass = 0;
+        int i;
+
+        MATCH_PER_STREAM_OPT(frame_sizes, str, frame_size, oc, st);
+        if (frame_size && av_parse_video_size(&video_enc->width, &video_enc->height, frame_size) < 0) {
+            av_log(NULL, AV_LOG_FATAL, "Invalid frame size: %s.\n", frame_size);
+            exit_program(1);
+        }
+
+        video_enc->bits_per_raw_sample = frame_bits_per_raw_sample;
+        MATCH_PER_STREAM_OPT(frame_pix_fmts, str, frame_pix_fmt, oc, st);
+        if (frame_pix_fmt && *frame_pix_fmt == '+') {
+            ost->keep_pix_fmt = 1;
+            if (!*++frame_pix_fmt)
+                frame_pix_fmt = NULL;
+        }
+        if (frame_pix_fmt && (video_enc->pix_fmt = av_get_pix_fmt(frame_pix_fmt)) == AV_PIX_FMT_NONE) {
+            av_log(NULL, AV_LOG_FATAL, "Unknown pixel format requested: %s.\n", frame_pix_fmt);
+            exit_program(1);
+        }
+        st->sample_aspect_ratio = video_enc->sample_aspect_ratio;
+
+        if (intra_only)
+            video_enc->gop_size = 0;
+        MATCH_PER_STREAM_OPT(intra_matrices, str, intra_matrix, oc, st);
+        if (intra_matrix) {
+            if (!(video_enc->intra_matrix = av_mallocz(sizeof(*video_enc->intra_matrix) * 64))) {
+                av_log(NULL, AV_LOG_FATAL, "Could not allocate memory for intra matrix.\n");
+                exit_program(1);
+            }
+            parse_matrix_coeffs(video_enc->intra_matrix, intra_matrix);
+        }
+        MATCH_PER_STREAM_OPT(chroma_intra_matrices, str, chroma_intra_matrix, oc, st);
+        if (chroma_intra_matrix) {
+            uint16_t *p = av_mallocz(sizeof(*video_enc->chroma_intra_matrix) * 64);
+            if (!p) {
+                av_log(NULL, AV_LOG_FATAL, "Could not allocate memory for intra matrix.\n");
+                exit_program(1);
+            }
+            video_enc->chroma_intra_matrix = p;
+            parse_matrix_coeffs(p, chroma_intra_matrix);
+        }
+        MATCH_PER_STREAM_OPT(inter_matrices, str, inter_matrix, oc, st);
+        if (inter_matrix) {
+            if (!(video_enc->inter_matrix = av_mallocz(sizeof(*video_enc->inter_matrix) * 64))) {
+                av_log(NULL, AV_LOG_FATAL, "Could not allocate memory for inter matrix.\n");
+                exit_program(1);
+            }
+            parse_matrix_coeffs(video_enc->inter_matrix, inter_matrix);
+        }
+
+        MATCH_PER_STREAM_OPT(rc_overrides, str, p, oc, st);
+        for (i = 0; p; i++) {
+            int start, end, q;
+            int e = sscanf(p, "%d,%d,%d", &start, &end, &q);
+            if (e != 3) {
+                av_log(NULL, AV_LOG_FATAL, "error parsing rc_override\n");
+                exit_program(1);
+            }
+            video_enc->rc_override =
+                av_realloc_array(video_enc->rc_override,
+                                 i + 1, sizeof(RcOverride));
+            if (!video_enc->rc_override) {
+                av_log(NULL, AV_LOG_FATAL, "Could not (re)allocate memory for rc_override.\n");
+                exit_program(1);
+            }
+            video_enc->rc_override[i].start_frame = start;
+            video_enc->rc_override[i].end_frame   = end;
+            if (q > 0) {
+                video_enc->rc_override[i].qscale         = q;
+                video_enc->rc_override[i].quality_factor = 1.0;
+            }
+            else {
+                video_enc->rc_override[i].qscale         = 0;
+                video_enc->rc_override[i].quality_factor = -q/100.0;
+            }
+            p = strchr(p, '/');
+            if (p) p++;
+        }
+        video_enc->rc_override_count = i;
+
+        if (do_psnr)
+            video_enc->flags|= AV_CODEC_FLAG_PSNR;
+
+        /* two pass mode */
+        MATCH_PER_STREAM_OPT(pass, i, do_pass, oc, st);
+        if (do_pass) {
+            if (do_pass & 1) {
+                video_enc->flags |= AV_CODEC_FLAG_PASS1;
+                av_dict_set(&ost->encoder_opts, "flags", "+pass1", AV_DICT_APPEND);
+            }
+            if (do_pass & 2) {
+                video_enc->flags |= AV_CODEC_FLAG_PASS2;
+                av_dict_set(&ost->encoder_opts, "flags", "+pass2", AV_DICT_APPEND);
+            }
+        }
+
+        MATCH_PER_STREAM_OPT(passlogfiles, str, ost->logfile_prefix, oc, st);
+        if (ost->logfile_prefix &&
+            !(ost->logfile_prefix = av_strdup(ost->logfile_prefix)))
+            exit_program(1);
+
+        if (do_pass) {
+            char logfilename[1024];
+            FILE *f;
+
+            snprintf(logfilename, sizeof(logfilename), "%s-%d.log",
+                     ost->logfile_prefix ? ost->logfile_prefix :
+                                           DEFAULT_PASS_LOGFILENAME_PREFIX,
+                     i);
+            if (!strcmp(ost->enc->name, "libx264")) {
+                av_dict_set(&ost->encoder_opts, "stats", logfilename, AV_DICT_DONT_OVERWRITE);
+            } else {
+                if (video_enc->flags & AV_CODEC_FLAG_PASS2) {
+                    char  *logbuffer = read_file(logfilename);
+
+                    if (!logbuffer) {
+                        av_log(NULL, AV_LOG_FATAL, "Error reading log file '%s' for pass-2 encoding\n",
+                               logfilename);
+                        exit_program(1);
+                    }
+                    video_enc->stats_in = logbuffer;
+                }
+                if (video_enc->flags & AV_CODEC_FLAG_PASS1) {
+                    f = av_fopen_utf8(logfilename, "wb");
+                    if (!f) {
+                        av_log(NULL, AV_LOG_FATAL,
+                               "Cannot write log file '%s' for pass-1 encoding: %s\n",
+                               logfilename, strerror(errno));
+                        exit_program(1);
+                    }
+                    ost->logfile = f;
+                }
+            }
+        }
+
+        MATCH_PER_STREAM_OPT(forced_key_frames, str, ost->forced_keyframes, oc, st);
+        if (ost->forced_keyframes)
+            ost->forced_keyframes = av_strdup(ost->forced_keyframes);
+
+        MATCH_PER_STREAM_OPT(force_fps, i, ost->force_fps, oc, st);
+
+        ost->top_field_first = -1;
+        MATCH_PER_STREAM_OPT(top_field_first, i, ost->top_field_first, oc, st);
+
+
+        ost->avfilter = get_ost_filters(o, oc, ost);
+        if (!ost->avfilter)
+            exit_program(1);
+    } else {
+        MATCH_PER_STREAM_OPT(copy_initial_nonkeyframes, i, ost->copy_initial_nonkeyframes, oc ,st);
+    }
+
+    if (ost->stream_copy)
+        check_streamcopy_filters(o, oc, ost, AVMEDIA_TYPE_VIDEO);
+
+    return ost;
+}
+
+static OutputStream *new_audio_stream(OptionsContext *o, AVFormatContext *oc, int source_index)
+{
+    int n;
+    AVStream *st;
+    OutputStream *ost;
+    AVCodecContext *audio_enc;
+
+    ost = new_output_stream(o, oc, AVMEDIA_TYPE_AUDIO, source_index);
+    st  = ost->st;
+
+    audio_enc = ost->enc_ctx;
+    audio_enc->codec_type = AVMEDIA_TYPE_AUDIO;
+
+    MATCH_PER_STREAM_OPT(filter_scripts, str, ost->filters_script, oc, st);
+    MATCH_PER_STREAM_OPT(filters,        str, ost->filters,        oc, st);
+
+    if (!ost->stream_copy) {
+        char *sample_fmt = NULL;
+
+        MATCH_PER_STREAM_OPT(audio_channels, i, audio_enc->channels, oc, st);
+
+        MATCH_PER_STREAM_OPT(sample_fmts, str, sample_fmt, oc, st);
+        if (sample_fmt &&
+            (audio_enc->sample_fmt = av_get_sample_fmt(sample_fmt)) == AV_SAMPLE_FMT_NONE) {
+            av_log(NULL, AV_LOG_FATAL, "Invalid sample format '%s'\n", sample_fmt);
+            exit_program(1);
+        }
+
+        MATCH_PER_STREAM_OPT(audio_sample_rate, i, audio_enc->sample_rate, oc, st);
+
+        MATCH_PER_STREAM_OPT(apad, str, ost->apad, oc, st);
+        ost->apad = av_strdup(ost->apad);
+
+        ost->avfilter = get_ost_filters(o, oc, ost);
+        if (!ost->avfilter)
+            exit_program(1);
+
+        /* check for channel mapping for this audio stream */
+        for (n = 0; n < o->nb_audio_channel_maps; n++) {
+            AudioChannelMap *map = &o->audio_channel_maps[n];
+            if ((map->ofile_idx   == -1 || ost->file_index == map->ofile_idx) &&
+                (map->ostream_idx == -1 || ost->st->index  == map->ostream_idx)) {
+                InputStream *ist;
+
+                if (map->channel_idx == -1) {
+                    ist = NULL;
+                } else if (ost->source_index < 0) {
+                    av_log(NULL, AV_LOG_FATAL, "Cannot determine input stream for channel mapping %d.%d\n",
+                           ost->file_index, ost->st->index);
+                    continue;
+                } else {
+                    ist = input_streams[ost->source_index];
+                }
+
+                if (!ist || (ist->file_index == map->file_idx && ist->st->index == map->stream_idx)) {
+                    if (av_reallocp_array(&ost->audio_channels_map,
+                                          ost->audio_channels_mapped + 1,
+                                          sizeof(*ost->audio_channels_map)
+                                          ) < 0 )
+                        exit_program(1);
+
+                    ost->audio_channels_map[ost->audio_channels_mapped++] = map->channel_idx;
+                }
+            }
+        }
+    }
+
+    if (ost->stream_copy)
+        check_streamcopy_filters(o, oc, ost, AVMEDIA_TYPE_AUDIO);
+
+    return ost;
+}
+
+static OutputStream *new_data_stream(OptionsContext *o, AVFormatContext *oc, int source_index)
+{
+    OutputStream *ost;
+
+    ost = new_output_stream(o, oc, AVMEDIA_TYPE_DATA, source_index);
+    if (!ost->stream_copy) {
+        av_log(NULL, AV_LOG_FATAL, "Data stream encoding not supported yet (only streamcopy)\n");
+        exit_program(1);
+    }
+
+    return ost;
+}
+
+static OutputStream *new_unknown_stream(OptionsContext *o, AVFormatContext *oc, int source_index)
+{
+    OutputStream *ost;
+
+    ost = new_output_stream(o, oc, AVMEDIA_TYPE_UNKNOWN, source_index);
+    if (!ost->stream_copy) {
+        av_log(NULL, AV_LOG_FATAL, "Unknown stream encoding not supported yet (only streamcopy)\n");
+        exit_program(1);
+    }
+
+    return ost;
+}
+
+static OutputStream *new_attachment_stream(OptionsContext *o, AVFormatContext *oc, int source_index)
+{
+    OutputStream *ost = new_output_stream(o, oc, AVMEDIA_TYPE_ATTACHMENT, source_index);
+    ost->stream_copy = 1;
+    ost->finished    = 1;
+    return ost;
+}
+
+static OutputStream *new_subtitle_stream(OptionsContext *o, AVFormatContext *oc, int source_index)
+{
+    AVStream *st;
+    OutputStream *ost;
+    AVCodecContext *subtitle_enc;
+
+    ost = new_output_stream(o, oc, AVMEDIA_TYPE_SUBTITLE, source_index);
+    st  = ost->st;
+    subtitle_enc = ost->enc_ctx;
+
+    subtitle_enc->codec_type = AVMEDIA_TYPE_SUBTITLE;
+
+    MATCH_PER_STREAM_OPT(copy_initial_nonkeyframes, i, ost->copy_initial_nonkeyframes, oc, st);
+
+    if (!ost->stream_copy) {
+        char *frame_size = NULL;
+
+        MATCH_PER_STREAM_OPT(frame_sizes, str, frame_size, oc, st);
+        if (frame_size && av_parse_video_size(&subtitle_enc->width, &subtitle_enc->height, frame_size) < 0) {
+            av_log(NULL, AV_LOG_FATAL, "Invalid frame size: %s.\n", frame_size);
+            exit_program(1);
+        }
+    }
+
+    return ost;
+}
+
+/* arg format is "output-stream-index:streamid-value". */
+static int opt_streamid(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    int idx;
+    char *p;
+    char idx_str[16];
+
+    av_strlcpy(idx_str, arg, sizeof(idx_str));
+    p = strchr(idx_str, ':');
+    if (!p) {
+        av_log(NULL, AV_LOG_FATAL,
+               "Invalid value '%s' for option '%s', required syntax is 'index:value'\n",
+               arg, opt);
+        exit_program(1);
+    }
+    *p++ = '\0';
+    idx = parse_number_or_die(opt, idx_str, OPT_INT, 0, MAX_STREAMS-1);
+    o->streamid_map = grow_array(o->streamid_map, sizeof(*o->streamid_map), &o->nb_streamid_map, idx+1);
+    o->streamid_map[idx] = parse_number_or_die(opt, p, OPT_INT, 0, INT_MAX);
+    return 0;
+}
+
+static int copy_chapters(InputFile *ifile, OutputFile *ofile, int copy_metadata)
+{
+    AVFormatContext *is = ifile->ctx;
+    AVFormatContext *os = ofile->ctx;
+    AVChapter **tmp;
+    int i;
+
+    tmp = av_realloc_f(os->chapters, is->nb_chapters + os->nb_chapters, sizeof(*os->chapters));
+    if (!tmp)
+        return AVERROR(ENOMEM);
+    os->chapters = tmp;
+
+    for (i = 0; i < is->nb_chapters; i++) {
+        AVChapter *in_ch = is->chapters[i], *out_ch;
+        int64_t start_time = (ofile->start_time == AV_NOPTS_VALUE) ? 0 : ofile->start_time;
+        int64_t ts_off   = av_rescale_q(start_time - ifile->ts_offset,
+                                       AV_TIME_BASE_Q, in_ch->time_base);
+        int64_t rt       = (ofile->recording_time == INT64_MAX) ? INT64_MAX :
+                           av_rescale_q(ofile->recording_time, AV_TIME_BASE_Q, in_ch->time_base);
+
+
+        if (in_ch->end < ts_off)
+            continue;
+        if (rt != INT64_MAX && in_ch->start > rt + ts_off)
+            break;
+
+        out_ch = av_mallocz(sizeof(AVChapter));
+        if (!out_ch)
+            return AVERROR(ENOMEM);
+
+        out_ch->id        = in_ch->id;
+        out_ch->time_base = in_ch->time_base;
+        out_ch->start     = FFMAX(0,  in_ch->start - ts_off);
+        out_ch->end       = FFMIN(rt, in_ch->end   - ts_off);
+
+        if (copy_metadata)
+            av_dict_copy(&out_ch->metadata, in_ch->metadata, 0);
+
+        os->chapters[os->nb_chapters++] = out_ch;
+    }
+    return 0;
+}
+
+static void init_output_filter(OutputFilter *ofilter, OptionsContext *o,
+                               AVFormatContext *oc)
+{
+    OutputStream *ost;
+
+    switch (ofilter->type) {
+    case AVMEDIA_TYPE_VIDEO: ost = new_video_stream(o, oc, -1); break;
+    case AVMEDIA_TYPE_AUDIO: ost = new_audio_stream(o, oc, -1); break;
+    default:
+        av_log(NULL, AV_LOG_FATAL, "Only video and audio filters are supported "
+               "currently.\n");
+        exit_program(1);
+    }
+
+    ost->source_index = -1;
+    ost->filter       = ofilter;
+
+    ofilter->ost      = ost;
+    ofilter->format   = -1;
+
+    if (ost->stream_copy) {
+        av_log(NULL, AV_LOG_ERROR, "Streamcopy requested for output stream %d:%d, "
+               "which is fed from a complex filtergraph. Filtering and streamcopy "
+               "cannot be used together.\n", ost->file_index, ost->index);
+        exit_program(1);
+    }
+
+    if (ost->avfilter && (ost->filters || ost->filters_script)) {
+        const char *opt = ost->filters ? "-vf/-af/-filter" : "-filter_script";
+        av_log(NULL, AV_LOG_ERROR,
+               "%s '%s' was specified through the %s option "
+               "for output stream %d:%d, which is fed from a complex filtergraph.\n"
+               "%s and -filter_complex cannot be used together for the same stream.\n",
+               ost->filters ? "Filtergraph" : "Filtergraph script",
+               ost->filters ? ost->filters : ost->filters_script,
+               opt, ost->file_index, ost->index, opt);
+        exit_program(1);
+    }
+
+    avfilter_inout_free(&ofilter->out_tmp);
+}
+
+static int init_complex_filters(void)
+{
+    int i, ret = 0;
+
+    for (i = 0; i < nb_filtergraphs; i++) {
+        ret = init_complex_filtergraph(filtergraphs[i]);
+        if (ret < 0)
+            return ret;
+    }
+    return 0;
+}
+
+static int open_output_file(OptionsContext *o, const char *filename)
+{
+    AVFormatContext *oc;
+    int i, j, err;
+    OutputFile *of;
+    OutputStream *ost;
+    InputStream  *ist;
+    AVDictionary *unused_opts = NULL;
+    AVDictionaryEntry *e = NULL;
+    int format_flags = 0;
+
+    if (o->stop_time != INT64_MAX && o->recording_time != INT64_MAX) {
+        o->stop_time = INT64_MAX;
+        av_log(NULL, AV_LOG_WARNING, "-t and -to cannot be used together; using -t.\n");
+    }
+
+    if (o->stop_time != INT64_MAX && o->recording_time == INT64_MAX) {
+        int64_t start_time = o->start_time == AV_NOPTS_VALUE ? 0 : o->start_time;
+        if (o->stop_time <= start_time) {
+            av_log(NULL, AV_LOG_ERROR, "-to value smaller than -ss; aborting.\n");
+            exit_program(1);
+        } else {
+            o->recording_time = o->stop_time - start_time;
+        }
+    }
+
+    GROW_ARRAY(output_files, nb_output_files);
+    of = av_mallocz(sizeof(*of));
+    if (!of)
+        exit_program(1);
+    output_files[nb_output_files - 1] = of;
+
+    of->ost_index      = nb_output_streams;
+    of->recording_time = o->recording_time;
+    of->start_time     = o->start_time;
+    of->limit_filesize = o->limit_filesize;
+    of->shortest       = o->shortest;
+    av_dict_copy(&of->opts, o->g->format_opts, 0);
+
+    if (!strcmp(filename, "-"))
+        filename = "pipe:";
+
+    err = avformat_alloc_output_context2(&oc, NULL, o->format, filename);
+    if (!oc) {
+        print_error(filename, err);
+        exit_program(1);
+    }
+
+    of->ctx = oc;
+    if (o->recording_time != INT64_MAX)
+        oc->duration = o->recording_time;
+
+    oc->interrupt_callback = int_cb;
+
+    e = av_dict_get(o->g->format_opts, "fflags", NULL, 0);
+    if (e) {
+        const AVOption *o = av_opt_find(oc, "fflags", NULL, 0, 0);
+        av_opt_eval_flags(oc, o, e->value, &format_flags);
+    }
+    if (o->bitexact) {
+        format_flags |= AVFMT_FLAG_BITEXACT;
+        oc->flags    |= AVFMT_FLAG_BITEXACT;
+    }
+
+    /* create streams for all unlabeled output pads */
+    for (i = 0; i < nb_filtergraphs; i++) {
+        FilterGraph *fg = filtergraphs[i];
+        for (j = 0; j < fg->nb_outputs; j++) {
+            OutputFilter *ofilter = fg->outputs[j];
+
+            if (!ofilter->out_tmp || ofilter->out_tmp->name)
+                continue;
+
+            switch (ofilter->type) {
+            case AVMEDIA_TYPE_VIDEO:    o->video_disable    = 1; break;
+            case AVMEDIA_TYPE_AUDIO:    o->audio_disable    = 1; break;
+            case AVMEDIA_TYPE_SUBTITLE: o->subtitle_disable = 1; break;
+            }
+            init_output_filter(ofilter, o, oc);
+        }
+    }
+
+    if (!o->nb_stream_maps) {
+        char *subtitle_codec_name = NULL;
+        /* pick the "best" stream of each type */
+
+        /* video: highest resolution */
+        if (!o->video_disable && av_guess_codec(oc->oformat, NULL, filename, NULL, AVMEDIA_TYPE_VIDEO) != AV_CODEC_ID_NONE) {
+            int best_score = 0, idx = -1;
+            int qcr = avformat_query_codec(oc->oformat, oc->oformat->video_codec, 0);
+            for (i = 0; i < nb_input_streams; i++) {
+                int score;
+                ist = input_streams[i];
+                score = ist->st->codecpar->width * ist->st->codecpar->height
+                           + 100000000 * !!(ist->st->event_flags & AVSTREAM_EVENT_FLAG_NEW_PACKETS)
+                           + 5000000*!!(ist->st->disposition & AV_DISPOSITION_DEFAULT);
+                if (ist->user_set_discard == AVDISCARD_ALL)
+                    continue;
+                if((qcr!=MKTAG('A', 'P', 'I', 'C')) && (ist->st->disposition & AV_DISPOSITION_ATTACHED_PIC))
+                    score = 1;
+                if (ist->st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO &&
+                    score > best_score) {
+                    if((qcr==MKTAG('A', 'P', 'I', 'C')) && !(ist->st->disposition & AV_DISPOSITION_ATTACHED_PIC))
+                        continue;
+                    best_score = score;
+                    idx = i;
+                }
+            }
+            if (idx >= 0)
+                new_video_stream(o, oc, idx);
+        }
+
+        /* audio: most channels */
+        if (!o->audio_disable && av_guess_codec(oc->oformat, NULL, filename, NULL, AVMEDIA_TYPE_AUDIO) != AV_CODEC_ID_NONE) {
+            int best_score = 0, idx = -1;
+            for (i = 0; i < nb_input_streams; i++) {
+                int score;
+                ist = input_streams[i];
+                score = ist->st->codecpar->channels + 100000000*!!ist->st->codec_info_nb_frames
+                        + 5000000*!!(ist->st->disposition & AV_DISPOSITION_DEFAULT);
+                if (ist->user_set_discard == AVDISCARD_ALL)
+                    continue;
+                if (ist->st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO &&
+                    score > best_score) {
+                    best_score = score;
+                    idx = i;
+                }
+            }
+            if (idx >= 0)
+                new_audio_stream(o, oc, idx);
+        }
+
+        /* subtitles: pick first */
+        MATCH_PER_TYPE_OPT(codec_names, str, subtitle_codec_name, oc, "s");
+        if (!o->subtitle_disable && (avcodec_find_encoder(oc->oformat->subtitle_codec) || subtitle_codec_name)) {
+            for (i = 0; i < nb_input_streams; i++)
+                if (input_streams[i]->st->codecpar->codec_type == AVMEDIA_TYPE_SUBTITLE) {
+                    AVCodecDescriptor const *input_descriptor =
+                        avcodec_descriptor_get(input_streams[i]->st->codecpar->codec_id);
+                    AVCodecDescriptor const *output_descriptor = NULL;
+                    AVCodec const *output_codec =
+                        avcodec_find_encoder(oc->oformat->subtitle_codec);
+                    int input_props = 0, output_props = 0;
+                    if (input_streams[i]->user_set_discard == AVDISCARD_ALL)
+                        continue;
+                    if (output_codec)
+                        output_descriptor = avcodec_descriptor_get(output_codec->id);
+                    if (input_descriptor)
+                        input_props = input_descriptor->props & (AV_CODEC_PROP_TEXT_SUB | AV_CODEC_PROP_BITMAP_SUB);
+                    if (output_descriptor)
+                        output_props = output_descriptor->props & (AV_CODEC_PROP_TEXT_SUB | AV_CODEC_PROP_BITMAP_SUB);
+                    if (subtitle_codec_name ||
+                        input_props & output_props ||
+                        // Map dvb teletext which has neither property to any output subtitle encoder
+                        input_descriptor && output_descriptor &&
+                        (!input_descriptor->props ||
+                         !output_descriptor->props)) {
+                        new_subtitle_stream(o, oc, i);
+                        break;
+                    }
+                }
+        }
+        /* Data only if codec id match */
+        if (!o->data_disable ) {
+            enum AVCodecID codec_id = av_guess_codec(oc->oformat, NULL, filename, NULL, AVMEDIA_TYPE_DATA);
+            for (i = 0; codec_id != AV_CODEC_ID_NONE && i < nb_input_streams; i++) {
+                if (input_streams[i]->user_set_discard == AVDISCARD_ALL)
+                    continue;
+                if (input_streams[i]->st->codecpar->codec_type == AVMEDIA_TYPE_DATA
+                    && input_streams[i]->st->codecpar->codec_id == codec_id )
+                    new_data_stream(o, oc, i);
+            }
+        }
+    } else {
+        for (i = 0; i < o->nb_stream_maps; i++) {
+            StreamMap *map = &o->stream_maps[i];
+
+            if (map->disabled)
+                continue;
+
+            if (map->linklabel) {
+                FilterGraph *fg;
+                OutputFilter *ofilter = NULL;
+                int j, k;
+
+                for (j = 0; j < nb_filtergraphs; j++) {
+                    fg = filtergraphs[j];
+                    for (k = 0; k < fg->nb_outputs; k++) {
+                        AVFilterInOut *out = fg->outputs[k]->out_tmp;
+                        if (out && !strcmp(out->name, map->linklabel)) {
+                            ofilter = fg->outputs[k];
+                            goto loop_end;
+                        }
+                    }
+                }
+loop_end:
+                if (!ofilter) {
+                    av_log(NULL, AV_LOG_FATAL, "Output with label '%s' does not exist "
+                           "in any defined filter graph, or was already used elsewhere.\n", map->linklabel);
+                    exit_program(1);
+                }
+                init_output_filter(ofilter, o, oc);
+            } else {
+                int src_idx = input_files[map->file_index]->ist_index + map->stream_index;
+
+                ist = input_streams[input_files[map->file_index]->ist_index + map->stream_index];
+                if (ist->user_set_discard == AVDISCARD_ALL) {
+                    av_log(NULL, AV_LOG_FATAL, "Stream #%d:%d is disabled and cannot be mapped.\n",
+                           map->file_index, map->stream_index);
+                    exit_program(1);
+                }
+                if(o->subtitle_disable && ist->st->codecpar->codec_type == AVMEDIA_TYPE_SUBTITLE)
+                    continue;
+                if(o->   audio_disable && ist->st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO)
+                    continue;
+                if(o->   video_disable && ist->st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO)
+                    continue;
+                if(o->    data_disable && ist->st->codecpar->codec_type == AVMEDIA_TYPE_DATA)
+                    continue;
+
+                ost = NULL;
+                switch (ist->st->codecpar->codec_type) {
+                case AVMEDIA_TYPE_VIDEO:      ost = new_video_stream     (o, oc, src_idx); break;
+                case AVMEDIA_TYPE_AUDIO:      ost = new_audio_stream     (o, oc, src_idx); break;
+                case AVMEDIA_TYPE_SUBTITLE:   ost = new_subtitle_stream  (o, oc, src_idx); break;
+                case AVMEDIA_TYPE_DATA:       ost = new_data_stream      (o, oc, src_idx); break;
+                case AVMEDIA_TYPE_ATTACHMENT: ost = new_attachment_stream(o, oc, src_idx); break;
+                case AVMEDIA_TYPE_UNKNOWN:
+                    if (copy_unknown_streams) {
+                        ost = new_unknown_stream   (o, oc, src_idx);
+                        break;
+                    }
+                default:
+                    av_log(NULL, ignore_unknown_streams ? AV_LOG_WARNING : AV_LOG_FATAL,
+                           "Cannot map stream #%d:%d - unsupported type.\n",
+                           map->file_index, map->stream_index);
+                    if (!ignore_unknown_streams) {
+                        av_log(NULL, AV_LOG_FATAL,
+                               "If you want unsupported types ignored instead "
+                               "of failing, please use the -ignore_unknown option\n"
+                               "If you want them copied, please use -copy_unknown\n");
+                        exit_program(1);
+                    }
+                }
+                if (ost)
+                    ost->sync_ist = input_streams[  input_files[map->sync_file_index]->ist_index
+                                                  + map->sync_stream_index];
+            }
+        }
+    }
+
+    /* handle attached files */
+    for (i = 0; i < o->nb_attachments; i++) {
+        AVIOContext *pb;
+        uint8_t *attachment;
+        const char *p;
+        int64_t len;
+
+        if ((err = avio_open2(&pb, o->attachments[i], AVIO_FLAG_READ, &int_cb, NULL)) < 0) {
+            av_log(NULL, AV_LOG_FATAL, "Could not open attachment file %s.\n",
+                   o->attachments[i]);
+            exit_program(1);
+        }
+        if ((len = avio_size(pb)) <= 0) {
+            av_log(NULL, AV_LOG_FATAL, "Could not get size of the attachment %s.\n",
+                   o->attachments[i]);
+            exit_program(1);
+        }
+        if (len > INT_MAX - AV_INPUT_BUFFER_PADDING_SIZE ||
+            !(attachment = av_malloc(len + AV_INPUT_BUFFER_PADDING_SIZE))) {
+            av_log(NULL, AV_LOG_FATAL, "Attachment %s too large.\n",
+                   o->attachments[i]);
+            exit_program(1);
+        }
+        avio_read(pb, attachment, len);
+        memset(attachment + len, 0, AV_INPUT_BUFFER_PADDING_SIZE);
+
+        ost = new_attachment_stream(o, oc, -1);
+        ost->stream_copy               = 0;
+        ost->attachment_filename       = o->attachments[i];
+        ost->st->codecpar->extradata      = attachment;
+        ost->st->codecpar->extradata_size = len;
+
+        p = strrchr(o->attachments[i], '/');
+        av_dict_set(&ost->st->metadata, "filename", (p && *p) ? p + 1 : o->attachments[i], AV_DICT_DONT_OVERWRITE);
+        avio_closep(&pb);
+    }
+
+#if FF_API_LAVF_AVCTX
+    for (i = nb_output_streams - oc->nb_streams; i < nb_output_streams; i++) { //for all streams of this output file
+        AVDictionaryEntry *e;
+        ost = output_streams[i];
+
+        if ((ost->stream_copy || ost->attachment_filename)
+            && (e = av_dict_get(o->g->codec_opts, "flags", NULL, AV_DICT_IGNORE_SUFFIX))
+            && (!e->key[5] || check_stream_specifier(oc, ost->st, e->key+6)))
+            if (av_opt_set(ost->st->codec, "flags", e->value, 0) < 0)
+                exit_program(1);
+    }
+#endif
+
+    if (!oc->nb_streams && !(oc->oformat->flags & AVFMT_NOSTREAMS)) {
+        av_dump_format(oc, nb_output_files - 1, oc->url, 1);
+        av_log(NULL, AV_LOG_ERROR, "Output file #%d does not contain any stream\n", nb_output_files - 1);
+        exit_program(1);
+    }
+
+    /* check if all codec options have been used */
+    unused_opts = strip_specifiers(o->g->codec_opts);
+    for (i = of->ost_index; i < nb_output_streams; i++) {
+        e = NULL;
+        while ((e = av_dict_get(output_streams[i]->encoder_opts, "", e,
+                                AV_DICT_IGNORE_SUFFIX)))
+            av_dict_set(&unused_opts, e->key, NULL, 0);
+    }
+
+    e = NULL;
+    while ((e = av_dict_get(unused_opts, "", e, AV_DICT_IGNORE_SUFFIX))) {
+        const AVClass *class = avcodec_get_class();
+        const AVOption *option = av_opt_find(&class, e->key, NULL, 0,
+                                             AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ);
+        const AVClass *fclass = avformat_get_class();
+        const AVOption *foption = av_opt_find(&fclass, e->key, NULL, 0,
+                                              AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ);
+        if (!option || foption)
+            continue;
+
+
+        if (!(option->flags & AV_OPT_FLAG_ENCODING_PARAM)) {
+            av_log(NULL, AV_LOG_ERROR, "Codec AVOption %s (%s) specified for "
+                   "output file #%d (%s) is not an encoding option.\n", e->key,
+                   option->help ? option->help : "", nb_output_files - 1,
+                   filename);
+            exit_program(1);
+        }
+
+        // gop_timecode is injected by generic code but not always used
+        if (!strcmp(e->key, "gop_timecode"))
+            continue;
+
+        av_log(NULL, AV_LOG_WARNING, "Codec AVOption %s (%s) specified for "
+               "output file #%d (%s) has not been used for any stream. The most "
+               "likely reason is either wrong type (e.g. a video option with "
+               "no video streams) or that it is a private option of some encoder "
+               "which was not actually used for any stream.\n", e->key,
+               option->help ? option->help : "", nb_output_files - 1, filename);
+    }
+    av_dict_free(&unused_opts);
+
+    /* set the decoding_needed flags and create simple filtergraphs */
+    for (i = of->ost_index; i < nb_output_streams; i++) {
+        OutputStream *ost = output_streams[i];
+
+        if (ost->encoding_needed && ost->source_index >= 0) {
+            InputStream *ist = input_streams[ost->source_index];
+            ist->decoding_needed |= DECODING_FOR_OST;
+
+            if (ost->st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO ||
+                ost->st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {
+                err = init_simple_filtergraph(ist, ost);
+                if (err < 0) {
+                    av_log(NULL, AV_LOG_ERROR,
+                           "Error initializing a simple filtergraph between streams "
+                           "%d:%d->%d:%d\n", ist->file_index, ost->source_index,
+                           nb_output_files - 1, ost->st->index);
+                    exit_program(1);
+                }
+            }
+        }
+
+        /* set the filter output constraints */
+        if (ost->filter) {
+            OutputFilter *f = ost->filter;
+            int count;
+            switch (ost->enc_ctx->codec_type) {
+            case AVMEDIA_TYPE_VIDEO:
+                f->frame_rate = ost->frame_rate;
+                f->width      = ost->enc_ctx->width;
+                f->height     = ost->enc_ctx->height;
+                if (ost->enc_ctx->pix_fmt != AV_PIX_FMT_NONE) {
+                    f->format = ost->enc_ctx->pix_fmt;
+                } else if (ost->enc->pix_fmts) {
+                    count = 0;
+                    while (ost->enc->pix_fmts[count] != AV_PIX_FMT_NONE)
+                        count++;
+                    f->formats = av_mallocz_array(count + 1, sizeof(*f->formats));
+                    if (!f->formats)
+                        exit_program(1);
+                    memcpy(f->formats, ost->enc->pix_fmts, (count + 1) * sizeof(*f->formats));
+                }
+                break;
+            case AVMEDIA_TYPE_AUDIO:
+                if (ost->enc_ctx->sample_fmt != AV_SAMPLE_FMT_NONE) {
+                    f->format = ost->enc_ctx->sample_fmt;
+                } else if (ost->enc->sample_fmts) {
+                    count = 0;
+                    while (ost->enc->sample_fmts[count] != AV_SAMPLE_FMT_NONE)
+                        count++;
+                    f->formats = av_mallocz_array(count + 1, sizeof(*f->formats));
+                    if (!f->formats)
+                        exit_program(1);
+                    memcpy(f->formats, ost->enc->sample_fmts, (count + 1) * sizeof(*f->formats));
+                }
+                if (ost->enc_ctx->sample_rate) {
+                    f->sample_rate = ost->enc_ctx->sample_rate;
+                } else if (ost->enc->supported_samplerates) {
+                    count = 0;
+                    while (ost->enc->supported_samplerates[count])
+                        count++;
+                    f->sample_rates = av_mallocz_array(count + 1, sizeof(*f->sample_rates));
+                    if (!f->sample_rates)
+                        exit_program(1);
+                    memcpy(f->sample_rates, ost->enc->supported_samplerates,
+                           (count + 1) * sizeof(*f->sample_rates));
+                }
+                if (ost->enc_ctx->channels) {
+                    f->channel_layout = av_get_default_channel_layout(ost->enc_ctx->channels);
+                } else if (ost->enc->channel_layouts) {
+                    count = 0;
+                    while (ost->enc->channel_layouts[count])
+                        count++;
+                    f->channel_layouts = av_mallocz_array(count + 1, sizeof(*f->channel_layouts));
+                    if (!f->channel_layouts)
+                        exit_program(1);
+                    memcpy(f->channel_layouts, ost->enc->channel_layouts,
+                           (count + 1) * sizeof(*f->channel_layouts));
+                }
+                break;
+            }
+        }
+    }
+
+    /* check filename in case of an image number is expected */
+    if (oc->oformat->flags & AVFMT_NEEDNUMBER) {
+        if (!av_filename_number_test(oc->url)) {
+            print_error(oc->url, AVERROR(EINVAL));
+            exit_program(1);
+        }
+    }
+
+    if (!(oc->oformat->flags & AVFMT_NOSTREAMS) && !input_stream_potentially_available) {
+        av_log(NULL, AV_LOG_ERROR,
+               "No input streams but output needs an input stream\n");
+        exit_program(1);
+    }
+
+    if (!(oc->oformat->flags & AVFMT_NOFILE)) {
+        /* test if it already exists to avoid losing precious files */
+        assert_file_overwrite(filename);
+
+        /* open the file */
+        if ((err = avio_open2(&oc->pb, filename, AVIO_FLAG_WRITE,
+                              &oc->interrupt_callback,
+                              &of->opts)) < 0) {
+            print_error(filename, err);
+            exit_program(1);
+        }
+    } else if (strcmp(oc->oformat->name, "image2")==0 && !av_filename_number_test(filename))
+        assert_file_overwrite(filename);
+
+    if (o->mux_preload) {
+        av_dict_set_int(&of->opts, "preload", o->mux_preload*AV_TIME_BASE, 0);
+    }
+    oc->max_delay = (int)(o->mux_max_delay * AV_TIME_BASE);
+
+    /* copy metadata */
+    for (i = 0; i < o->nb_metadata_map; i++) {
+        char *p;
+        int in_file_index = strtol(o->metadata_map[i].u.str, &p, 0);
+
+        if (in_file_index >= nb_input_files) {
+            av_log(NULL, AV_LOG_FATAL, "Invalid input file index %d while processing metadata maps\n", in_file_index);
+            exit_program(1);
+        }
+        copy_metadata(o->metadata_map[i].specifier, *p ? p + 1 : p, oc,
+                      in_file_index >= 0 ?
+                      input_files[in_file_index]->ctx : NULL, o);
+    }
+
+    /* copy chapters */
+    if (o->chapters_input_file >= nb_input_files) {
+        if (o->chapters_input_file == INT_MAX) {
+            /* copy chapters from the first input file that has them*/
+            o->chapters_input_file = -1;
+            for (i = 0; i < nb_input_files; i++)
+                if (input_files[i]->ctx->nb_chapters) {
+                    o->chapters_input_file = i;
+                    break;
+                }
+        } else {
+            av_log(NULL, AV_LOG_FATAL, "Invalid input file index %d in chapter mapping.\n",
+                   o->chapters_input_file);
+            exit_program(1);
+        }
+    }
+    if (o->chapters_input_file >= 0)
+        copy_chapters(input_files[o->chapters_input_file], of,
+                      !o->metadata_chapters_manual);
+
+    /* copy global metadata by default */
+    if (!o->metadata_global_manual && nb_input_files){
+        av_dict_copy(&oc->metadata, input_files[0]->ctx->metadata,
+                     AV_DICT_DONT_OVERWRITE);
+        if(o->recording_time != INT64_MAX)
+            av_dict_set(&oc->metadata, "duration", NULL, 0);
+        av_dict_set(&oc->metadata, "creation_time", NULL, 0);
+        av_dict_set(&oc->metadata, "company_name", NULL, 0);
+        av_dict_set(&oc->metadata, "product_name", NULL, 0);
+        av_dict_set(&oc->metadata, "product_version", NULL, 0);
+    }
+    if (!o->metadata_streams_manual)
+        for (i = of->ost_index; i < nb_output_streams; i++) {
+            InputStream *ist;
+            if (output_streams[i]->source_index < 0)         /* this is true e.g. for attached files */
+                continue;
+            ist = input_streams[output_streams[i]->source_index];
+            av_dict_copy(&output_streams[i]->st->metadata, ist->st->metadata, AV_DICT_DONT_OVERWRITE);
+            if (!output_streams[i]->stream_copy) {
+                av_dict_set(&output_streams[i]->st->metadata, "encoder", NULL, 0);
+            }
+        }
+
+    /* process manually set programs */
+    for (i = 0; i < o->nb_program; i++) {
+        const char *p = o->program[i].u.str;
+        int progid = i+1;
+        AVProgram *program;
+
+        while(*p) {
+            const char *p2 = av_get_token(&p, ":");
+            const char *to_dealloc = p2;
+            char *key;
+            if (!p2)
+                break;
+
+            if(*p) p++;
+
+            key = av_get_token(&p2, "=");
+            if (!key || !*p2) {
+                av_freep(&to_dealloc);
+                av_freep(&key);
+                break;
+            }
+            p2++;
+
+            if (!strcmp(key, "program_num"))
+                progid = strtol(p2, NULL, 0);
+            av_freep(&to_dealloc);
+            av_freep(&key);
+        }
+
+        program = av_new_program(oc, progid);
+
+        p = o->program[i].u.str;
+        while(*p) {
+            const char *p2 = av_get_token(&p, ":");
+            const char *to_dealloc = p2;
+            char *key;
+            if (!p2)
+                break;
+            if(*p) p++;
+
+            key = av_get_token(&p2, "=");
+            if (!key) {
+                av_log(NULL, AV_LOG_FATAL,
+                       "No '=' character in program string %s.\n",
+                       p2);
+                exit_program(1);
+            }
+            if (!*p2)
+                exit_program(1);
+            p2++;
+
+            if (!strcmp(key, "title")) {
+                av_dict_set(&program->metadata, "title", p2, 0);
+            } else if (!strcmp(key, "program_num")) {
+            } else if (!strcmp(key, "st")) {
+                int st_num = strtol(p2, NULL, 0);
+                av_program_add_stream_index(oc, progid, st_num);
+            } else {
+                av_log(NULL, AV_LOG_FATAL, "Unknown program key %s.\n", key);
+                exit_program(1);
+            }
+            av_freep(&to_dealloc);
+            av_freep(&key);
+        }
+    }
+
+    /* process manually set metadata */
+    for (i = 0; i < o->nb_metadata; i++) {
+        AVDictionary **m;
+        char type, *val;
+        const char *stream_spec;
+        int index = 0, j, ret = 0;
+
+        val = strchr(o->metadata[i].u.str, '=');
+        if (!val) {
+            av_log(NULL, AV_LOG_FATAL, "No '=' character in metadata string %s.\n",
+                   o->metadata[i].u.str);
+            exit_program(1);
+        }
+        *val++ = 0;
+
+        parse_meta_type(o->metadata[i].specifier, &type, &index, &stream_spec);
+        if (type == 's') {
+            for (j = 0; j < oc->nb_streams; j++) {
+                ost = output_streams[nb_output_streams - oc->nb_streams + j];
+                if ((ret = check_stream_specifier(oc, oc->streams[j], stream_spec)) > 0) {
+                    if (!strcmp(o->metadata[i].u.str, "rotate")) {
+                        char *tail;
+                        double theta = av_strtod(val, &tail);
+                        if (!*tail) {
+                            ost->rotate_overridden = 1;
+                            ost->rotate_override_value = theta;
+                        }
+                    } else {
+                        av_dict_set(&oc->streams[j]->metadata, o->metadata[i].u.str, *val ? val : NULL, 0);
+                    }
+                } else if (ret < 0)
+                    exit_program(1);
+            }
+        }
+        else {
+            switch (type) {
+            case 'g':
+                m = &oc->metadata;
+                break;
+            case 'c':
+                if (index < 0 || index >= oc->nb_chapters) {
+                    av_log(NULL, AV_LOG_FATAL, "Invalid chapter index %d in metadata specifier.\n", index);
+                    exit_program(1);
+                }
+                m = &oc->chapters[index]->metadata;
+                break;
+            case 'p':
+                if (index < 0 || index >= oc->nb_programs) {
+                    av_log(NULL, AV_LOG_FATAL, "Invalid program index %d in metadata specifier.\n", index);
+                    exit_program(1);
+                }
+                m = &oc->programs[index]->metadata;
+                break;
+            default:
+                av_log(NULL, AV_LOG_FATAL, "Invalid metadata specifier %s.\n", o->metadata[i].specifier);
+                exit_program(1);
+            }
+            av_dict_set(m, o->metadata[i].u.str, *val ? val : NULL, 0);
+        }
+    }
+
+    return 0;
+}
+
+static int opt_target(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    enum { PAL, NTSC, FILM, UNKNOWN } norm = UNKNOWN;
+    static const char *const frame_rates[] = { "25", "30000/1001", "24000/1001" };
+
+    if (!strncmp(arg, "pal-", 4)) {
+        norm = PAL;
+        arg += 4;
+    } else if (!strncmp(arg, "ntsc-", 5)) {
+        norm = NTSC;
+        arg += 5;
+    } else if (!strncmp(arg, "film-", 5)) {
+        norm = FILM;
+        arg += 5;
+    } else {
+        /* Try to determine PAL/NTSC by peeking in the input files */
+        if (nb_input_files) {
+            int i, j;
+            for (j = 0; j < nb_input_files; j++) {
+                for (i = 0; i < input_files[j]->nb_streams; i++) {
+                    AVStream *st = input_files[j]->ctx->streams[i];
+                    int64_t fr;
+                    if (st->codecpar->codec_type != AVMEDIA_TYPE_VIDEO)
+                        continue;
+                    fr = st->time_base.den * 1000LL / st->time_base.num;
+                    if (fr == 25000) {
+                        norm = PAL;
+                        break;
+                    } else if ((fr == 29970) || (fr == 23976)) {
+                        norm = NTSC;
+                        break;
+                    }
+                }
+                if (norm != UNKNOWN)
+                    break;
+            }
+        }
+        if (norm != UNKNOWN)
+            av_log(NULL, AV_LOG_INFO, "Assuming %s for target.\n", norm == PAL ? "PAL" : "NTSC");
+    }
+
+    if (norm == UNKNOWN) {
+        av_log(NULL, AV_LOG_FATAL, "Could not determine norm (PAL/NTSC/NTSC-Film) for target.\n");
+        av_log(NULL, AV_LOG_FATAL, "Please prefix target with \"pal-\", \"ntsc-\" or \"film-\",\n");
+        av_log(NULL, AV_LOG_FATAL, "or set a framerate with \"-r xxx\".\n");
+        exit_program(1);
+    }
+
+    if (!strcmp(arg, "vcd")) {
+        opt_video_codec(o, "c:v", "mpeg1video");
+        opt_audio_codec(o, "c:a", "mp2");
+        parse_option(o, "f", "vcd", options);
+
+        parse_option(o, "s", norm == PAL ? "352x288" : "352x240", options);
+        parse_option(o, "r", frame_rates[norm], options);
+        opt_default(NULL, "g", norm == PAL ? "15" : "18");
+
+        opt_default(NULL, "b:v", "1150000");
+        opt_default(NULL, "maxrate:v", "1150000");
+        opt_default(NULL, "minrate:v", "1150000");
+        opt_default(NULL, "bufsize:v", "327680"); // 40*1024*8;
+
+        opt_default(NULL, "b:a", "224000");
+        parse_option(o, "ar", "44100", options);
+        parse_option(o, "ac", "2", options);
+
+        opt_default(NULL, "packetsize", "2324");
+        opt_default(NULL, "muxrate", "1411200"); // 2352 * 75 * 8;
+
+        /* We have to offset the PTS, so that it is consistent with the SCR.
+           SCR starts at 36000, but the first two packs contain only padding
+           and the first pack from the other stream, respectively, may also have
+           been written before.
+           So the real data starts at SCR 36000+3*1200. */
+        o->mux_preload = (36000 + 3 * 1200) / 90000.0; // 0.44
+    } else if (!strcmp(arg, "svcd")) {
+
+        opt_video_codec(o, "c:v", "mpeg2video");
+        opt_audio_codec(o, "c:a", "mp2");
+        parse_option(o, "f", "svcd", options);
+
+        parse_option(o, "s", norm == PAL ? "480x576" : "480x480", options);
+        parse_option(o, "r", frame_rates[norm], options);
+        parse_option(o, "pix_fmt", "yuv420p", options);
+        opt_default(NULL, "g", norm == PAL ? "15" : "18");
+
+        opt_default(NULL, "b:v", "2040000");
+        opt_default(NULL, "maxrate:v", "2516000");
+        opt_default(NULL, "minrate:v", "0"); // 1145000;
+        opt_default(NULL, "bufsize:v", "1835008"); // 224*1024*8;
+        opt_default(NULL, "scan_offset", "1");
+
+        opt_default(NULL, "b:a", "224000");
+        parse_option(o, "ar", "44100", options);
+
+        opt_default(NULL, "packetsize", "2324");
+
+    } else if (!strcmp(arg, "dvd")) {
+
+        opt_video_codec(o, "c:v", "mpeg2video");
+        opt_audio_codec(o, "c:a", "ac3");
+        parse_option(o, "f", "dvd", options);
+
+        parse_option(o, "s", norm == PAL ? "720x576" : "720x480", options);
+        parse_option(o, "r", frame_rates[norm], options);
+        parse_option(o, "pix_fmt", "yuv420p", options);
+        opt_default(NULL, "g", norm == PAL ? "15" : "18");
+
+        opt_default(NULL, "b:v", "6000000");
+        opt_default(NULL, "maxrate:v", "9000000");
+        opt_default(NULL, "minrate:v", "0"); // 1500000;
+        opt_default(NULL, "bufsize:v", "1835008"); // 224*1024*8;
+
+        opt_default(NULL, "packetsize", "2048");  // from www.mpucoder.com: DVD sectors contain 2048 bytes of data, this is also the size of one pack.
+        opt_default(NULL, "muxrate", "10080000"); // from mplex project: data_rate = 1260000. mux_rate = data_rate * 8
+
+        opt_default(NULL, "b:a", "448000");
+        parse_option(o, "ar", "48000", options);
+
+    } else if (!strncmp(arg, "dv", 2)) {
+
+        parse_option(o, "f", "dv", options);
+
+        parse_option(o, "s", norm == PAL ? "720x576" : "720x480", options);
+        parse_option(o, "pix_fmt", !strncmp(arg, "dv50", 4) ? "yuv422p" :
+                          norm == PAL ? "yuv420p" : "yuv411p", options);
+        parse_option(o, "r", frame_rates[norm], options);
+
+        parse_option(o, "ar", "48000", options);
+        parse_option(o, "ac", "2", options);
+
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "Unknown target: %s\n", arg);
+        return AVERROR(EINVAL);
+    }
+
+    av_dict_copy(&o->g->codec_opts,  codec_opts, AV_DICT_DONT_OVERWRITE);
+    av_dict_copy(&o->g->format_opts, format_opts, AV_DICT_DONT_OVERWRITE);
+
+    return 0;
+}
+
+static int opt_vstats_file(void *optctx, const char *opt, const char *arg)
+{
+    av_free (vstats_filename);
+    vstats_filename = av_strdup (arg);
+    return 0;
+}
+
+static int opt_vstats(void *optctx, const char *opt, const char *arg)
+{
+    char filename[40];
+    time_t today2 = time(NULL);
+    struct tm *today = localtime(&today2);
+
+    if (!today) { // maybe tomorrow
+        av_log(NULL, AV_LOG_FATAL, "Unable to get current time: %s\n", strerror(errno));
+        exit_program(1);
+    }
+
+    snprintf(filename, sizeof(filename), "vstats_%02d%02d%02d.log", today->tm_hour, today->tm_min,
+             today->tm_sec);
+    return opt_vstats_file(NULL, opt, filename);
+}
+
+static int opt_video_frames(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "frames:v", arg, options);
+}
+
+static int opt_audio_frames(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "frames:a", arg, options);
+}
+
+static int opt_data_frames(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "frames:d", arg, options);
+}
+
+static int opt_default_new(OptionsContext *o, const char *opt, const char *arg)
+{
+    int ret;
+    AVDictionary *cbak = codec_opts;
+    AVDictionary *fbak = format_opts;
+    codec_opts = NULL;
+    format_opts = NULL;
+
+    ret = opt_default(NULL, opt, arg);
+
+    av_dict_copy(&o->g->codec_opts , codec_opts, 0);
+    av_dict_copy(&o->g->format_opts, format_opts, 0);
+    av_dict_free(&codec_opts);
+    av_dict_free(&format_opts);
+    codec_opts = cbak;
+    format_opts = fbak;
+
+    return ret;
+}
+
+static int opt_preset(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    FILE *f=NULL;
+    char filename[1000], line[1000], tmp_line[1000];
+    const char *codec_name = NULL;
+
+    tmp_line[0] = *opt;
+    tmp_line[1] = 0;
+    MATCH_PER_TYPE_OPT(codec_names, str, codec_name, NULL, tmp_line);
+
+    if (!(f = get_preset_file(filename, sizeof(filename), arg, *opt == 'f', codec_name))) {
+        if(!strncmp(arg, "libx264-lossless", strlen("libx264-lossless"))){
+            av_log(NULL, AV_LOG_FATAL, "Please use -preset <speed> -qp 0\n");
+        }else
+            av_log(NULL, AV_LOG_FATAL, "File for preset '%s' not found\n", arg);
+        exit_program(1);
+    }
+
+    while (fgets(line, sizeof(line), f)) {
+        char *key = tmp_line, *value, *endptr;
+
+        if (strcspn(line, "#\n\r") == 0)
+            continue;
+        av_strlcpy(tmp_line, line, sizeof(tmp_line));
+        if (!av_strtok(key,   "=",    &value) ||
+            !av_strtok(value, "\r\n", &endptr)) {
+            av_log(NULL, AV_LOG_FATAL, "%s: Invalid syntax: '%s'\n", filename, line);
+            exit_program(1);
+        }
+        av_log(NULL, AV_LOG_DEBUG, "ffpreset[%s]: set '%s' = '%s'\n", filename, key, value);
+
+        if      (!strcmp(key, "acodec")) opt_audio_codec   (o, key, value);
+        else if (!strcmp(key, "vcodec")) opt_video_codec   (o, key, value);
+        else if (!strcmp(key, "scodec")) opt_subtitle_codec(o, key, value);
+        else if (!strcmp(key, "dcodec")) opt_data_codec    (o, key, value);
+        else if (opt_default_new(o, key, value) < 0) {
+            av_log(NULL, AV_LOG_FATAL, "%s: Invalid option or argument: '%s', parsed as '%s' = '%s'\n",
+                   filename, line, key, value);
+            exit_program(1);
+        }
+    }
+
+    fclose(f);
+
+    return 0;
+}
+
+static int opt_old2new(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    int ret;
+    char *s = av_asprintf("%s:%c", opt + 1, *opt);
+    if (!s)
+        return AVERROR(ENOMEM);
+    ret = parse_option(o, s, arg, options);
+    av_free(s);
+    return ret;
+}
+
+static int opt_bitrate(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+
+    if(!strcmp(opt, "ab")){
+        av_dict_set(&o->g->codec_opts, "b:a", arg, 0);
+        return 0;
+    } else if(!strcmp(opt, "b")){
+        av_log(NULL, AV_LOG_WARNING, "Please use -b:a or -b:v, -b is ambiguous\n");
+        av_dict_set(&o->g->codec_opts, "b:v", arg, 0);
+        return 0;
+    }
+    av_dict_set(&o->g->codec_opts, opt, arg, 0);
+    return 0;
+}
+
+static int opt_qscale(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    char *s;
+    int ret;
+    if(!strcmp(opt, "qscale")){
+        av_log(NULL, AV_LOG_WARNING, "Please use -q:a or -q:v, -qscale is ambiguous\n");
+        return parse_option(o, "q:v", arg, options);
+    }
+    s = av_asprintf("q%s", opt + 6);
+    if (!s)
+        return AVERROR(ENOMEM);
+    ret = parse_option(o, s, arg, options);
+    av_free(s);
+    return ret;
+}
+
+static int opt_profile(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    if(!strcmp(opt, "profile")){
+        av_log(NULL, AV_LOG_WARNING, "Please use -profile:a or -profile:v, -profile is ambiguous\n");
+        av_dict_set(&o->g->codec_opts, "profile:v", arg, 0);
+        return 0;
+    }
+    av_dict_set(&o->g->codec_opts, opt, arg, 0);
+    return 0;
+}
+
+static int opt_video_filters(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "filter:v", arg, options);
+}
+
+static int opt_audio_filters(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "filter:a", arg, options);
+}
+
+static int opt_vsync(void *optctx, const char *opt, const char *arg)
+{
+    if      (!av_strcasecmp(arg, "cfr"))         video_sync_method = VSYNC_CFR;
+    else if (!av_strcasecmp(arg, "vfr"))         video_sync_method = VSYNC_VFR;
+    else if (!av_strcasecmp(arg, "passthrough")) video_sync_method = VSYNC_PASSTHROUGH;
+    else if (!av_strcasecmp(arg, "drop"))        video_sync_method = VSYNC_DROP;
+
+    if (video_sync_method == VSYNC_AUTO)
+        video_sync_method = parse_number_or_die("vsync", arg, OPT_INT, VSYNC_AUTO, VSYNC_VFR);
+    return 0;
+}
+
+static int opt_timecode(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    int ret;
+    char *tcr = av_asprintf("timecode=%s", arg);
+    if (!tcr)
+        return AVERROR(ENOMEM);
+    ret = parse_option(o, "metadata:g", tcr, options);
+    if (ret >= 0)
+        ret = av_dict_set(&o->g->codec_opts, "gop_timecode", arg, 0);
+    av_free(tcr);
+    return ret;
+}
+
+static int opt_channel_layout(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    char layout_str[32];
+    char *stream_str;
+    char *ac_str;
+    int ret, channels, ac_str_size;
+    uint64_t layout;
+
+    layout = av_get_channel_layout(arg);
+    if (!layout) {
+        av_log(NULL, AV_LOG_ERROR, "Unknown channel layout: %s\n", arg);
+        return AVERROR(EINVAL);
+    }
+    snprintf(layout_str, sizeof(layout_str), "%"PRIu64, layout);
+    ret = opt_default_new(o, opt, layout_str);
+    if (ret < 0)
+        return ret;
+
+    /* set 'ac' option based on channel layout */
+    channels = av_get_channel_layout_nb_channels(layout);
+    snprintf(layout_str, sizeof(layout_str), "%d", channels);
+    stream_str = strchr(opt, ':');
+    ac_str_size = 3 + (stream_str ? strlen(stream_str) : 0);
+    ac_str = av_mallocz(ac_str_size);
+    if (!ac_str)
+        return AVERROR(ENOMEM);
+    av_strlcpy(ac_str, "ac", 3);
+    if (stream_str)
+        av_strlcat(ac_str, stream_str, ac_str_size);
+    ret = parse_option(o, ac_str, layout_str, options);
+    av_free(ac_str);
+
+    return ret;
+}
+
+static int opt_audio_qscale(void *optctx, const char *opt, const char *arg)
+{
+    OptionsContext *o = optctx;
+    return parse_option(o, "q:a", arg, options);
+}
+
+static int opt_filter_complex(void *optctx, const char *opt, const char *arg)
+{
+    GROW_ARRAY(filtergraphs, nb_filtergraphs);
+    if (!(filtergraphs[nb_filtergraphs - 1] = av_mallocz(sizeof(*filtergraphs[0]))))
+        return AVERROR(ENOMEM);
+    filtergraphs[nb_filtergraphs - 1]->index      = nb_filtergraphs - 1;
+    filtergraphs[nb_filtergraphs - 1]->graph_desc = av_strdup(arg);
+    if (!filtergraphs[nb_filtergraphs - 1]->graph_desc)
+        return AVERROR(ENOMEM);
+
+    input_stream_potentially_available = 1;
+
+    return 0;
+}
+
+static int opt_filter_complex_script(void *optctx, const char *opt, const char *arg)
+{
+    uint8_t *graph_desc = read_file(arg);
+    if (!graph_desc)
+        return AVERROR(EINVAL);
+
+    GROW_ARRAY(filtergraphs, nb_filtergraphs);
+    if (!(filtergraphs[nb_filtergraphs - 1] = av_mallocz(sizeof(*filtergraphs[0]))))
+        return AVERROR(ENOMEM);
+    filtergraphs[nb_filtergraphs - 1]->index      = nb_filtergraphs - 1;
+    filtergraphs[nb_filtergraphs - 1]->graph_desc = graph_desc;
+
+    input_stream_potentially_available = 1;
+
+    return 0;
+}
+
+void show_help_default(const char *opt, const char *arg)
+{
+    /* per-file options have at least one of those set */
+    const int per_file = OPT_SPEC | OPT_OFFSET | OPT_PERFILE;
+    int show_advanced = 0, show_avoptions = 0;
+
+    if (opt && *opt) {
+        if (!strcmp(opt, "long"))
+            show_advanced = 1;
+        else if (!strcmp(opt, "full"))
+            show_advanced = show_avoptions = 1;
+        else
+            av_log(NULL, AV_LOG_ERROR, "Unknown help option '%s'.\n", opt);
+    }
+
+    show_usage();
+
+    printf("Getting help:\n"
+           "    -h      -- print basic options\n"
+           "    -h long -- print more options\n"
+           "    -h full -- print all options (including all format and codec specific options, very long)\n"
+           "    -h type=name -- print all options for the named decoder/encoder/demuxer/muxer/filter/bsf/protocol\n"
+           "    See man %s for detailed description of the options.\n"
+           "\n", program_name);
+
+    show_help_options(options, "Print help / information / capabilities:",
+                      OPT_EXIT, 0, 0);
+
+    show_help_options(options, "Global options (affect whole program "
+                      "instead of just one file):",
+                      0, per_file | OPT_EXIT | OPT_EXPERT, 0);
+    if (show_advanced)
+        show_help_options(options, "Advanced global options:", OPT_EXPERT,
+                          per_file | OPT_EXIT, 0);
+
+    show_help_options(options, "Per-file main options:", 0,
+                      OPT_EXPERT | OPT_AUDIO | OPT_VIDEO | OPT_SUBTITLE |
+                      OPT_EXIT, per_file);
+    if (show_advanced)
+        show_help_options(options, "Advanced per-file options:",
+                          OPT_EXPERT, OPT_AUDIO | OPT_VIDEO | OPT_SUBTITLE, per_file);
+
+    show_help_options(options, "Video options:",
+                      OPT_VIDEO, OPT_EXPERT | OPT_AUDIO, 0);
+    if (show_advanced)
+        show_help_options(options, "Advanced Video options:",
+                          OPT_EXPERT | OPT_VIDEO, OPT_AUDIO, 0);
+
+    show_help_options(options, "Audio options:",
+                      OPT_AUDIO, OPT_EXPERT | OPT_VIDEO, 0);
+    if (show_advanced)
+        show_help_options(options, "Advanced Audio options:",
+                          OPT_EXPERT | OPT_AUDIO, OPT_VIDEO, 0);
+    show_help_options(options, "Subtitle options:",
+                      OPT_SUBTITLE, 0, 0);
+    printf("\n");
+
+    if (show_avoptions) {
+        int flags = AV_OPT_FLAG_DECODING_PARAM | AV_OPT_FLAG_ENCODING_PARAM;
+        show_help_children(avcodec_get_class(), flags);
+        show_help_children(avformat_get_class(), flags);
+#if CONFIG_SWSCALE
+        show_help_children(sws_get_class(), flags);
+#endif
+#if CONFIG_SWRESAMPLE
+        show_help_children(swr_get_class(), AV_OPT_FLAG_AUDIO_PARAM);
+#endif
+        show_help_children(avfilter_get_class(), AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_AUDIO_PARAM | AV_OPT_FLAG_FILTERING_PARAM);
+        show_help_children(av_bsf_get_class(), AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_AUDIO_PARAM | AV_OPT_FLAG_BSF_PARAM);
+    }
+}
+
+void show_usage(void)
+{
+    av_log(NULL, AV_LOG_INFO, "Hyper fast Audio and Video encoder\n");
+    av_log(NULL, AV_LOG_INFO, "usage: %s [options] [[infile options] -i infile]... {[outfile options] outfile}...\n", program_name);
+    av_log(NULL, AV_LOG_INFO, "\n");
+}
+
+enum OptGroup {
+    GROUP_OUTFILE,
+    GROUP_INFILE,
+};
+
+static const OptionGroupDef groups[] = {
+    [GROUP_OUTFILE] = { "output url",  NULL, OPT_OUTPUT },
+    [GROUP_INFILE]  = { "input url",   "i",  OPT_INPUT },
+};
+
+static int open_files(OptionGroupList *l, const char *inout,
+                      int (*open_file)(OptionsContext*, const char*))
+{
+    int i, ret;
+
+    for (i = 0; i < l->nb_groups; i++) {
+        OptionGroup *g = &l->groups[i];
+        OptionsContext o;
+
+        init_options(&o);
+        o.g = g;
+
+        ret = parse_optgroup(&o, g);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error parsing options for %s file "
+                   "%s.\n", inout, g->arg);
+            uninit_options(&o);
+            return ret;
+        }
+
+        av_log(NULL, AV_LOG_DEBUG, "Opening an %s file: %s.\n", inout, g->arg);
+        ret = open_file(&o, g->arg);
+        uninit_options(&o);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "Error opening %s file %s.\n",
+                   inout, g->arg);
+            return ret;
+        }
+        av_log(NULL, AV_LOG_DEBUG, "Successfully opened the file.\n");
+    }
+
+    return 0;
+}
+
+int ffmpeg_parse_options(int argc, char **argv)
+{
+    OptionParseContext octx;
+    uint8_t error[128];
+    int ret;
+
+    memset(&octx, 0, sizeof(octx));
+
+    /* split the commandline into an internal representation */
+    ret = split_commandline(&octx, argc, argv, options, groups,
+                            FF_ARRAY_ELEMS(groups));
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Error splitting the argument list: ");
+        goto fail;
+    }
+
+    /* apply global options */
+    ret = parse_optgroup(NULL, &octx.global_opts);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Error parsing global options: ");
+        goto fail;
+    }
+
+    /* configure terminal and setup signal handlers */
+    term_init();
+
+    /* open input files */
+    ret = open_files(&octx.groups[GROUP_INFILE], "input", open_input_file);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Error opening input files: ");
+        goto fail;
+    }
+
+    /* create the complex filtergraphs */
+    ret = init_complex_filters();
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Error initializing complex filters.\n");
+        goto fail;
+    }
+
+    /* open output files */
+    ret = open_files(&octx.groups[GROUP_OUTFILE], "output", open_output_file);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_FATAL, "Error opening output files: ");
+        goto fail;
+    }
+
+    check_filter_outputs();
+
+fail:
+    uninit_parse_context(&octx);
+    if (ret < 0) {
+        av_strerror(ret, error, sizeof(error));
+        av_log(NULL, AV_LOG_FATAL, "%s\n", error);
+    }
+    return ret;
+}
+
+static int opt_progress(void *optctx, const char *opt, const char *arg)
+{
+    AVIOContext *avio = NULL;
+    int ret;
+
+    if (!strcmp(arg, "-"))
+        arg = "pipe:";
+    ret = avio_open2(&avio, arg, AVIO_FLAG_WRITE, &int_cb, NULL);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "Failed to open progress URL \"%s\": %s\n",
+               arg, av_err2str(ret));
+        return ret;
+    }
+    progress_avio = avio;
+    return 0;
+}
+
+#define OFFSET(x) offsetof(OptionsContext, x)
+const OptionDef options[] = {
+    /* main options */
+    CMDUTILS_COMMON_OPTIONS
+    { "f",              HAS_ARG | OPT_STRING | OPT_OFFSET |
+                        OPT_INPUT | OPT_OUTPUT,                      { .off       = OFFSET(format) },
+        "force format", "fmt" },
+    { "y",              OPT_BOOL,                                    {              &file_overwrite },
+        "overwrite output files" },
+    { "n",              OPT_BOOL,                                    {              &no_file_overwrite },
+        "never overwrite output files" },
+    { "ignore_unknown", OPT_BOOL,                                    {              &ignore_unknown_streams },
+        "Ignore unknown stream types" },
+    { "copy_unknown",   OPT_BOOL | OPT_EXPERT,                       {              &copy_unknown_streams },
+        "Copy unknown stream types" },
+    { "c",              HAS_ARG | OPT_STRING | OPT_SPEC |
+                        OPT_INPUT | OPT_OUTPUT,                      { .off       = OFFSET(codec_names) },
+        "codec name", "codec" },
+    { "codec",          HAS_ARG | OPT_STRING | OPT_SPEC |
+                        OPT_INPUT | OPT_OUTPUT,                      { .off       = OFFSET(codec_names) },
+        "codec name", "codec" },
+    { "pre",            HAS_ARG | OPT_STRING | OPT_SPEC |
+                        OPT_OUTPUT,                                  { .off       = OFFSET(presets) },
+        "preset name", "preset" },
+    { "map",            HAS_ARG | OPT_EXPERT | OPT_PERFILE |
+                        OPT_OUTPUT,                                  { .func_arg = opt_map },
+        "set input stream mapping",
+        "[-]input_file_id[:stream_specifier][,sync_file_id[:stream_specifier]]" },
+    { "map_channel",    HAS_ARG | OPT_EXPERT | OPT_PERFILE | OPT_OUTPUT, { .func_arg = opt_map_channel },
+        "map an audio channel from one stream to another", "file.stream.channel[:syncfile.syncstream]" },
+    { "map_metadata",   HAS_ARG | OPT_STRING | OPT_SPEC |
+                        OPT_OUTPUT,                                  { .off       = OFFSET(metadata_map) },
+        "set metadata information of outfile from infile",
+        "outfile[,metadata]:infile[,metadata]" },
+    { "map_chapters",   HAS_ARG | OPT_INT | OPT_EXPERT | OPT_OFFSET |
+                        OPT_OUTPUT,                                  { .off = OFFSET(chapters_input_file) },
+        "set chapters mapping", "input_file_index" },
+    { "t",              HAS_ARG | OPT_TIME | OPT_OFFSET |
+                        OPT_INPUT | OPT_OUTPUT,                      { .off = OFFSET(recording_time) },
+        "record or transcode \"duration\" seconds of audio/video",
+        "duration" },
+    { "to",             HAS_ARG | OPT_TIME | OPT_OFFSET | OPT_INPUT | OPT_OUTPUT,  { .off = OFFSET(stop_time) },
+        "record or transcode stop time", "time_stop" },
+    { "fs",             HAS_ARG | OPT_INT64 | OPT_OFFSET | OPT_OUTPUT, { .off = OFFSET(limit_filesize) },
+        "set the limit file size in bytes", "limit_size" },
+    { "ss",             HAS_ARG | OPT_TIME | OPT_OFFSET |
+                        OPT_INPUT | OPT_OUTPUT,                      { .off = OFFSET(start_time) },
+        "set the start time offset", "time_off" },
+    { "sseof",          HAS_ARG | OPT_TIME | OPT_OFFSET |
+                        OPT_INPUT,                                   { .off = OFFSET(start_time_eof) },
+        "set the start time offset relative to EOF", "time_off" },
+    { "seek_timestamp", HAS_ARG | OPT_INT | OPT_OFFSET |
+                        OPT_INPUT,                                   { .off = OFFSET(seek_timestamp) },
+        "enable/disable seeking by timestamp with -ss" },
+    { "accurate_seek",  OPT_BOOL | OPT_OFFSET | OPT_EXPERT |
+                        OPT_INPUT,                                   { .off = OFFSET(accurate_seek) },
+        "enable/disable accurate seeking with -ss" },
+    { "itsoffset",      HAS_ARG | OPT_TIME | OPT_OFFSET |
+                        OPT_EXPERT | OPT_INPUT,                      { .off = OFFSET(input_ts_offset) },
+        "set the input ts offset", "time_off" },
+    { "itsscale",       HAS_ARG | OPT_DOUBLE | OPT_SPEC |
+                        OPT_EXPERT | OPT_INPUT,                      { .off = OFFSET(ts_scale) },
+        "set the input ts scale", "scale" },
+    { "timestamp",      HAS_ARG | OPT_PERFILE | OPT_OUTPUT,          { .func_arg = opt_recording_timestamp },
+        "set the recording timestamp ('now' to set the current time)", "time" },
+    { "metadata",       HAS_ARG | OPT_STRING | OPT_SPEC | OPT_OUTPUT, { .off = OFFSET(metadata) },
+        "add metadata", "string=string" },
+    { "program",        HAS_ARG | OPT_STRING | OPT_SPEC | OPT_OUTPUT, { .off = OFFSET(program) },
+        "add program with specified streams", "title=string:st=number..." },
+    { "dframes",        HAS_ARG | OPT_PERFILE | OPT_EXPERT |
+                        OPT_OUTPUT,                                  { .func_arg = opt_data_frames },
+        "set the number of data frames to output", "number" },
+    { "benchmark",      OPT_BOOL | OPT_EXPERT,                       { &do_benchmark },
+        "add timings for benchmarking" },
+    { "benchmark_all",  OPT_BOOL | OPT_EXPERT,                       { &do_benchmark_all },
+      "add timings for each task" },
+    { "progress",       HAS_ARG | OPT_EXPERT,                        { .func_arg = opt_progress },
+      "write program-readable progress information", "url" },
+    { "stdin",          OPT_BOOL | OPT_EXPERT,                       { &stdin_interaction },
+      "enable or disable interaction on standard input" },
+    { "timelimit",      HAS_ARG | OPT_EXPERT,                        { .func_arg = opt_timelimit },
+        "set max runtime in seconds in CPU user time", "limit" },
+    { "dump",           OPT_BOOL | OPT_EXPERT,                       { &do_pkt_dump },
+        "dump each input packet" },
+    { "hex",            OPT_BOOL | OPT_EXPERT,                       { &do_hex_dump },
+        "when dumping packets, also dump the payload" },
+    { "re",             OPT_BOOL | OPT_EXPERT | OPT_OFFSET |
+                        OPT_INPUT,                                   { .off = OFFSET(rate_emu) },
+        "read input at native frame rate", "" },
+    { "target",         HAS_ARG | OPT_PERFILE | OPT_OUTPUT,          { .func_arg = opt_target },
+        "specify target file type (\"vcd\", \"svcd\", \"dvd\", \"dv\" or \"dv50\" "
+        "with optional prefixes \"pal-\", \"ntsc-\" or \"film-\")", "type" },
+    { "vsync",          HAS_ARG | OPT_EXPERT,                        { .func_arg = opt_vsync },
+        "video sync method", "" },
+    { "frame_drop_threshold", HAS_ARG | OPT_FLOAT | OPT_EXPERT,      { &frame_drop_threshold },
+        "frame drop threshold", "" },
+    { "async",          HAS_ARG | OPT_INT | OPT_EXPERT,              { &audio_sync_method },
+        "audio sync method", "" },
+    { "adrift_threshold", HAS_ARG | OPT_FLOAT | OPT_EXPERT,          { &audio_drift_threshold },
+        "audio drift threshold", "threshold" },
+    { "copyts",         OPT_BOOL | OPT_EXPERT,                       { &copy_ts },
+        "copy timestamps" },
+    { "start_at_zero",  OPT_BOOL | OPT_EXPERT,                       { &start_at_zero },
+        "shift input timestamps to start at 0 when using copyts" },
+    { "copytb",         HAS_ARG | OPT_INT | OPT_EXPERT,              { &copy_tb },
+        "copy input stream time base when stream copying", "mode" },
+    { "shortest",       OPT_BOOL | OPT_EXPERT | OPT_OFFSET |
+                        OPT_OUTPUT,                                  { .off = OFFSET(shortest) },
+        "finish encoding within shortest input" },
+    { "bitexact",       OPT_BOOL | OPT_EXPERT | OPT_OFFSET |
+                        OPT_OUTPUT | OPT_INPUT,                      { .off = OFFSET(bitexact) },
+        "bitexact mode" },
+    { "apad",           OPT_STRING | HAS_ARG | OPT_SPEC |
+                        OPT_OUTPUT,                                  { .off = OFFSET(apad) },
+        "audio pad", "" },
+    { "dts_delta_threshold", HAS_ARG | OPT_FLOAT | OPT_EXPERT,       { &dts_delta_threshold },
+        "timestamp discontinuity delta threshold", "threshold" },
+    { "dts_error_threshold", HAS_ARG | OPT_FLOAT | OPT_EXPERT,       { &dts_error_threshold },
+        "timestamp error delta threshold", "threshold" },
+    { "xerror",         OPT_BOOL | OPT_EXPERT,                       { &exit_on_error },
+        "exit on error", "error" },
+    { "abort_on",       HAS_ARG | OPT_EXPERT,                        { .func_arg = opt_abort_on },
+        "abort on the specified condition flags", "flags" },
+    { "copyinkf",       OPT_BOOL | OPT_EXPERT | OPT_SPEC |
+                        OPT_OUTPUT,                                  { .off = OFFSET(copy_initial_nonkeyframes) },
+        "copy initial non-keyframes" },
+    { "copypriorss",    OPT_INT | HAS_ARG | OPT_EXPERT | OPT_SPEC | OPT_OUTPUT,   { .off = OFFSET(copy_prior_start) },
+        "copy or discard frames before start time" },
+    { "frames",         OPT_INT64 | HAS_ARG | OPT_SPEC | OPT_OUTPUT, { .off = OFFSET(max_frames) },
+        "set the number of frames to output", "number" },
+    { "tag",            OPT_STRING | HAS_ARG | OPT_SPEC |
+                        OPT_EXPERT | OPT_OUTPUT | OPT_INPUT,         { .off = OFFSET(codec_tags) },
+        "force codec tag/fourcc", "fourcc/tag" },
+    { "q",              HAS_ARG | OPT_EXPERT | OPT_DOUBLE |
+                        OPT_SPEC | OPT_OUTPUT,                       { .off = OFFSET(qscale) },
+        "use fixed quality scale (VBR)", "q" },
+    { "qscale",         HAS_ARG | OPT_EXPERT | OPT_PERFILE |
+                        OPT_OUTPUT,                                  { .func_arg = opt_qscale },
+        "use fixed quality scale (VBR)", "q" },
+    { "profile",        HAS_ARG | OPT_EXPERT | OPT_PERFILE | OPT_OUTPUT, { .func_arg = opt_profile },
+        "set profile", "profile" },
+    { "filter",         HAS_ARG | OPT_STRING | OPT_SPEC | OPT_OUTPUT, { .off = OFFSET(filters) },
+        "set stream filtergraph", "filter_graph" },
+    { "filter_threads",  HAS_ARG | OPT_INT,                          { &filter_nbthreads },
+        "number of non-complex filter threads" },
+    { "filter_script",  HAS_ARG | OPT_STRING | OPT_SPEC | OPT_OUTPUT, { .off = OFFSET(filter_scripts) },
+        "read stream filtergraph description from a file", "filename" },
+    { "reinit_filter",  HAS_ARG | OPT_INT | OPT_SPEC | OPT_INPUT,    { .off = OFFSET(reinit_filters) },
+        "reinit filtergraph on input parameter changes", "" },
+    { "filter_complex", HAS_ARG | OPT_EXPERT,                        { .func_arg = opt_filter_complex },
+        "create a complex filtergraph", "graph_description" },
+    { "filter_complex_threads", HAS_ARG | OPT_INT,                   { &filter_complex_nbthreads },
+        "number of threads for -filter_complex" },
+    { "lavfi",          HAS_ARG | OPT_EXPERT,                        { .func_arg = opt_filter_complex },
+        "create a complex filtergraph", "graph_description" },
+    { "filter_complex_script", HAS_ARG | OPT_EXPERT,                 { .func_arg = opt_filter_complex_script },
+        "read complex filtergraph description from a file", "filename" },
+    { "auto_conversion_filters", OPT_BOOL | OPT_EXPERT,              { &auto_conversion_filters },
+        "enable automatic conversion filters globally" },
+    { "stats",          OPT_BOOL,                                    { &print_stats },
+        "print progress report during encoding", },
+    { "stats_period",    HAS_ARG | OPT_EXPERT,                       { .func_arg = opt_stats_period },
+        "set the period at which ffmpeg updates stats and -progress output", "time" },
+    { "attach",         HAS_ARG | OPT_PERFILE | OPT_EXPERT |
+                        OPT_OUTPUT,                                  { .func_arg = opt_attach },
+        "add an attachment to the output file", "filename" },
+    { "dump_attachment", HAS_ARG | OPT_STRING | OPT_SPEC |
+                         OPT_EXPERT | OPT_INPUT,                     { .off = OFFSET(dump_attachment) },
+        "extract an attachment into a file", "filename" },
+    { "stream_loop", OPT_INT | HAS_ARG | OPT_EXPERT | OPT_INPUT |
+                        OPT_OFFSET,                                  { .off = OFFSET(loop) }, "set number of times input stream shall be looped", "loop count" },
+    { "debug_ts",       OPT_BOOL | OPT_EXPERT,                       { &debug_ts },
+        "print timestamp debugging info" },
+    { "max_error_rate",  HAS_ARG | OPT_FLOAT,                        { &max_error_rate },
+        "ratio of decoding errors (0.0: no errors, 1.0: 100% errors) above which ffmpeg returns an error instead of success.", "maximum error rate" },
+    { "discard",        OPT_STRING | HAS_ARG | OPT_SPEC |
+                        OPT_INPUT,                                   { .off = OFFSET(discard) },
+        "discard", "" },
+    { "disposition",    OPT_STRING | HAS_ARG | OPT_SPEC |
+                        OPT_OUTPUT,                                  { .off = OFFSET(disposition) },
+        "disposition", "" },
+    { "thread_queue_size", HAS_ARG | OPT_INT | OPT_OFFSET | OPT_EXPERT | OPT_INPUT,
+                                                                     { .off = OFFSET(thread_queue_size) },
+        "set the maximum number of queued packets from the demuxer" },
+    { "find_stream_info", OPT_BOOL | OPT_PERFILE | OPT_INPUT | OPT_EXPERT, { &find_stream_info },
+        "read and decode the streams to fill missing information with heuristics" },
+
+    /* video options */
+    { "vframes",      OPT_VIDEO | HAS_ARG  | OPT_PERFILE | OPT_OUTPUT,           { .func_arg = opt_video_frames },
+        "set the number of video frames to output", "number" },
+    { "r",            OPT_VIDEO | HAS_ARG  | OPT_STRING | OPT_SPEC |
+                      OPT_INPUT | OPT_OUTPUT,                                    { .off = OFFSET(frame_rates) },
+        "set frame rate (Hz value, fraction or abbreviation)", "rate" },
+    { "fpsmax",       OPT_VIDEO | HAS_ARG  | OPT_STRING | OPT_SPEC |
+                      OPT_OUTPUT,                                                { .off = OFFSET(max_frame_rates) },
+        "set max frame rate (Hz value, fraction or abbreviation)", "rate" },
+    { "s",            OPT_VIDEO | HAS_ARG | OPT_SUBTITLE | OPT_STRING | OPT_SPEC |
+                      OPT_INPUT | OPT_OUTPUT,                                    { .off = OFFSET(frame_sizes) },
+        "set frame size (WxH or abbreviation)", "size" },
+    { "aspect",       OPT_VIDEO | HAS_ARG  | OPT_STRING | OPT_SPEC |
+                      OPT_OUTPUT,                                                { .off = OFFSET(frame_aspect_ratios) },
+        "set aspect ratio (4:3, 16:9 or 1.3333, 1.7777)", "aspect" },
+    { "pix_fmt",      OPT_VIDEO | HAS_ARG | OPT_EXPERT  | OPT_STRING | OPT_SPEC |
+                      OPT_INPUT | OPT_OUTPUT,                                    { .off = OFFSET(frame_pix_fmts) },
+        "set pixel format", "format" },
+    { "bits_per_raw_sample", OPT_VIDEO | OPT_INT | HAS_ARG,                      { &frame_bits_per_raw_sample },
+        "set the number of bits per raw sample", "number" },
+    { "intra",        OPT_VIDEO | OPT_BOOL | OPT_EXPERT,                         { &intra_only },
+        "deprecated use -g 1" },
+    { "vn",           OPT_VIDEO | OPT_BOOL  | OPT_OFFSET | OPT_INPUT | OPT_OUTPUT,{ .off = OFFSET(video_disable) },
+        "disable video" },
+    { "rc_override",  OPT_VIDEO | HAS_ARG | OPT_EXPERT  | OPT_STRING | OPT_SPEC |
+                      OPT_OUTPUT,                                                { .off = OFFSET(rc_overrides) },
+        "rate control override for specific intervals", "override" },
+    { "vcodec",       OPT_VIDEO | HAS_ARG  | OPT_PERFILE | OPT_INPUT |
+                      OPT_OUTPUT,                                                { .func_arg = opt_video_codec },
+        "force video codec ('copy' to copy stream)", "codec" },
+    { "sameq",        OPT_VIDEO | OPT_EXPERT ,                                   { .func_arg = opt_sameq },
+        "Removed" },
+    { "same_quant",   OPT_VIDEO | OPT_EXPERT ,                                   { .func_arg = opt_sameq },
+        "Removed" },
+    { "timecode",     OPT_VIDEO | HAS_ARG | OPT_PERFILE | OPT_OUTPUT,            { .func_arg = opt_timecode },
+        "set initial TimeCode value.", "hh:mm:ss[:;.]ff" },
+    { "pass",         OPT_VIDEO | HAS_ARG | OPT_SPEC | OPT_INT | OPT_OUTPUT,     { .off = OFFSET(pass) },
+        "select the pass number (1 to 3)", "n" },
+    { "passlogfile",  OPT_VIDEO | HAS_ARG | OPT_STRING | OPT_EXPERT | OPT_SPEC |
+                      OPT_OUTPUT,                                                { .off = OFFSET(passlogfiles) },
+        "select two pass log file name prefix", "prefix" },
+    { "deinterlace",  OPT_VIDEO | OPT_BOOL | OPT_EXPERT,                         { &do_deinterlace },
+        "this option is deprecated, use the yadif filter instead" },
+    { "psnr",         OPT_VIDEO | OPT_BOOL | OPT_EXPERT,                         { &do_psnr },
+        "calculate PSNR of compressed frames" },
+    { "vstats",       OPT_VIDEO | OPT_EXPERT ,                                   { .func_arg = opt_vstats },
+        "dump video coding statistics to file" },
+    { "vstats_file",  OPT_VIDEO | HAS_ARG | OPT_EXPERT ,                         { .func_arg = opt_vstats_file },
+        "dump video coding statistics to file", "file" },
+    { "vstats_version",  OPT_VIDEO | OPT_INT | HAS_ARG | OPT_EXPERT ,            { &vstats_version },
+        "Version of the vstats format to use."},
+    { "vf",           OPT_VIDEO | HAS_ARG  | OPT_PERFILE | OPT_OUTPUT,           { .func_arg = opt_video_filters },
+        "set video filters", "filter_graph" },
+    { "intra_matrix", OPT_VIDEO | HAS_ARG | OPT_EXPERT  | OPT_STRING | OPT_SPEC |
+                      OPT_OUTPUT,                                                { .off = OFFSET(intra_matrices) },
+        "specify intra matrix coeffs", "matrix" },
+    { "inter_matrix", OPT_VIDEO | HAS_ARG | OPT_EXPERT  | OPT_STRING | OPT_SPEC |
+                      OPT_OUTPUT,                                                { .off = OFFSET(inter_matrices) },
+        "specify inter matrix coeffs", "matrix" },
+    { "chroma_intra_matrix", OPT_VIDEO | HAS_ARG | OPT_EXPERT  | OPT_STRING | OPT_SPEC |
+                      OPT_OUTPUT,                                                { .off = OFFSET(chroma_intra_matrices) },
+        "specify intra matrix coeffs", "matrix" },
+    { "top",          OPT_VIDEO | HAS_ARG | OPT_EXPERT  | OPT_INT| OPT_SPEC |
+                      OPT_INPUT | OPT_OUTPUT,                                    { .off = OFFSET(top_field_first) },
+        "top=1/bottom=0/auto=-1 field first", "" },
+    { "vtag",         OPT_VIDEO | HAS_ARG | OPT_EXPERT  | OPT_PERFILE |
+                      OPT_INPUT | OPT_OUTPUT,                                    { .func_arg = opt_old2new },
+        "force video tag/fourcc", "fourcc/tag" },
+    { "qphist",       OPT_VIDEO | OPT_BOOL | OPT_EXPERT ,                        { &qp_hist },
+        "show QP histogram" },
+    { "force_fps",    OPT_VIDEO | OPT_BOOL | OPT_EXPERT  | OPT_SPEC |
+                      OPT_OUTPUT,                                                { .off = OFFSET(force_fps) },
+        "force the selected framerate, disable the best supported framerate selection" },
+    { "streamid",     OPT_VIDEO | HAS_ARG | OPT_EXPERT | OPT_PERFILE |
+                      OPT_OUTPUT,                                                { .func_arg = opt_streamid },
+        "set the value of an outfile streamid", "streamIndex:value" },
+    { "force_key_frames", OPT_VIDEO | OPT_STRING | HAS_ARG | OPT_EXPERT |
+                          OPT_SPEC | OPT_OUTPUT,                                 { .off = OFFSET(forced_key_frames) },
+        "force key frames at specified timestamps", "timestamps" },
+    { "ab",           OPT_VIDEO | HAS_ARG | OPT_PERFILE | OPT_OUTPUT,            { .func_arg = opt_bitrate },
+        "audio bitrate (please use -b:a)", "bitrate" },
+    { "b",            OPT_VIDEO | HAS_ARG | OPT_PERFILE | OPT_OUTPUT,            { .func_arg = opt_bitrate },
+        "video bitrate (please use -b:v)", "bitrate" },
+    { "hwaccel",          OPT_VIDEO | OPT_STRING | HAS_ARG | OPT_EXPERT |
+                          OPT_SPEC | OPT_INPUT,                                  { .off = OFFSET(hwaccels) },
+        "use HW accelerated decoding", "hwaccel name" },
+    { "hwaccel_device",   OPT_VIDEO | OPT_STRING | HAS_ARG | OPT_EXPERT |
+                          OPT_SPEC | OPT_INPUT,                                  { .off = OFFSET(hwaccel_devices) },
+        "select a device for HW acceleration", "devicename" },
+    { "hwaccel_output_format", OPT_VIDEO | OPT_STRING | HAS_ARG | OPT_EXPERT |
+                          OPT_SPEC | OPT_INPUT,                                  { .off = OFFSET(hwaccel_output_formats) },
+        "select output format used with HW accelerated decoding", "format" },
+#if CONFIG_VIDEOTOOLBOX
+    { "videotoolbox_pixfmt", HAS_ARG | OPT_STRING | OPT_EXPERT, { &videotoolbox_pixfmt}, "" },
+#endif
+    { "hwaccels",         OPT_EXIT,                                              { .func_arg = show_hwaccels },
+        "show available HW acceleration methods" },
+    { "autorotate",       HAS_ARG | OPT_BOOL | OPT_SPEC |
+                          OPT_EXPERT | OPT_INPUT,                                { .off = OFFSET(autorotate) },
+        "automatically insert correct rotate filters" },
+    { "autoscale",        HAS_ARG | OPT_BOOL | OPT_SPEC |
+                          OPT_EXPERT | OPT_OUTPUT,                               { .off = OFFSET(autoscale) },
+        "automatically insert a scale filter at the end of the filter graph" },
+
+    /* audio options */
+    { "aframes",        OPT_AUDIO | HAS_ARG  | OPT_PERFILE | OPT_OUTPUT,           { .func_arg = opt_audio_frames },
+        "set the number of audio frames to output", "number" },
+    { "aq",             OPT_AUDIO | HAS_ARG  | OPT_PERFILE | OPT_OUTPUT,           { .func_arg = opt_audio_qscale },
+        "set audio quality (codec-specific)", "quality", },
+    { "ar",             OPT_AUDIO | HAS_ARG  | OPT_INT | OPT_SPEC |
+                        OPT_INPUT | OPT_OUTPUT,                                    { .off = OFFSET(audio_sample_rate) },
+        "set audio sampling rate (in Hz)", "rate" },
+    { "ac",             OPT_AUDIO | HAS_ARG  | OPT_INT | OPT_SPEC |
+                        OPT_INPUT | OPT_OUTPUT,                                    { .off = OFFSET(audio_channels) },
+        "set number of audio channels", "channels" },
+    { "an",             OPT_AUDIO | OPT_BOOL | OPT_OFFSET | OPT_INPUT | OPT_OUTPUT,{ .off = OFFSET(audio_disable) },
+        "disable audio" },
+    { "acodec",         OPT_AUDIO | HAS_ARG  | OPT_PERFILE |
+                        OPT_INPUT | OPT_OUTPUT,                                    { .func_arg = opt_audio_codec },
+        "force audio codec ('copy' to copy stream)", "codec" },
+    { "atag",           OPT_AUDIO | HAS_ARG  | OPT_EXPERT | OPT_PERFILE |
+                        OPT_OUTPUT,                                                { .func_arg = opt_old2new },
+        "force audio tag/fourcc", "fourcc/tag" },
+    { "vol",            OPT_AUDIO | HAS_ARG  | OPT_INT,                            { &audio_volume },
+        "change audio volume (256=normal)" , "volume" },
+    { "sample_fmt",     OPT_AUDIO | HAS_ARG  | OPT_EXPERT | OPT_SPEC |
+                        OPT_STRING | OPT_INPUT | OPT_OUTPUT,                       { .off = OFFSET(sample_fmts) },
+        "set sample format", "format" },
+    { "channel_layout", OPT_AUDIO | HAS_ARG  | OPT_EXPERT | OPT_PERFILE |
+                        OPT_INPUT | OPT_OUTPUT,                                    { .func_arg = opt_channel_layout },
+        "set channel layout", "layout" },
+    { "af",             OPT_AUDIO | HAS_ARG  | OPT_PERFILE | OPT_OUTPUT,           { .func_arg = opt_audio_filters },
+        "set audio filters", "filter_graph" },
+    { "guess_layout_max", OPT_AUDIO | HAS_ARG | OPT_INT | OPT_SPEC | OPT_EXPERT | OPT_INPUT, { .off = OFFSET(guess_layout_max) },
+      "set the maximum number of channels to try to guess the channel layout" },
+
+    /* subtitle options */
+    { "sn",     OPT_SUBTITLE | OPT_BOOL | OPT_OFFSET | OPT_INPUT | OPT_OUTPUT, { .off = OFFSET(subtitle_disable) },
+        "disable subtitle" },
+    { "scodec", OPT_SUBTITLE | HAS_ARG  | OPT_PERFILE | OPT_INPUT | OPT_OUTPUT, { .func_arg = opt_subtitle_codec },
+        "force subtitle codec ('copy' to copy stream)", "codec" },
+    { "stag",   OPT_SUBTITLE | HAS_ARG  | OPT_EXPERT  | OPT_PERFILE | OPT_OUTPUT, { .func_arg = opt_old2new }
+        , "force subtitle tag/fourcc", "fourcc/tag" },
+    { "fix_sub_duration", OPT_BOOL | OPT_EXPERT | OPT_SUBTITLE | OPT_SPEC | OPT_INPUT, { .off = OFFSET(fix_sub_duration) },
+        "fix subtitles duration" },
+    { "canvas_size", OPT_SUBTITLE | HAS_ARG | OPT_STRING | OPT_SPEC | OPT_INPUT, { .off = OFFSET(canvas_sizes) },
+        "set canvas size (WxH or abbreviation)", "size" },
+
+    /* grab options */
+    { "vc", HAS_ARG | OPT_EXPERT | OPT_VIDEO, { .func_arg = opt_video_channel },
+        "deprecated, use -channel", "channel" },
+    { "tvstd", HAS_ARG | OPT_EXPERT | OPT_VIDEO, { .func_arg = opt_video_standard },
+        "deprecated, use -standard", "standard" },
+    { "isync", OPT_BOOL | OPT_EXPERT, { &input_sync }, "this option is deprecated and does nothing", "" },
+
+    /* muxer options */
+    { "muxdelay",   OPT_FLOAT | HAS_ARG | OPT_EXPERT | OPT_OFFSET | OPT_OUTPUT, { .off = OFFSET(mux_max_delay) },
+        "set the maximum demux-decode delay", "seconds" },
+    { "muxpreload", OPT_FLOAT | HAS_ARG | OPT_EXPERT | OPT_OFFSET | OPT_OUTPUT, { .off = OFFSET(mux_preload) },
+        "set the initial demux-decode delay", "seconds" },
+    { "sdp_file", HAS_ARG | OPT_EXPERT | OPT_OUTPUT, { .func_arg = opt_sdp_file },
+        "specify a file in which to print sdp information", "file" },
+
+    { "time_base", HAS_ARG | OPT_STRING | OPT_EXPERT | OPT_SPEC | OPT_OUTPUT, { .off = OFFSET(time_bases) },
+        "set the desired time base hint for output stream (1:24, 1:48000 or 0.04166, 2.0833e-5)", "ratio" },
+    { "enc_time_base", HAS_ARG | OPT_STRING | OPT_EXPERT | OPT_SPEC | OPT_OUTPUT, { .off = OFFSET(enc_time_bases) },
+        "set the desired time base for the encoder (1:24, 1:48000 or 0.04166, 2.0833e-5). "
+        "two special values are defined - "
+        "0 = use frame rate (video) or sample rate (audio),"
+        "-1 = match source time base", "ratio" },
+
+    { "bsf", HAS_ARG | OPT_STRING | OPT_SPEC | OPT_EXPERT | OPT_OUTPUT, { .off = OFFSET(bitstream_filters) },
+        "A comma-separated list of bitstream filters", "bitstream_filters" },
+    { "absf", HAS_ARG | OPT_AUDIO | OPT_EXPERT| OPT_PERFILE | OPT_OUTPUT, { .func_arg = opt_old2new },
+        "deprecated", "audio bitstream_filters" },
+    { "vbsf", OPT_VIDEO | HAS_ARG | OPT_EXPERT| OPT_PERFILE | OPT_OUTPUT, { .func_arg = opt_old2new },
+        "deprecated", "video bitstream_filters" },
+
+    { "apre", HAS_ARG | OPT_AUDIO | OPT_EXPERT| OPT_PERFILE | OPT_OUTPUT,    { .func_arg = opt_preset },
+        "set the audio options to the indicated preset", "preset" },
+    { "vpre", OPT_VIDEO | HAS_ARG | OPT_EXPERT| OPT_PERFILE | OPT_OUTPUT,    { .func_arg = opt_preset },
+        "set the video options to the indicated preset", "preset" },
+    { "spre", HAS_ARG | OPT_SUBTITLE | OPT_EXPERT| OPT_PERFILE | OPT_OUTPUT, { .func_arg = opt_preset },
+        "set the subtitle options to the indicated preset", "preset" },
+    { "fpre", HAS_ARG | OPT_EXPERT| OPT_PERFILE | OPT_OUTPUT,                { .func_arg = opt_preset },
+        "set options from indicated preset file", "filename" },
+
+    { "max_muxing_queue_size", HAS_ARG | OPT_INT | OPT_SPEC | OPT_EXPERT | OPT_OUTPUT, { .off = OFFSET(max_muxing_queue_size) },
+        "maximum number of packets that can be buffered while waiting for all streams to initialize", "packets" },
+    { "muxing_queue_data_threshold", HAS_ARG | OPT_INT | OPT_SPEC | OPT_EXPERT | OPT_OUTPUT, { .off = OFFSET(muxing_queue_data_threshold) },
+        "set the threshold after which max_muxing_queue_size is taken into account", "bytes" },
+
+    /* data codec support */
+    { "dcodec", HAS_ARG | OPT_DATA | OPT_PERFILE | OPT_EXPERT | OPT_INPUT | OPT_OUTPUT, { .func_arg = opt_data_codec },
+        "force data codec ('copy' to copy stream)", "codec" },
+    { "dn", OPT_BOOL | OPT_VIDEO | OPT_OFFSET | OPT_INPUT | OPT_OUTPUT, { .off = OFFSET(data_disable) },
+        "disable data" },
+
+#if CONFIG_VAAPI
+    { "vaapi_device", HAS_ARG | OPT_EXPERT, { .func_arg = opt_vaapi_device },
+        "set VAAPI hardware device (DRM path or X11 display name)", "device" },
+#endif
+
+#if CONFIG_QSV
+    { "qsv_device", HAS_ARG | OPT_STRING | OPT_EXPERT, { &qsv_device },
+        "set QSV hardware device (DirectX adapter index, DRM path or X11 display name)", "device"},
+#endif
+
+    { "init_hw_device", HAS_ARG | OPT_EXPERT, { .func_arg = opt_init_hw_device },
+        "initialise hardware device", "args" },
+    { "filter_hw_device", HAS_ARG | OPT_EXPERT, { .func_arg = opt_filter_hw_device },
+        "set hardware device used when filtering", "device" },
+
+    { NULL, },
+};
diff -Naur ffmpeg-4.4-N-Alpha1/fftools/ffplay.c ffmpeg-4.4-N-Alpha1-2/fftools/ffplay.c
--- ffmpeg-4.4-N-Alpha1/fftools/ffplay.c	2022-04-20 03:47:13.896503418 +0200
+++ ffmpeg-4.4-N-Alpha1-2/fftools/ffplay.c	2022-04-20 03:49:31.086968147 +0200
@@ -2601,6 +2601,31 @@
         case AVMEDIA_TYPE_SUBTITLE: is->last_subtitle_stream = stream_index; forced_codec_name = subtitle_codec_name; break;
         case AVMEDIA_TYPE_VIDEO   : is->last_video_stream    = stream_index; forced_codec_name =    video_codec_name; break;
     }
+
+#if CONFIG_NVV4L2
+    /* Reset requested decoder in order to enforce NVV4L2 if possible. */
+    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO && forced_codec_name) {
+        if (strcmp(forced_codec_name, "h264") == 0)
+            forced_codec_name = NULL;    
+        else if (strcmp(forced_codec_name, "hevc") == 0)
+            forced_codec_name = NULL; 
+        else if (strcmp(forced_codec_name, "mpeg2video") == 0)
+            forced_codec_name = NULL;
+        else if (strcmp(forced_codec_name, "mpeg4") == 0)
+            forced_codec_name = NULL;
+        else if (strcmp(forced_codec_name, "vp8") == 0)
+            forced_codec_name = NULL;
+        else if (strcmp(forced_codec_name, "vp9") == 0 &&
+                 avctx->pix_fmt != AV_PIX_FMT_YUV420P10) {
+            forced_codec_name = NULL;
+        }
+    }
+
+    /* NVV4L2 does not support VP9 with YUV420P10. */
+    if (!forced_codec_name && avctx->pix_fmt == AV_PIX_FMT_YUV420P10)
+        forced_codec_name = "vp9";
+#endif
+
     if (forced_codec_name)
         codec = avcodec_find_decoder_by_name(forced_codec_name);
     if (!codec) {
diff -Naur ffmpeg-4.4-N-Alpha1/libavcodec/allcodecs.c ffmpeg-4.4-N-Alpha1-2/libavcodec/allcodecs.c
--- ffmpeg-4.4-N-Alpha1/libavcodec/allcodecs.c	2022-04-20 03:47:13.904503562 +0200
+++ ffmpeg-4.4-N-Alpha1-2/libavcodec/allcodecs.c	2022-04-20 03:49:41.819220377 +0200
@@ -141,6 +141,8 @@
 extern AVCodec ff_h263p_encoder;
 extern AVCodec ff_h263p_decoder;
 extern AVCodec ff_h263_v4l2m2m_decoder;
+extern AVCodec ff_h264_nvv4l2_encoder;
+extern AVCodec ff_h264_nvv4l2_decoder;
 extern AVCodec ff_h264_decoder;
 extern AVCodec ff_h264_crystalhd_decoder;
 extern AVCodec ff_h264_v4l2m2m_decoder;
@@ -150,6 +152,8 @@
 extern AVCodec ff_h264_rkmpp_decoder;
 extern AVCodec ff_hap_encoder;
 extern AVCodec ff_hap_decoder;
+extern AVCodec ff_hevc_nvv4l2_encoder;
+extern AVCodec ff_hevc_nvv4l2_decoder;
 extern AVCodec ff_hevc_decoder;
 extern AVCodec ff_hevc_qsv_decoder;
 extern AVCodec ff_hevc_rkmpp_decoder;
@@ -194,8 +198,10 @@
 extern AVCodec ff_motionpixels_decoder;
 extern AVCodec ff_mpeg1video_encoder;
 extern AVCodec ff_mpeg1video_decoder;
+extern AVCodec ff_mpeg2_nvv4l2_decoder;
 extern AVCodec ff_mpeg2video_encoder;
 extern AVCodec ff_mpeg2video_decoder;
+extern AVCodec ff_mpeg4_nvv4l2_decoder;
 extern AVCodec ff_mpeg4_encoder;
 extern AVCodec ff_mpeg4_decoder;
 extern AVCodec ff_mpeg4_crystalhd_decoder;
@@ -356,9 +362,11 @@
 extern AVCodec ff_vp6a_decoder;
 extern AVCodec ff_vp6f_decoder;
 extern AVCodec ff_vp7_decoder;
+extern AVCodec ff_vp8_nvv4l2_decoder;
 extern AVCodec ff_vp8_decoder;
 extern AVCodec ff_vp8_rkmpp_decoder;
 extern AVCodec ff_vp8_v4l2m2m_decoder;
+extern AVCodec ff_vp9_nvv4l2_decoder;
 extern AVCodec ff_vp9_decoder;
 extern AVCodec ff_vp9_rkmpp_decoder;
 extern AVCodec ff_vp9_v4l2m2m_decoder;
diff -Naur ffmpeg-4.4-N-Alpha1/libavcodec/allcodecs.c.orig ffmpeg-4.4-N-Alpha1-2/libavcodec/allcodecs.c.orig
--- ffmpeg-4.4-N-Alpha1/libavcodec/allcodecs.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ ffmpeg-4.4-N-Alpha1-2/libavcodec/allcodecs.c.orig	2022-04-20 03:48:51.826263047 +0200
@@ -0,0 +1,977 @@
+/*
+ * Provide registration of all codecs, parsers and bitstream filters for libavcodec.
+ * Copyright (c) 2002 Fabrice Bellard
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Provide registration of all codecs, parsers and bitstream filters for libavcodec.
+ */
+
+#include "config.h"
+#include "libavutil/thread.h"
+#include "avcodec.h"
+#include "version.h"
+
+extern AVCodec ff_a64multi_encoder;
+extern AVCodec ff_a64multi5_encoder;
+extern AVCodec ff_aasc_decoder;
+extern AVCodec ff_aic_decoder;
+extern AVCodec ff_alias_pix_encoder;
+extern AVCodec ff_alias_pix_decoder;
+extern AVCodec ff_agm_decoder;
+extern AVCodec ff_amv_encoder;
+extern AVCodec ff_amv_decoder;
+extern AVCodec ff_anm_decoder;
+extern AVCodec ff_ansi_decoder;
+extern AVCodec ff_apng_encoder;
+extern AVCodec ff_apng_decoder;
+extern AVCodec ff_arbc_decoder;
+extern AVCodec ff_argo_decoder;
+extern AVCodec ff_asv1_encoder;
+extern AVCodec ff_asv1_decoder;
+extern AVCodec ff_asv2_encoder;
+extern AVCodec ff_asv2_decoder;
+extern AVCodec ff_aura_decoder;
+extern AVCodec ff_aura2_decoder;
+extern AVCodec ff_avrp_encoder;
+extern AVCodec ff_avrp_decoder;
+extern AVCodec ff_avrn_decoder;
+extern AVCodec ff_avs_decoder;
+extern AVCodec ff_avui_encoder;
+extern AVCodec ff_avui_decoder;
+extern AVCodec ff_ayuv_encoder;
+extern AVCodec ff_ayuv_decoder;
+extern AVCodec ff_bethsoftvid_decoder;
+extern AVCodec ff_bfi_decoder;
+extern AVCodec ff_bink_decoder;
+extern AVCodec ff_bitpacked_decoder;
+extern AVCodec ff_bmp_encoder;
+extern AVCodec ff_bmp_decoder;
+extern AVCodec ff_bmv_video_decoder;
+extern AVCodec ff_brender_pix_decoder;
+extern AVCodec ff_c93_decoder;
+extern AVCodec ff_cavs_decoder;
+extern AVCodec ff_cdgraphics_decoder;
+extern AVCodec ff_cdtoons_decoder;
+extern AVCodec ff_cdxl_decoder;
+extern AVCodec ff_cfhd_encoder;
+extern AVCodec ff_cfhd_decoder;
+extern AVCodec ff_cinepak_encoder;
+extern AVCodec ff_cinepak_decoder;
+extern AVCodec ff_clearvideo_decoder;
+extern AVCodec ff_cljr_encoder;
+extern AVCodec ff_cljr_decoder;
+extern AVCodec ff_cllc_decoder;
+extern AVCodec ff_comfortnoise_encoder;
+extern AVCodec ff_comfortnoise_decoder;
+extern AVCodec ff_cpia_decoder;
+extern AVCodec ff_cri_decoder;
+extern AVCodec ff_cscd_decoder;
+extern AVCodec ff_cyuv_decoder;
+extern AVCodec ff_dds_decoder;
+extern AVCodec ff_dfa_decoder;
+extern AVCodec ff_dirac_decoder;
+extern AVCodec ff_dnxhd_encoder;
+extern AVCodec ff_dnxhd_decoder;
+extern AVCodec ff_dpx_encoder;
+extern AVCodec ff_dpx_decoder;
+extern AVCodec ff_dsicinvideo_decoder;
+extern AVCodec ff_dvaudio_decoder;
+extern AVCodec ff_dvvideo_encoder;
+extern AVCodec ff_dvvideo_decoder;
+extern AVCodec ff_dxa_decoder;
+extern AVCodec ff_dxtory_decoder;
+extern AVCodec ff_dxv_decoder;
+extern AVCodec ff_eacmv_decoder;
+extern AVCodec ff_eamad_decoder;
+extern AVCodec ff_eatgq_decoder;
+extern AVCodec ff_eatgv_decoder;
+extern AVCodec ff_eatqi_decoder;
+extern AVCodec ff_eightbps_decoder;
+extern AVCodec ff_eightsvx_exp_decoder;
+extern AVCodec ff_eightsvx_fib_decoder;
+extern AVCodec ff_escape124_decoder;
+extern AVCodec ff_escape130_decoder;
+extern AVCodec ff_exr_encoder;
+extern AVCodec ff_exr_decoder;
+extern AVCodec ff_ffv1_encoder;
+extern AVCodec ff_ffv1_decoder;
+extern AVCodec ff_ffvhuff_encoder;
+extern AVCodec ff_ffvhuff_decoder;
+extern AVCodec ff_fic_decoder;
+extern AVCodec ff_fits_encoder;
+extern AVCodec ff_fits_decoder;
+extern AVCodec ff_flashsv_encoder;
+extern AVCodec ff_flashsv_decoder;
+extern AVCodec ff_flashsv2_encoder;
+extern AVCodec ff_flashsv2_decoder;
+extern AVCodec ff_flic_decoder;
+extern AVCodec ff_flv_encoder;
+extern AVCodec ff_flv_decoder;
+extern AVCodec ff_fmvc_decoder;
+extern AVCodec ff_fourxm_decoder;
+extern AVCodec ff_fraps_decoder;
+extern AVCodec ff_frwu_decoder;
+extern AVCodec ff_g2m_decoder;
+extern AVCodec ff_gdv_decoder;
+extern AVCodec ff_gif_encoder;
+extern AVCodec ff_gif_decoder;
+extern AVCodec ff_h261_encoder;
+extern AVCodec ff_h261_decoder;
+extern AVCodec ff_h263_encoder;
+extern AVCodec ff_h263_decoder;
+extern AVCodec ff_h263i_decoder;
+extern AVCodec ff_h263p_encoder;
+extern AVCodec ff_h263p_decoder;
+extern AVCodec ff_h263_v4l2m2m_decoder;
+extern AVCodec ff_h264_decoder;
+extern AVCodec ff_h264_crystalhd_decoder;
+extern AVCodec ff_h264_v4l2m2m_decoder;
+extern AVCodec ff_h264_mediacodec_decoder;
+extern AVCodec ff_h264_mmal_decoder;
+extern AVCodec ff_h264_qsv_decoder;
+extern AVCodec ff_h264_rkmpp_decoder;
+extern AVCodec ff_hap_encoder;
+extern AVCodec ff_hap_decoder;
+extern AVCodec ff_hevc_decoder;
+extern AVCodec ff_hevc_qsv_decoder;
+extern AVCodec ff_hevc_rkmpp_decoder;
+extern AVCodec ff_hevc_v4l2m2m_decoder;
+extern AVCodec ff_hnm4_video_decoder;
+extern AVCodec ff_hq_hqa_decoder;
+extern AVCodec ff_hqx_decoder;
+extern AVCodec ff_huffyuv_encoder;
+extern AVCodec ff_huffyuv_decoder;
+extern AVCodec ff_hymt_decoder;
+extern AVCodec ff_idcin_decoder;
+extern AVCodec ff_iff_ilbm_decoder;
+extern AVCodec ff_imm4_decoder;
+extern AVCodec ff_imm5_decoder;
+extern AVCodec ff_indeo2_decoder;
+extern AVCodec ff_indeo3_decoder;
+extern AVCodec ff_indeo4_decoder;
+extern AVCodec ff_indeo5_decoder;
+extern AVCodec ff_interplay_video_decoder;
+extern AVCodec ff_ipu_decoder;
+extern AVCodec ff_jpeg2000_encoder;
+extern AVCodec ff_jpeg2000_decoder;
+extern AVCodec ff_jpegls_encoder;
+extern AVCodec ff_jpegls_decoder;
+extern AVCodec ff_jv_decoder;
+extern AVCodec ff_kgv1_decoder;
+extern AVCodec ff_kmvc_decoder;
+extern AVCodec ff_lagarith_decoder;
+extern AVCodec ff_ljpeg_encoder;
+extern AVCodec ff_loco_decoder;
+extern AVCodec ff_lscr_decoder;
+extern AVCodec ff_m101_decoder;
+extern AVCodec ff_magicyuv_encoder;
+extern AVCodec ff_magicyuv_decoder;
+extern AVCodec ff_mdec_decoder;
+extern AVCodec ff_mimic_decoder;
+extern AVCodec ff_mjpeg_encoder;
+extern AVCodec ff_mjpeg_decoder;
+extern AVCodec ff_mjpegb_decoder;
+extern AVCodec ff_mmvideo_decoder;
+extern AVCodec ff_mobiclip_decoder;
+extern AVCodec ff_motionpixels_decoder;
+extern AVCodec ff_mpeg1video_encoder;
+extern AVCodec ff_mpeg1video_decoder;
+extern AVCodec ff_mpeg2video_encoder;
+extern AVCodec ff_mpeg2video_decoder;
+extern AVCodec ff_mpeg4_encoder;
+extern AVCodec ff_mpeg4_decoder;
+extern AVCodec ff_mpeg4_crystalhd_decoder;
+extern AVCodec ff_mpeg4_v4l2m2m_decoder;
+extern AVCodec ff_mpeg4_mmal_decoder;
+extern AVCodec ff_mpegvideo_decoder;
+extern AVCodec ff_mpeg1_v4l2m2m_decoder;
+extern AVCodec ff_mpeg2_mmal_decoder;
+extern AVCodec ff_mpeg2_crystalhd_decoder;
+extern AVCodec ff_mpeg2_v4l2m2m_decoder;
+extern AVCodec ff_mpeg2_qsv_decoder;
+extern AVCodec ff_mpeg2_mediacodec_decoder;
+extern AVCodec ff_msa1_decoder;
+extern AVCodec ff_mscc_decoder;
+extern AVCodec ff_msmpeg4v1_decoder;
+extern AVCodec ff_msmpeg4v2_encoder;
+extern AVCodec ff_msmpeg4v2_decoder;
+extern AVCodec ff_msmpeg4v3_encoder;
+extern AVCodec ff_msmpeg4v3_decoder;
+extern AVCodec ff_msmpeg4_crystalhd_decoder;
+extern AVCodec ff_msp2_decoder;
+extern AVCodec ff_msrle_decoder;
+extern AVCodec ff_mss1_decoder;
+extern AVCodec ff_mss2_decoder;
+extern AVCodec ff_msvideo1_encoder;
+extern AVCodec ff_msvideo1_decoder;
+extern AVCodec ff_mszh_decoder;
+extern AVCodec ff_mts2_decoder;
+extern AVCodec ff_mv30_decoder;
+extern AVCodec ff_mvc1_decoder;
+extern AVCodec ff_mvc2_decoder;
+extern AVCodec ff_mvdv_decoder;
+extern AVCodec ff_mvha_decoder;
+extern AVCodec ff_mwsc_decoder;
+extern AVCodec ff_mxpeg_decoder;
+extern AVCodec ff_notchlc_decoder;
+extern AVCodec ff_nuv_decoder;
+extern AVCodec ff_paf_video_decoder;
+extern AVCodec ff_pam_encoder;
+extern AVCodec ff_pam_decoder;
+extern AVCodec ff_pbm_encoder;
+extern AVCodec ff_pbm_decoder;
+extern AVCodec ff_pcx_encoder;
+extern AVCodec ff_pcx_decoder;
+extern AVCodec ff_pfm_encoder;
+extern AVCodec ff_pfm_decoder;
+extern AVCodec ff_pgm_encoder;
+extern AVCodec ff_pgm_decoder;
+extern AVCodec ff_pgmyuv_encoder;
+extern AVCodec ff_pgmyuv_decoder;
+extern AVCodec ff_pgx_decoder;
+extern AVCodec ff_photocd_decoder;
+extern AVCodec ff_pictor_decoder;
+extern AVCodec ff_pixlet_decoder;
+extern AVCodec ff_png_encoder;
+extern AVCodec ff_png_decoder;
+extern AVCodec ff_ppm_encoder;
+extern AVCodec ff_ppm_decoder;
+extern AVCodec ff_prores_encoder;
+extern AVCodec ff_prores_decoder;
+extern AVCodec ff_prores_aw_encoder;
+extern AVCodec ff_prores_ks_encoder;
+extern AVCodec ff_prosumer_decoder;
+extern AVCodec ff_psd_decoder;
+extern AVCodec ff_ptx_decoder;
+extern AVCodec ff_qdraw_decoder;
+extern AVCodec ff_qpeg_decoder;
+extern AVCodec ff_qtrle_encoder;
+extern AVCodec ff_qtrle_decoder;
+extern AVCodec ff_r10k_encoder;
+extern AVCodec ff_r10k_decoder;
+extern AVCodec ff_r210_encoder;
+extern AVCodec ff_r210_decoder;
+extern AVCodec ff_rasc_decoder;
+extern AVCodec ff_rawvideo_encoder;
+extern AVCodec ff_rawvideo_decoder;
+extern AVCodec ff_rl2_decoder;
+extern AVCodec ff_roq_encoder;
+extern AVCodec ff_roq_decoder;
+extern AVCodec ff_rpza_encoder;
+extern AVCodec ff_rpza_decoder;
+extern AVCodec ff_rscc_decoder;
+extern AVCodec ff_rv10_encoder;
+extern AVCodec ff_rv10_decoder;
+extern AVCodec ff_rv20_encoder;
+extern AVCodec ff_rv20_decoder;
+extern AVCodec ff_rv30_decoder;
+extern AVCodec ff_rv40_decoder;
+extern AVCodec ff_s302m_encoder;
+extern AVCodec ff_s302m_decoder;
+extern AVCodec ff_sanm_decoder;
+extern AVCodec ff_scpr_decoder;
+extern AVCodec ff_screenpresso_decoder;
+extern AVCodec ff_sga_decoder;
+extern AVCodec ff_sgi_encoder;
+extern AVCodec ff_sgi_decoder;
+extern AVCodec ff_sgirle_decoder;
+extern AVCodec ff_sheervideo_decoder;
+extern AVCodec ff_simbiosis_imx_decoder;
+extern AVCodec ff_smacker_decoder;
+extern AVCodec ff_smc_decoder;
+extern AVCodec ff_smvjpeg_decoder;
+extern AVCodec ff_snow_encoder;
+extern AVCodec ff_snow_decoder;
+extern AVCodec ff_sp5x_decoder;
+extern AVCodec ff_speedhq_decoder;
+extern AVCodec ff_speedhq_encoder;
+extern AVCodec ff_srgc_decoder;
+extern AVCodec ff_sunrast_encoder;
+extern AVCodec ff_sunrast_decoder;
+extern AVCodec ff_svq1_encoder;
+extern AVCodec ff_svq1_decoder;
+extern AVCodec ff_svq3_decoder;
+extern AVCodec ff_targa_encoder;
+extern AVCodec ff_targa_decoder;
+extern AVCodec ff_targa_y216_decoder;
+extern AVCodec ff_tdsc_decoder;
+extern AVCodec ff_theora_decoder;
+extern AVCodec ff_thp_decoder;
+extern AVCodec ff_tiertexseqvideo_decoder;
+extern AVCodec ff_tiff_encoder;
+extern AVCodec ff_tiff_decoder;
+extern AVCodec ff_tmv_decoder;
+extern AVCodec ff_truemotion1_decoder;
+extern AVCodec ff_truemotion2_decoder;
+extern AVCodec ff_truemotion2rt_decoder;
+extern AVCodec ff_tscc_decoder;
+extern AVCodec ff_tscc2_decoder;
+extern AVCodec ff_txd_decoder;
+extern AVCodec ff_ulti_decoder;
+extern AVCodec ff_utvideo_encoder;
+extern AVCodec ff_utvideo_decoder;
+extern AVCodec ff_v210_encoder;
+extern AVCodec ff_v210_decoder;
+extern AVCodec ff_v210x_decoder;
+extern AVCodec ff_v308_encoder;
+extern AVCodec ff_v308_decoder;
+extern AVCodec ff_v408_encoder;
+extern AVCodec ff_v408_decoder;
+extern AVCodec ff_v410_encoder;
+extern AVCodec ff_v410_decoder;
+extern AVCodec ff_vb_decoder;
+extern AVCodec ff_vble_decoder;
+extern AVCodec ff_vc1_decoder;
+extern AVCodec ff_vc1_crystalhd_decoder;
+extern AVCodec ff_vc1image_decoder;
+extern AVCodec ff_vc1_mmal_decoder;
+extern AVCodec ff_vc1_qsv_decoder;
+extern AVCodec ff_vc1_v4l2m2m_decoder;
+extern AVCodec ff_vc2_encoder;
+extern AVCodec ff_vcr1_decoder;
+extern AVCodec ff_vmdvideo_decoder;
+extern AVCodec ff_vmnc_decoder;
+extern AVCodec ff_vp3_decoder;
+extern AVCodec ff_vp4_decoder;
+extern AVCodec ff_vp5_decoder;
+extern AVCodec ff_vp6_decoder;
+extern AVCodec ff_vp6a_decoder;
+extern AVCodec ff_vp6f_decoder;
+extern AVCodec ff_vp7_decoder;
+extern AVCodec ff_vp8_decoder;
+extern AVCodec ff_vp8_rkmpp_decoder;
+extern AVCodec ff_vp8_v4l2m2m_decoder;
+extern AVCodec ff_vp9_decoder;
+extern AVCodec ff_vp9_rkmpp_decoder;
+extern AVCodec ff_vp9_v4l2m2m_decoder;
+extern AVCodec ff_vqa_decoder;
+extern AVCodec ff_webp_decoder;
+extern AVCodec ff_wcmv_decoder;
+extern AVCodec ff_wrapped_avframe_encoder;
+extern AVCodec ff_wrapped_avframe_decoder;
+extern AVCodec ff_wmv1_encoder;
+extern AVCodec ff_wmv1_decoder;
+extern AVCodec ff_wmv2_encoder;
+extern AVCodec ff_wmv2_decoder;
+extern AVCodec ff_wmv3_decoder;
+extern AVCodec ff_wmv3_crystalhd_decoder;
+extern AVCodec ff_wmv3image_decoder;
+extern AVCodec ff_wnv1_decoder;
+extern AVCodec ff_xan_wc3_decoder;
+extern AVCodec ff_xan_wc4_decoder;
+extern AVCodec ff_xbm_encoder;
+extern AVCodec ff_xbm_decoder;
+extern AVCodec ff_xface_encoder;
+extern AVCodec ff_xface_decoder;
+extern AVCodec ff_xl_decoder;
+extern AVCodec ff_xpm_decoder;
+extern AVCodec ff_xwd_encoder;
+extern AVCodec ff_xwd_decoder;
+extern AVCodec ff_y41p_encoder;
+extern AVCodec ff_y41p_decoder;
+extern AVCodec ff_ylc_decoder;
+extern AVCodec ff_yop_decoder;
+extern AVCodec ff_yuv4_encoder;
+extern AVCodec ff_yuv4_decoder;
+extern AVCodec ff_zero12v_decoder;
+extern AVCodec ff_zerocodec_decoder;
+extern AVCodec ff_zlib_encoder;
+extern AVCodec ff_zlib_decoder;
+extern AVCodec ff_zmbv_encoder;
+extern AVCodec ff_zmbv_decoder;
+
+/* audio codecs */
+extern AVCodec ff_aac_encoder;
+extern AVCodec ff_aac_decoder;
+extern AVCodec ff_aac_fixed_decoder;
+extern AVCodec ff_aac_latm_decoder;
+extern AVCodec ff_ac3_encoder;
+extern AVCodec ff_ac3_decoder;
+extern AVCodec ff_ac3_fixed_encoder;
+extern AVCodec ff_ac3_fixed_decoder;
+extern AVCodec ff_acelp_kelvin_decoder;
+extern AVCodec ff_alac_encoder;
+extern AVCodec ff_alac_decoder;
+extern AVCodec ff_als_decoder;
+extern AVCodec ff_amrnb_decoder;
+extern AVCodec ff_amrwb_decoder;
+extern AVCodec ff_ape_decoder;
+extern AVCodec ff_aptx_encoder;
+extern AVCodec ff_aptx_decoder;
+extern AVCodec ff_aptx_hd_encoder;
+extern AVCodec ff_aptx_hd_decoder;
+extern AVCodec ff_atrac1_decoder;
+extern AVCodec ff_atrac3_decoder;
+extern AVCodec ff_atrac3al_decoder;
+extern AVCodec ff_atrac3p_decoder;
+extern AVCodec ff_atrac3pal_decoder;
+extern AVCodec ff_atrac9_decoder;
+extern AVCodec ff_binkaudio_dct_decoder;
+extern AVCodec ff_binkaudio_rdft_decoder;
+extern AVCodec ff_bmv_audio_decoder;
+extern AVCodec ff_cook_decoder;
+extern AVCodec ff_dca_encoder;
+extern AVCodec ff_dca_decoder;
+extern AVCodec ff_dolby_e_decoder;
+extern AVCodec ff_dsd_lsbf_decoder;
+extern AVCodec ff_dsd_msbf_decoder;
+extern AVCodec ff_dsd_lsbf_planar_decoder;
+extern AVCodec ff_dsd_msbf_planar_decoder;
+extern AVCodec ff_dsicinaudio_decoder;
+extern AVCodec ff_dss_sp_decoder;
+extern AVCodec ff_dst_decoder;
+extern AVCodec ff_eac3_encoder;
+extern AVCodec ff_eac3_decoder;
+extern AVCodec ff_evrc_decoder;
+extern AVCodec ff_fastaudio_decoder;
+extern AVCodec ff_ffwavesynth_decoder;
+extern AVCodec ff_flac_encoder;
+extern AVCodec ff_flac_decoder;
+extern AVCodec ff_g723_1_encoder;
+extern AVCodec ff_g723_1_decoder;
+extern AVCodec ff_g729_decoder;
+extern AVCodec ff_gsm_decoder;
+extern AVCodec ff_gsm_ms_decoder;
+extern AVCodec ff_hca_decoder;
+extern AVCodec ff_hcom_decoder;
+extern AVCodec ff_iac_decoder;
+extern AVCodec ff_ilbc_decoder;
+extern AVCodec ff_imc_decoder;
+extern AVCodec ff_interplay_acm_decoder;
+extern AVCodec ff_mace3_decoder;
+extern AVCodec ff_mace6_decoder;
+extern AVCodec ff_metasound_decoder;
+extern AVCodec ff_mlp_encoder;
+extern AVCodec ff_mlp_decoder;
+extern AVCodec ff_mp1_decoder;
+extern AVCodec ff_mp1float_decoder;
+extern AVCodec ff_mp2_encoder;
+extern AVCodec ff_mp2_decoder;
+extern AVCodec ff_mp2float_decoder;
+extern AVCodec ff_mp2fixed_encoder;
+extern AVCodec ff_mp3float_decoder;
+extern AVCodec ff_mp3_decoder;
+extern AVCodec ff_mp3adufloat_decoder;
+extern AVCodec ff_mp3adu_decoder;
+extern AVCodec ff_mp3on4float_decoder;
+extern AVCodec ff_mp3on4_decoder;
+extern AVCodec ff_mpc7_decoder;
+extern AVCodec ff_mpc8_decoder;
+extern AVCodec ff_nellymoser_encoder;
+extern AVCodec ff_nellymoser_decoder;
+extern AVCodec ff_on2avc_decoder;
+extern AVCodec ff_opus_encoder;
+extern AVCodec ff_opus_decoder;
+extern AVCodec ff_paf_audio_decoder;
+extern AVCodec ff_qcelp_decoder;
+extern AVCodec ff_qdm2_decoder;
+extern AVCodec ff_qdmc_decoder;
+extern AVCodec ff_ra_144_encoder;
+extern AVCodec ff_ra_144_decoder;
+extern AVCodec ff_ra_288_decoder;
+extern AVCodec ff_ralf_decoder;
+extern AVCodec ff_sbc_encoder;
+extern AVCodec ff_sbc_decoder;
+extern AVCodec ff_shorten_decoder;
+extern AVCodec ff_sipr_decoder;
+extern AVCodec ff_siren_decoder;
+extern AVCodec ff_smackaud_decoder;
+extern AVCodec ff_sonic_encoder;
+extern AVCodec ff_sonic_decoder;
+extern AVCodec ff_sonic_ls_encoder;
+extern AVCodec ff_tak_decoder;
+extern AVCodec ff_truehd_encoder;
+extern AVCodec ff_truehd_decoder;
+extern AVCodec ff_truespeech_decoder;
+extern AVCodec ff_tta_encoder;
+extern AVCodec ff_tta_decoder;
+extern AVCodec ff_twinvq_decoder;
+extern AVCodec ff_vmdaudio_decoder;
+extern AVCodec ff_vorbis_encoder;
+extern AVCodec ff_vorbis_decoder;
+extern AVCodec ff_wavpack_encoder;
+extern AVCodec ff_wavpack_decoder;
+extern AVCodec ff_wmalossless_decoder;
+extern AVCodec ff_wmapro_decoder;
+extern AVCodec ff_wmav1_encoder;
+extern AVCodec ff_wmav1_decoder;
+extern AVCodec ff_wmav2_encoder;
+extern AVCodec ff_wmav2_decoder;
+extern AVCodec ff_wmavoice_decoder;
+extern AVCodec ff_ws_snd1_decoder;
+extern AVCodec ff_xma1_decoder;
+extern AVCodec ff_xma2_decoder;
+
+/* PCM codecs */
+extern AVCodec ff_pcm_alaw_encoder;
+extern AVCodec ff_pcm_alaw_decoder;
+extern AVCodec ff_pcm_bluray_decoder;
+extern AVCodec ff_pcm_dvd_encoder;
+extern AVCodec ff_pcm_dvd_decoder;
+extern AVCodec ff_pcm_f16le_decoder;
+extern AVCodec ff_pcm_f24le_decoder;
+extern AVCodec ff_pcm_f32be_encoder;
+extern AVCodec ff_pcm_f32be_decoder;
+extern AVCodec ff_pcm_f32le_encoder;
+extern AVCodec ff_pcm_f32le_decoder;
+extern AVCodec ff_pcm_f64be_encoder;
+extern AVCodec ff_pcm_f64be_decoder;
+extern AVCodec ff_pcm_f64le_encoder;
+extern AVCodec ff_pcm_f64le_decoder;
+extern AVCodec ff_pcm_lxf_decoder;
+extern AVCodec ff_pcm_mulaw_encoder;
+extern AVCodec ff_pcm_mulaw_decoder;
+extern AVCodec ff_pcm_s8_encoder;
+extern AVCodec ff_pcm_s8_decoder;
+extern AVCodec ff_pcm_s8_planar_encoder;
+extern AVCodec ff_pcm_s8_planar_decoder;
+extern AVCodec ff_pcm_s16be_encoder;
+extern AVCodec ff_pcm_s16be_decoder;
+extern AVCodec ff_pcm_s16be_planar_encoder;
+extern AVCodec ff_pcm_s16be_planar_decoder;
+extern AVCodec ff_pcm_s16le_encoder;
+extern AVCodec ff_pcm_s16le_decoder;
+extern AVCodec ff_pcm_s16le_planar_encoder;
+extern AVCodec ff_pcm_s16le_planar_decoder;
+extern AVCodec ff_pcm_s24be_encoder;
+extern AVCodec ff_pcm_s24be_decoder;
+extern AVCodec ff_pcm_s24daud_encoder;
+extern AVCodec ff_pcm_s24daud_decoder;
+extern AVCodec ff_pcm_s24le_encoder;
+extern AVCodec ff_pcm_s24le_decoder;
+extern AVCodec ff_pcm_s24le_planar_encoder;
+extern AVCodec ff_pcm_s24le_planar_decoder;
+extern AVCodec ff_pcm_s32be_encoder;
+extern AVCodec ff_pcm_s32be_decoder;
+extern AVCodec ff_pcm_s32le_encoder;
+extern AVCodec ff_pcm_s32le_decoder;
+extern AVCodec ff_pcm_s32le_planar_encoder;
+extern AVCodec ff_pcm_s32le_planar_decoder;
+extern AVCodec ff_pcm_s64be_encoder;
+extern AVCodec ff_pcm_s64be_decoder;
+extern AVCodec ff_pcm_s64le_encoder;
+extern AVCodec ff_pcm_s64le_decoder;
+extern AVCodec ff_pcm_sga_decoder;
+extern AVCodec ff_pcm_u8_encoder;
+extern AVCodec ff_pcm_u8_decoder;
+extern AVCodec ff_pcm_u16be_encoder;
+extern AVCodec ff_pcm_u16be_decoder;
+extern AVCodec ff_pcm_u16le_encoder;
+extern AVCodec ff_pcm_u16le_decoder;
+extern AVCodec ff_pcm_u24be_encoder;
+extern AVCodec ff_pcm_u24be_decoder;
+extern AVCodec ff_pcm_u24le_encoder;
+extern AVCodec ff_pcm_u24le_decoder;
+extern AVCodec ff_pcm_u32be_encoder;
+extern AVCodec ff_pcm_u32be_decoder;
+extern AVCodec ff_pcm_u32le_encoder;
+extern AVCodec ff_pcm_u32le_decoder;
+extern AVCodec ff_pcm_vidc_encoder;
+extern AVCodec ff_pcm_vidc_decoder;
+
+/* DPCM codecs */
+extern AVCodec ff_derf_dpcm_decoder;
+extern AVCodec ff_gremlin_dpcm_decoder;
+extern AVCodec ff_interplay_dpcm_decoder;
+extern AVCodec ff_roq_dpcm_encoder;
+extern AVCodec ff_roq_dpcm_decoder;
+extern AVCodec ff_sdx2_dpcm_decoder;
+extern AVCodec ff_sol_dpcm_decoder;
+extern AVCodec ff_xan_dpcm_decoder;
+
+/* ADPCM codecs */
+extern AVCodec ff_adpcm_4xm_decoder;
+extern AVCodec ff_adpcm_adx_encoder;
+extern AVCodec ff_adpcm_adx_decoder;
+extern AVCodec ff_adpcm_afc_decoder;
+extern AVCodec ff_adpcm_agm_decoder;
+extern AVCodec ff_adpcm_aica_decoder;
+extern AVCodec ff_adpcm_argo_decoder;
+extern AVCodec ff_adpcm_argo_encoder;
+extern AVCodec ff_adpcm_ct_decoder;
+extern AVCodec ff_adpcm_dtk_decoder;
+extern AVCodec ff_adpcm_ea_decoder;
+extern AVCodec ff_adpcm_ea_maxis_xa_decoder;
+extern AVCodec ff_adpcm_ea_r1_decoder;
+extern AVCodec ff_adpcm_ea_r2_decoder;
+extern AVCodec ff_adpcm_ea_r3_decoder;
+extern AVCodec ff_adpcm_ea_xas_decoder;
+extern AVCodec ff_adpcm_g722_encoder;
+extern AVCodec ff_adpcm_g722_decoder;
+extern AVCodec ff_adpcm_g726_encoder;
+extern AVCodec ff_adpcm_g726_decoder;
+extern AVCodec ff_adpcm_g726le_encoder;
+extern AVCodec ff_adpcm_g726le_decoder;
+extern AVCodec ff_adpcm_ima_amv_decoder;
+extern AVCodec ff_adpcm_ima_amv_encoder;
+extern AVCodec ff_adpcm_ima_alp_decoder;
+extern AVCodec ff_adpcm_ima_alp_encoder;
+extern AVCodec ff_adpcm_ima_apc_decoder;
+extern AVCodec ff_adpcm_ima_apm_decoder;
+extern AVCodec ff_adpcm_ima_apm_encoder;
+extern AVCodec ff_adpcm_ima_cunning_decoder;
+extern AVCodec ff_adpcm_ima_dat4_decoder;
+extern AVCodec ff_adpcm_ima_dk3_decoder;
+extern AVCodec ff_adpcm_ima_dk4_decoder;
+extern AVCodec ff_adpcm_ima_ea_eacs_decoder;
+extern AVCodec ff_adpcm_ima_ea_sead_decoder;
+extern AVCodec ff_adpcm_ima_iss_decoder;
+extern AVCodec ff_adpcm_ima_moflex_decoder;
+extern AVCodec ff_adpcm_ima_mtf_decoder;
+extern AVCodec ff_adpcm_ima_oki_decoder;
+extern AVCodec ff_adpcm_ima_qt_encoder;
+extern AVCodec ff_adpcm_ima_qt_decoder;
+extern AVCodec ff_adpcm_ima_rad_decoder;
+extern AVCodec ff_adpcm_ima_ssi_decoder;
+extern AVCodec ff_adpcm_ima_ssi_encoder;
+extern AVCodec ff_adpcm_ima_smjpeg_decoder;
+extern AVCodec ff_adpcm_ima_wav_encoder;
+extern AVCodec ff_adpcm_ima_wav_decoder;
+extern AVCodec ff_adpcm_ima_ws_decoder;
+extern AVCodec ff_adpcm_ms_encoder;
+extern AVCodec ff_adpcm_ms_decoder;
+extern AVCodec ff_adpcm_mtaf_decoder;
+extern AVCodec ff_adpcm_psx_decoder;
+extern AVCodec ff_adpcm_sbpro_2_decoder;
+extern AVCodec ff_adpcm_sbpro_3_decoder;
+extern AVCodec ff_adpcm_sbpro_4_decoder;
+extern AVCodec ff_adpcm_swf_encoder;
+extern AVCodec ff_adpcm_swf_decoder;
+extern AVCodec ff_adpcm_thp_decoder;
+extern AVCodec ff_adpcm_thp_le_decoder;
+extern AVCodec ff_adpcm_vima_decoder;
+extern AVCodec ff_adpcm_xa_decoder;
+extern AVCodec ff_adpcm_yamaha_encoder;
+extern AVCodec ff_adpcm_yamaha_decoder;
+extern AVCodec ff_adpcm_zork_decoder;
+
+/* subtitles */
+extern AVCodec ff_ssa_encoder;
+extern AVCodec ff_ssa_decoder;
+extern AVCodec ff_ass_encoder;
+extern AVCodec ff_ass_decoder;
+extern AVCodec ff_ccaption_decoder;
+extern AVCodec ff_dvbsub_encoder;
+extern AVCodec ff_dvbsub_decoder;
+extern AVCodec ff_dvdsub_encoder;
+extern AVCodec ff_dvdsub_decoder;
+extern AVCodec ff_jacosub_decoder;
+extern AVCodec ff_microdvd_decoder;
+extern AVCodec ff_movtext_encoder;
+extern AVCodec ff_movtext_decoder;
+extern AVCodec ff_mpl2_decoder;
+extern AVCodec ff_pgssub_decoder;
+extern AVCodec ff_pjs_decoder;
+extern AVCodec ff_realtext_decoder;
+extern AVCodec ff_sami_decoder;
+extern AVCodec ff_srt_encoder;
+extern AVCodec ff_srt_decoder;
+extern AVCodec ff_stl_decoder;
+extern AVCodec ff_subrip_encoder;
+extern AVCodec ff_subrip_decoder;
+extern AVCodec ff_subviewer_decoder;
+extern AVCodec ff_subviewer1_decoder;
+extern AVCodec ff_text_encoder;
+extern AVCodec ff_text_decoder;
+extern AVCodec ff_ttml_encoder;
+extern AVCodec ff_vplayer_decoder;
+extern AVCodec ff_webvtt_encoder;
+extern AVCodec ff_webvtt_decoder;
+extern AVCodec ff_xsub_encoder;
+extern AVCodec ff_xsub_decoder;
+
+/* external libraries */
+extern AVCodec ff_aac_at_encoder;
+extern AVCodec ff_aac_at_decoder;
+extern AVCodec ff_ac3_at_decoder;
+extern AVCodec ff_adpcm_ima_qt_at_decoder;
+extern AVCodec ff_alac_at_encoder;
+extern AVCodec ff_alac_at_decoder;
+extern AVCodec ff_amr_nb_at_decoder;
+extern AVCodec ff_eac3_at_decoder;
+extern AVCodec ff_gsm_ms_at_decoder;
+extern AVCodec ff_ilbc_at_encoder;
+extern AVCodec ff_ilbc_at_decoder;
+extern AVCodec ff_mp1_at_decoder;
+extern AVCodec ff_mp2_at_decoder;
+extern AVCodec ff_mp3_at_decoder;
+extern AVCodec ff_pcm_alaw_at_encoder;
+extern AVCodec ff_pcm_alaw_at_decoder;
+extern AVCodec ff_pcm_mulaw_at_encoder;
+extern AVCodec ff_pcm_mulaw_at_decoder;
+extern AVCodec ff_qdmc_at_decoder;
+extern AVCodec ff_qdm2_at_decoder;
+extern AVCodec ff_libaom_av1_encoder;
+extern AVCodec ff_libaribb24_decoder;
+extern AVCodec ff_libcelt_decoder;
+extern AVCodec ff_libcodec2_encoder;
+extern AVCodec ff_libcodec2_decoder;
+extern AVCodec ff_libdav1d_decoder;
+extern AVCodec ff_libdavs2_decoder;
+extern AVCodec ff_libfdk_aac_encoder;
+extern AVCodec ff_libfdk_aac_decoder;
+extern AVCodec ff_libgsm_encoder;
+extern AVCodec ff_libgsm_decoder;
+extern AVCodec ff_libgsm_ms_encoder;
+extern AVCodec ff_libgsm_ms_decoder;
+extern AVCodec ff_libilbc_encoder;
+extern AVCodec ff_libilbc_decoder;
+extern AVCodec ff_libmp3lame_encoder;
+extern AVCodec ff_libopencore_amrnb_encoder;
+extern AVCodec ff_libopencore_amrnb_decoder;
+extern AVCodec ff_libopencore_amrwb_decoder;
+extern AVCodec ff_libopenjpeg_encoder;
+extern AVCodec ff_libopenjpeg_decoder;
+extern AVCodec ff_libopus_encoder;
+extern AVCodec ff_libopus_decoder;
+extern AVCodec ff_librav1e_encoder;
+extern AVCodec ff_librsvg_decoder;
+extern AVCodec ff_libshine_encoder;
+extern AVCodec ff_libspeex_encoder;
+extern AVCodec ff_libspeex_decoder;
+extern AVCodec ff_libsvtav1_encoder;
+extern AVCodec ff_libtheora_encoder;
+extern AVCodec ff_libtwolame_encoder;
+extern AVCodec ff_libuavs3d_decoder;
+extern AVCodec ff_libvo_amrwbenc_encoder;
+extern AVCodec ff_libvorbis_encoder;
+extern AVCodec ff_libvorbis_decoder;
+extern AVCodec ff_libvpx_vp8_encoder;
+extern AVCodec ff_libvpx_vp8_decoder;
+extern AVCodec ff_libvpx_vp9_encoder;
+extern AVCodec ff_libvpx_vp9_decoder;
+/* preferred over libwebp */
+extern AVCodec ff_libwebp_anim_encoder;
+extern AVCodec ff_libwebp_encoder;
+extern AVCodec ff_libx262_encoder;
+extern AVCodec ff_libx264_encoder;
+extern AVCodec ff_libx264rgb_encoder;
+extern AVCodec ff_libx265_encoder;
+extern AVCodec ff_libxavs_encoder;
+extern AVCodec ff_libxavs2_encoder;
+extern AVCodec ff_libxvid_encoder;
+extern AVCodec ff_libzvbi_teletext_decoder;
+
+/* text */
+extern AVCodec ff_bintext_decoder;
+extern AVCodec ff_xbin_decoder;
+extern AVCodec ff_idf_decoder;
+
+/* external libraries, that shouldn't be used by default if one of the
+ * above is available */
+extern AVCodec ff_aac_mf_encoder;
+extern AVCodec ff_ac3_mf_encoder;
+extern AVCodec ff_h263_v4l2m2m_encoder;
+extern AVCodec ff_libaom_av1_decoder;
+/* hwaccel hooks only, so prefer external decoders */
+extern AVCodec ff_av1_decoder;
+extern AVCodec ff_av1_cuvid_decoder;
+extern AVCodec ff_av1_qsv_decoder;
+extern AVCodec ff_libopenh264_encoder;
+extern AVCodec ff_libopenh264_decoder;
+extern AVCodec ff_h264_amf_encoder;
+extern AVCodec ff_h264_cuvid_decoder;
+extern AVCodec ff_h264_mf_encoder;
+extern AVCodec ff_h264_nvenc_encoder;
+extern AVCodec ff_h264_omx_encoder;
+extern AVCodec ff_h264_qsv_encoder;
+extern AVCodec ff_h264_v4l2m2m_encoder;
+extern AVCodec ff_h264_vaapi_encoder;
+extern AVCodec ff_h264_videotoolbox_encoder;
+#if FF_API_NVENC_OLD_NAME
+extern AVCodec ff_nvenc_encoder;
+extern AVCodec ff_nvenc_h264_encoder;
+extern AVCodec ff_nvenc_hevc_encoder;
+#endif
+extern AVCodec ff_hevc_amf_encoder;
+extern AVCodec ff_hevc_cuvid_decoder;
+extern AVCodec ff_hevc_mediacodec_decoder;
+extern AVCodec ff_hevc_mf_encoder;
+extern AVCodec ff_hevc_nvenc_encoder;
+extern AVCodec ff_hevc_qsv_encoder;
+extern AVCodec ff_hevc_v4l2m2m_encoder;
+extern AVCodec ff_hevc_vaapi_encoder;
+extern AVCodec ff_hevc_videotoolbox_encoder;
+extern AVCodec ff_libkvazaar_encoder;
+extern AVCodec ff_mjpeg_cuvid_decoder;
+extern AVCodec ff_mjpeg_qsv_encoder;
+extern AVCodec ff_mjpeg_qsv_decoder;
+extern AVCodec ff_mjpeg_vaapi_encoder;
+extern AVCodec ff_mp3_mf_encoder;
+extern AVCodec ff_mpeg1_cuvid_decoder;
+extern AVCodec ff_mpeg2_cuvid_decoder;
+extern AVCodec ff_mpeg2_qsv_encoder;
+extern AVCodec ff_mpeg2_vaapi_encoder;
+extern AVCodec ff_mpeg4_cuvid_decoder;
+extern AVCodec ff_mpeg4_mediacodec_decoder;
+extern AVCodec ff_mpeg4_omx_encoder;
+extern AVCodec ff_mpeg4_v4l2m2m_encoder;
+extern AVCodec ff_vc1_cuvid_decoder;
+extern AVCodec ff_vp8_cuvid_decoder;
+extern AVCodec ff_vp8_mediacodec_decoder;
+extern AVCodec ff_vp8_qsv_decoder;
+extern AVCodec ff_vp8_v4l2m2m_encoder;
+extern AVCodec ff_vp8_vaapi_encoder;
+extern AVCodec ff_vp9_cuvid_decoder;
+extern AVCodec ff_vp9_mediacodec_decoder;
+extern AVCodec ff_vp9_qsv_decoder;
+extern AVCodec ff_vp9_vaapi_encoder;
+extern AVCodec ff_vp9_qsv_encoder;
+
+// The iterate API is not usable with ossfuzz due to the excessive size of binaries created
+#if CONFIG_OSSFUZZ
+AVCodec * codec_list[] = {
+    NULL,
+    NULL,
+    NULL
+};
+#else
+#include "libavcodec/codec_list.c"
+#endif
+
+static AVOnce av_codec_static_init = AV_ONCE_INIT;
+static void av_codec_init_static(void)
+{
+    for (int i = 0; codec_list[i]; i++) {
+        if (codec_list[i]->init_static_data)
+            codec_list[i]->init_static_data((AVCodec*)codec_list[i]);
+    }
+}
+
+const AVCodec *av_codec_iterate(void **opaque)
+{
+    uintptr_t i = (uintptr_t)*opaque;
+    const AVCodec *c = codec_list[i];
+
+    ff_thread_once(&av_codec_static_init, av_codec_init_static);
+
+    if (c)
+        *opaque = (void*)(i + 1);
+
+    return c;
+}
+
+#if FF_API_NEXT
+FF_DISABLE_DEPRECATION_WARNINGS
+static AVOnce av_codec_next_init = AV_ONCE_INIT;
+
+static void av_codec_init_next(void)
+{
+    AVCodec *prev = NULL, *p;
+    void *i = 0;
+    while ((p = (AVCodec*)av_codec_iterate(&i))) {
+        if (prev)
+            prev->next = p;
+        prev = p;
+    }
+}
+
+
+
+av_cold void avcodec_register(AVCodec *codec)
+{
+    ff_thread_once(&av_codec_next_init, av_codec_init_next);
+}
+
+AVCodec *av_codec_next(const AVCodec *c)
+{
+    ff_thread_once(&av_codec_next_init, av_codec_init_next);
+
+    if (c)
+        return c->next;
+    else
+        return (AVCodec*)codec_list[0];
+}
+
+void avcodec_register_all(void)
+{
+    ff_thread_once(&av_codec_next_init, av_codec_init_next);
+}
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+
+static enum AVCodecID remap_deprecated_codec_id(enum AVCodecID id)
+{
+    switch(id){
+        //This is for future deprecatec codec ids, its empty since
+        //last major bump but will fill up again over time, please don't remove it
+        default                                         : return id;
+    }
+}
+
+static AVCodec *find_codec(enum AVCodecID id, int (*x)(const AVCodec *))
+{
+    const AVCodec *p, *experimental = NULL;
+    void *i = 0;
+
+    id = remap_deprecated_codec_id(id);
+
+    while ((p = av_codec_iterate(&i))) {
+        if (!x(p))
+            continue;
+        if (p->id == id) {
+            if (p->capabilities & AV_CODEC_CAP_EXPERIMENTAL && !experimental) {
+                experimental = p;
+            } else
+                return (AVCodec*)p;
+        }
+    }
+
+    return (AVCodec*)experimental;
+}
+
+AVCodec *avcodec_find_encoder(enum AVCodecID id)
+{
+    return find_codec(id, av_codec_is_encoder);
+}
+
+AVCodec *avcodec_find_decoder(enum AVCodecID id)
+{
+    return find_codec(id, av_codec_is_decoder);
+}
+
+static AVCodec *find_codec_by_name(const char *name, int (*x)(const AVCodec *))
+{
+    void *i = 0;
+    const AVCodec *p;
+
+    if (!name)
+        return NULL;
+
+    while ((p = av_codec_iterate(&i))) {
+        if (!x(p))
+            continue;
+        if (strcmp(name, p->name) == 0)
+            return (AVCodec*)p;
+    }
+
+    return NULL;
+}
+
+AVCodec *avcodec_find_encoder_by_name(const char *name)
+{
+    return find_codec_by_name(name, av_codec_is_encoder);
+}
+
+AVCodec *avcodec_find_decoder_by_name(const char *name)
+{
+    return find_codec_by_name(name, av_codec_is_decoder);
+}
diff -Naur ffmpeg-4.4-N-Alpha1/libavcodec/Makefile ffmpeg-4.4-N-Alpha1-2/libavcodec/Makefile
--- ffmpeg-4.4-N-Alpha1/libavcodec/Makefile	2022-04-20 03:47:13.928503993 +0200
+++ ffmpeg-4.4-N-Alpha1-2/libavcodec/Makefile	2022-04-20 03:54:01.069999112 +0200
@@ -133,6 +133,7 @@
                                           mpegvideoencdsp.o
 OBJS-$(CONFIG_MSS34DSP)                += mss34dsp.o
 OBJS-$(CONFIG_NVENC)                   += nvenc.o
+OBJS-$(CONFIG_NVV4L2)                  += nvv4l2.o
 OBJS-$(CONFIG_PIXBLOCKDSP)             += pixblockdsp.o
 OBJS-$(CONFIG_QPELDSP)                 += qpeldsp.o
 OBJS-$(CONFIG_QSV)                     += qsv.o
@@ -373,12 +374,14 @@
                                           h264_slice.o h264data.o
 OBJS-$(CONFIG_H264_AMF_ENCODER)        += amfenc_h264.o
 OBJS-$(CONFIG_H264_CUVID_DECODER)      += cuviddec.o
+OBJS-$(CONFIG_H264_NVV4L2_DECODER)     += nvv4l2_dec.o
 OBJS-$(CONFIG_H264_MEDIACODEC_DECODER) += mediacodecdec.o
 OBJS-$(CONFIG_H264_MF_ENCODER)         += mfenc.o mf_utils.o
 OBJS-$(CONFIG_H264_MMAL_DECODER)       += mmaldec.o
 OBJS-$(CONFIG_H264_NVENC_ENCODER)      += nvenc_h264.o
 OBJS-$(CONFIG_NVENC_ENCODER)           += nvenc_h264.o
 OBJS-$(CONFIG_NVENC_H264_ENCODER)      += nvenc_h264.o
+OBJS-$(CONFIG_H264_NVV4L2_ENCODER)     += nvv4l2_enc.o
 OBJS-$(CONFIG_H264_OMX_ENCODER)        += omx.o
 OBJS-$(CONFIG_H264_QSV_DECODER)        += qsvdec.o
 OBJS-$(CONFIG_H264_QSV_ENCODER)        += qsvenc_h264.o
@@ -396,6 +399,7 @@
                                           hevcdsp.o hevc_filter.o hevc_data.o
 OBJS-$(CONFIG_HEVC_AMF_ENCODER)        += amfenc_hevc.o
 OBJS-$(CONFIG_HEVC_CUVID_DECODER)      += cuviddec.o
+OBJS-$(CONFIG_HEVC_NVV4L2_DECODER)     += nvv4l2_dec.o
 OBJS-$(CONFIG_HEVC_MEDIACODEC_DECODER) += mediacodecdec.o
 OBJS-$(CONFIG_HEVC_MF_ENCODER)         += mfenc.o mf_utils.o
 OBJS-$(CONFIG_HEVC_NVENC_ENCODER)      += nvenc_hevc.o
@@ -406,6 +410,7 @@
 OBJS-$(CONFIG_HEVC_RKMPP_DECODER)      += rkmppdec.o
 OBJS-$(CONFIG_HEVC_VAAPI_ENCODER)      += vaapi_encode_h265.o h265_profile_level.o
 OBJS-$(CONFIG_HEVC_V4L2M2M_DECODER)    += v4l2_m2m_dec.o
+OBJS-$(CONFIG_HEVC_NVV4L2_ENCODER)     += nvv4l2_enc.o
 OBJS-$(CONFIG_HEVC_V4L2M2M_ENCODER)    += v4l2_m2m_enc.o
 OBJS-$(CONFIG_HNM4_VIDEO_DECODER)      += hnm4video.o
 OBJS-$(CONFIG_HQ_HQA_DECODER)          += hq_hqa.o hq_hqadata.o hq_hqadsp.o \
@@ -496,12 +501,14 @@
 OBJS-$(CONFIG_MPEG2VIDEO_DECODER)      += mpeg12dec.o mpeg12.o mpeg12data.o
 OBJS-$(CONFIG_MPEG2VIDEO_ENCODER)      += mpeg12enc.o mpeg12.o
 OBJS-$(CONFIG_MPEG2_CUVID_DECODER)     += cuviddec.o
+OBJS-$(CONFIG_MPEG2_NVV4L2_DECODER)    += nvv4l2_dec.o
 OBJS-$(CONFIG_MPEG2_MEDIACODEC_DECODER) += mediacodecdec.o
 OBJS-$(CONFIG_MPEG2_VAAPI_ENCODER)     += vaapi_encode_mpeg2.o
 OBJS-$(CONFIG_MPEG2_V4L2M2M_DECODER)   += v4l2_m2m_dec.o
 OBJS-$(CONFIG_MPEG4_DECODER)           += xvididct.o
 OBJS-$(CONFIG_MPEG4_ENCODER)           += mpeg4videoenc.o
 OBJS-$(CONFIG_MPEG4_CUVID_DECODER)     += cuviddec.o
+OBJS-$(CONFIG_MPEG4_NVV4L2_DECODER)    += nvv4l2_dec.o
 OBJS-$(CONFIG_MPEG4_MEDIACODEC_DECODER) += mediacodecdec.o
 OBJS-$(CONFIG_MPEG4_OMX_ENCODER)       += omx.o
 OBJS-$(CONFIG_MPEG4_V4L2M2M_DECODER)   += v4l2_m2m_dec.o
@@ -716,6 +723,7 @@
 OBJS-$(CONFIG_VP7_DECODER)             += vp8.o vp56rac.o
 OBJS-$(CONFIG_VP8_DECODER)             += vp8.o vp56rac.o
 OBJS-$(CONFIG_VP8_CUVID_DECODER)       += cuviddec.o
+OBJS-$(CONFIG_VP8_NVV4L2_DECODER)      += nvv4l2_dec.o
 OBJS-$(CONFIG_VP8_MEDIACODEC_DECODER)  += mediacodecdec.o
 OBJS-$(CONFIG_VP8_QSV_DECODER)         += qsvdec.o
 OBJS-$(CONFIG_VP8_RKMPP_DECODER)       += rkmppdec.o
@@ -726,6 +734,7 @@
                                           vp9block.o vp9prob.o vp9mvs.o vp56rac.o \
                                           vp9dsp_8bpp.o vp9dsp_10bpp.o vp9dsp_12bpp.o
 OBJS-$(CONFIG_VP9_CUVID_DECODER)       += cuviddec.o
+OBJS-$(CONFIG_VP9_NVV4L2_DECODER)      += nvv4l2_dec.o
 OBJS-$(CONFIG_VP9_MEDIACODEC_DECODER)  += mediacodecdec.o
 OBJS-$(CONFIG_VP9_RKMPP_DECODER)       += rkmppdec.o
 OBJS-$(CONFIG_VP9_VAAPI_ENCODER)       += vaapi_encode_vp9.o
diff -Naur ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2.c ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2.c
--- ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2.c	1970-01-01 01:00:00.000000000 +0100
+++ ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2.c	2022-04-20 03:49:41.819220377 +0200
@@ -0,0 +1,866 @@
+/*
+ * Copyright (c) 2021-2022, CTCaer <ctcaer@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include <stdatomic.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <stdint.h>
+#include <unistd.h>
+#include <pthread.h>
+#include <string.h>
+#include <fcntl.h>
+#include <sys/mman.h>
+#include <errno.h>
+#include "internal.h"
+#include "libavutil/log.h"
+
+#include "nvv4l2.h"
+
+uint32_t nvv4l2_map_nvcodec_type(NvCodingType nv_codec_type)
+{
+    uint32_t v4l2_pix_fmt;
+    switch (nv_codec_type) {
+    case NvVideoCodec_H264:
+        v4l2_pix_fmt = V4L2_PIX_FMT_H264;
+        break;
+    case NvVideoCodec_HEVC:
+        v4l2_pix_fmt = V4L2_PIX_FMT_H265;
+        break;
+    case NvVideoCodec_MPEG2:
+        v4l2_pix_fmt = V4L2_PIX_FMT_MPEG2;
+        break;
+    case NvVideoCodec_MPEG4:
+        v4l2_pix_fmt = V4L2_PIX_FMT_MPEG4;
+        break;
+    case NvVideoCodec_VP8:
+        v4l2_pix_fmt = V4L2_PIX_FMT_VP8;
+        break;
+    case NvVideoCodec_VP9:
+        v4l2_pix_fmt = V4L2_PIX_FMT_VP9;
+        break;
+    default:
+        v4l2_pix_fmt = V4L2_PIX_FMT_H264;
+        break;
+    }
+
+    return v4l2_pix_fmt;
+}
+
+int nvv4l2_pool_idx_next(nvv4l2_ctx_t *ctx, NvQueues *q)
+{
+    int index;
+    if (q->capacity < NV_MAX_BUFFERS) {
+        index = q->back;
+    } else {
+        index = -1;
+    }
+    return index;
+}
+
+void nvv4l2_pool_push(nvv4l2_ctx_t *ctx, NvQueues *q)
+{
+    if (q->capacity < NV_MAX_BUFFERS) {
+        q->back = (q->back + 1) % NV_MAX_BUFFERS;
+        atomic_fetch_add(&q->capacity, 1);
+    } else {
+        av_log(ctx->avctx, AV_LOG_ERROR, "Queue already full!\n");
+    }
+}
+
+int nvv4l2_pool_pop(nvv4l2_ctx_t *ctx, NvQueues *q)
+{
+    int index = q->front;
+    if (q->capacity != 0) {
+        q->front = (q->front + 1) % NV_MAX_BUFFERS;
+        atomic_fetch_sub(&q->capacity, 1);
+    } else {
+        av_log(ctx->avctx, AV_LOG_ERROR, "Queue already empty!");
+    }
+    return index;
+}
+
+int
+nvv4l2_create_bufferfmt(NvBuffer *buffer, enum v4l2_buf_type buf_type,
+                     enum v4l2_memory memory_type, uint32_t n_planes,
+                     NvBufferPlaneFormat *fmt, uint32_t index)
+{
+    buffer->mapped = false;
+    buffer->buf_type = buf_type;
+    buffer->memory_type = memory_type;
+    buffer->index = index;
+    buffer->n_planes = n_planes;
+
+    memset(buffer->planes, 0, sizeof(NvBufferPlane));
+    for (uint32_t i = 0; i < buffer->n_planes; i++) {
+        buffer->planes[i].fd = -1;
+        buffer->planes[i].fmt = fmt[i];
+    }
+    return 0;
+}
+
+int
+nvv4l2_map_out(nvv4l2_ctx_t *ctx, struct v4l2_buffer *v4l2_buf,
+               enum v4l2_buf_type buf_type, enum v4l2_memory mem_type,
+               int dma_fd)
+{
+    int ret;
+    NvBuffer *buffer;
+    NvBufferParams params;
+    unsigned char *data;
+    pthread_mutex_lock(&ctx->queue_lock);
+
+    if (buf_type == ctx->op_buf_type)
+        buffer = ctx->op_buffers[v4l2_buf->index];
+    else if (buf_type == ctx->cp_buf_type)
+        buffer = ctx->cp_buffers[v4l2_buf->index];
+
+    switch (mem_type) {
+    case V4L2_MEMORY_DMABUF:
+        ret = NvBufferGetParams(dma_fd, &params);
+        if(ret) {
+            av_log(ctx->avctx, AV_LOG_ERROR, "GetParams failed!\n");
+            pthread_mutex_unlock(&ctx->queue_lock);
+            return ret;
+        }
+        for (uint32_t i = 0; i < buffer->n_planes; i++) {
+            buffer->planes[i].fd = dma_fd;
+            v4l2_buf->m.planes[i].m.fd = dma_fd;
+            buffer->planes[i].mem_offset = params.offset[i];
+            ret = NvBufferMemMap(dma_fd, i, NvBufferMem_Read_Write,
+                                 (void **)&data);
+            if (ret) {
+                ctx->in_error = true;
+                av_log(ctx->avctx, AV_LOG_ERROR,
+                       "Error while Mapping buffer!\n");
+                pthread_mutex_unlock(&ctx->queue_lock);
+                return ret;
+            }
+            buffer->planes[i].data = data;
+        }
+        break;
+    default:
+        pthread_mutex_unlock(&ctx->queue_lock);
+        return -1;
+    }
+    pthread_mutex_unlock(&ctx->queue_lock);
+
+    return ret;
+}
+
+int
+nvv4l2_unmap_out(nvv4l2_ctx_t *ctx, int index, enum v4l2_buf_type buf_type,
+                 enum v4l2_memory mem_type, int dma_fd)
+{
+    int ret = 0;
+    NvBuffer *buffer;
+    pthread_mutex_lock(&ctx->queue_lock);
+
+    if (buf_type == ctx->op_buf_type)
+        buffer = ctx->op_buffers[index];
+    else if (buf_type == ctx->cp_buf_type)
+        buffer = ctx->cp_buffers[index];
+
+    switch (mem_type) {
+    case V4L2_MEMORY_DMABUF:
+        for (uint32_t i = 0; i < buffer->n_planes; i++) {
+            ret = NvBufferMemUnMap(dma_fd, i, (void **)&buffer->planes[i].data);
+            if (ret) {
+                ctx->in_error = true;
+                av_log(ctx->avctx, AV_LOG_ERROR,
+                       "Error while Unmapping buffer!\n");
+                pthread_mutex_unlock(&ctx->queue_lock);
+                return ret;
+            }
+        }
+        break;
+    default:
+        pthread_mutex_unlock(&ctx->queue_lock);
+        return -1;
+    }
+    pthread_mutex_unlock(&ctx->queue_lock);
+
+    return ret;
+}
+
+int nvv4l2_allocate_memory(nvv4l2_ctx_t *ctx, NvBuffer *buffer)
+{
+     for (uint32_t i = 0; i < buffer->n_planes; i++) {
+        buffer->planes[i].length = NVMAX(buffer->planes[i].fmt.sizeimage,
+                                         buffer->planes[i].fmt.width *
+                                          buffer->planes[i].fmt.bytesperpixel *
+                                          buffer->planes[i].fmt.height);
+        buffer->planes[i].data =
+                (unsigned char *)NVMALLOC(sizeof(unsigned char) *
+                                        buffer->planes[i].length);
+        if (buffer->planes[i].data == NULL) {
+            av_log(ctx->avctx, AV_LOG_ERROR,
+                   "Could not allocate buffer %d plane %d!\n",
+                   buffer->index, i);
+            return -1;
+        }
+    }
+    return 0;
+}
+
+int nvv4l2_map(nvv4l2_ctx_t *ctx, NvBuffer *buffer)
+{
+    if (buffer->memory_type != V4L2_MEMORY_MMAP) {
+        av_log(ctx->avctx, AV_LOG_ERROR,
+               "Buffer type %d can't be mapped!\n", buffer->memory_type);
+        return -1;
+    }
+
+    if (buffer->mapped) {
+        av_log(ctx->avctx, AV_LOG_VERBOSE, "Buffer %d already mapped!\n",
+               buffer->index);
+        return 0;
+    }
+
+    for (uint32_t i = 0; i < buffer->n_planes; i++) {
+        if (buffer->planes[i].fd == -1) {
+            return -1;
+        }
+
+        buffer->planes[i].data =
+            (unsigned char *)mmap(NULL, buffer-> planes[i].length,
+                                         PROT_READ | PROT_WRITE, MAP_SHARED,
+                                         buffer->planes[i].fd,
+                                         buffer->planes
+                                         [i].mem_offset);
+        if (buffer->planes[i].data == MAP_FAILED) {
+            av_log(ctx->avctx, AV_LOG_ERROR,
+                   "Could not map buffer %d plane %d!\n", buffer->index, i);
+            return -1;
+        }
+    }
+    buffer->mapped = true;
+    return 0;
+}
+
+void nvv4l2_unmap(nvv4l2_ctx_t *ctx, NvBuffer *buffer)
+{
+    if (buffer->memory_type != V4L2_MEMORY_MMAP || !buffer->mapped) {
+        av_log(ctx->avctx, AV_LOG_VERBOSE,
+            "Cannot unmap Buffer %d Only mapped MMAP buffer can be unmapped\n",
+            buffer->index);
+        return;
+    }
+
+    for (uint32_t i = 0; i < buffer->n_planes; i++) {
+        if (buffer->planes[i].data) {
+            munmap(buffer->planes[i].data, buffer->planes[i].length);
+        }
+        buffer->planes[i].data = NULL;
+    }
+    buffer->mapped = false;
+}
+
+void nvv4l2_destroyBuffer(nvv4l2_ctx_t *ctx, NvBuffer *buffer)
+{
+    if (buffer->mapped) {
+        nvv4l2_unmap(ctx, buffer);
+    }
+}
+
+int
+nvv4l2_query_buffer(nvv4l2_ctx_t *ctx, enum v4l2_buf_type buf_type,
+                    enum v4l2_memory memory_type, uint32_t num_planes,
+                    uint32_t index)
+{
+    struct v4l2_buffer v4l2_buf;
+    struct v4l2_plane planes[NV_MAX_PLANES];
+    NvBuffer *buffer;
+    int ret;
+    uint32_t j;
+
+    memset(&v4l2_buf, 0, sizeof(struct v4l2_buffer));
+    memset(planes, 0, sizeof(planes));
+    v4l2_buf.index = index;
+    v4l2_buf.type = buf_type;
+    v4l2_buf.memory = memory_type;
+    v4l2_buf.m.planes = planes;
+    v4l2_buf.length = num_planes;
+
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_QUERYBUF, &v4l2_buf);
+    if (ret) {
+        av_log(ctx->avctx, AV_LOG_ERROR, "Error in QueryBuf!\n");
+    } else {
+        if (buf_type == ctx->op_buf_type) {
+            buffer = ctx->op_buffers[index];
+        } else if (buf_type == ctx->cp_buf_type) {
+            buffer = ctx->cp_buffers[index];
+        }
+
+        for (j = 0; j < v4l2_buf.length; j++) {
+            buffer->planes[j].length = v4l2_buf.m.planes[j].length;
+            buffer->planes[j].mem_offset =
+                v4l2_buf.m.planes[j].m.mem_offset;
+        }
+    }
+
+    return ret;
+}
+
+int
+nvv4l2_export_buffer(nvv4l2_ctx_t *ctx, enum v4l2_buf_type buf_type,
+                     uint32_t num_planes, uint32_t index)
+{
+    struct v4l2_exportbuffer expbuf;
+    NvBuffer *buffer;
+    int ret;
+
+    memset(&expbuf, 0, sizeof(expbuf));
+    expbuf.type = buf_type;
+    expbuf.index = index;
+
+    for (uint32_t i = 0; i < num_planes; i++) {
+        expbuf.plane = i;
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_EXPBUF, &expbuf);
+        if (ret) {
+            av_log(ctx->avctx, AV_LOG_ERROR, "Error in ExportBuf!\n");
+        }
+        else {
+            if (buf_type == ctx->op_buf_type) {
+                buffer = ctx->op_buffers[index];
+            } else if (buf_type == ctx->cp_buf_type) {
+                buffer = ctx->cp_buffers[index];
+            }
+            buffer->planes[i].fd = expbuf.fd;
+        }
+    }
+    return 0;
+}
+
+int
+nvv4l2_fill_buffer_plane_format(nvv4l2_ctx_t *ctx,
+                                uint32_t *num_planes,
+                                NvBufferPlaneFormat *planefmts,
+                                uint32_t width, uint32_t height,
+                                uint32_t pixfmt)
+{
+    switch (pixfmt) {
+    case V4L2_PIX_FMT_YUV444M:
+        *num_planes = 3;
+
+        planefmts[0].width = width;
+        planefmts[1].width = width;
+        planefmts[2].width = width;
+
+        planefmts[0].height = height;
+        planefmts[1].height = height;
+        planefmts[2].height = height;
+
+        planefmts[0].bytesperpixel = 1;
+        planefmts[1].bytesperpixel = 1;
+        planefmts[2].bytesperpixel = 1;
+        break;
+    case V4L2_PIX_FMT_YUV420M:
+        *num_planes = 3;
+
+        planefmts[0].width = width;
+        planefmts[1].width = width / 2;
+        planefmts[2].width = width / 2;
+
+        planefmts[0].height = height;
+        planefmts[1].height = height / 2;
+        planefmts[2].height = height / 2;
+
+        planefmts[0].bytesperpixel = 1;
+        planefmts[1].bytesperpixel = 1;
+        planefmts[2].bytesperpixel = 1;
+        break;
+    case V4L2_PIX_FMT_NV12M:
+        *num_planes = 2;
+
+        planefmts[0].width = width;
+        planefmts[1].width = width / 2;
+
+        planefmts[0].height = height;
+        planefmts[1].height = height / 2;
+
+        planefmts[0].bytesperpixel = 1;
+        planefmts[1].bytesperpixel = 2;
+        break;
+    case V4L2_PIX_FMT_P010M:
+        *num_planes = 2;
+
+        planefmts[0].width = width;
+        planefmts[1].width = width / 2;
+
+        planefmts[0].height = height;
+        planefmts[1].height = height / 2;
+
+        planefmts[0].bytesperpixel = 2;
+        planefmts[1].bytesperpixel = 4;
+        break;
+    default:
+        av_log(ctx->avctx, AV_LOG_ERROR, "Unsupported pixel format!");
+        return -1;
+    }
+
+    return 0;
+}
+
+int
+nvv4l2_dq_event(nvv4l2_ctx_t *ctx, struct v4l2_event *event,
+                uint32_t max_wait_ms)
+{
+    int ret;
+    do {
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_DQEVENT, event);
+
+        if (errno != EAGAIN) {
+            break;
+        } else if (max_wait_ms-- == 0) {
+            break;
+        } else {
+            usleep(1000);
+        }
+    }
+    while (ret && (ctx->op_streamon || ctx->cp_streamon));
+
+    return ret;
+}
+
+int
+nvv4l2_dq_buffer(nvv4l2_ctx_t *ctx, struct v4l2_buffer *v4l2_buf,
+                 NvBuffer **buffer, enum v4l2_buf_type buf_type,
+                 enum v4l2_memory memory_type, uint32_t num_retries)
+{
+    int ret;
+    bool is_in_error = false;
+    v4l2_buf->type = buf_type;
+    v4l2_buf->memory = memory_type;
+    do {
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_DQBUF, v4l2_buf);
+        if (ret == 0) {
+            pthread_mutex_lock(&ctx->queue_lock);
+            switch (v4l2_buf->type) {
+            case V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:
+                if (buffer)
+                    *buffer = ctx->op_buffers[v4l2_buf->index];
+                for (uint32_t i = 0;
+                     i < ctx->op_buffers[v4l2_buf->index]->n_planes; i++) {
+                    ctx->op_buffers[v4l2_buf->index]->planes[i].bytesused =
+                        v4l2_buf->m.planes[i].bytesused;
+                }
+                ctx->num_queued_op_buffers--;
+                break;
+
+            case V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:
+                if (buffer)
+                    *buffer = ctx->cp_buffers[v4l2_buf->index];
+                for (uint32_t i = 0;
+                     i < ctx->cp_buffers[v4l2_buf->index]->n_planes; i++) {
+                    ctx->cp_buffers[v4l2_buf->index]->planes[i].bytesused =
+                        v4l2_buf->m.planes[i].bytesused;
+                }
+                ctx->num_queued_cp_buffers--;
+                break;
+
+            default:
+                av_log(ctx->avctx, AV_LOG_ERROR, "Invalid buffer type!\n");
+            }
+            pthread_cond_broadcast(&ctx->queue_cond);
+            pthread_mutex_unlock(&ctx->queue_lock);
+        } else if (errno == EAGAIN) {
+            pthread_mutex_lock(&ctx->queue_lock);
+            if (v4l2_buf->flags & V4L2_BUF_FLAG_LAST) {
+                pthread_mutex_unlock(&ctx->queue_lock);
+                break;
+            }
+            pthread_mutex_unlock(&ctx->queue_lock);
+
+            if (num_retries-- == 0) {
+                av_log(ctx->avctx, AV_LOG_VERBOSE, "Resource unavailable!\n");
+                break;
+            }
+        } else {
+            is_in_error = true;
+            break;
+        }
+    }
+    while (ret && !is_in_error);
+
+    return ret;
+}
+
+int
+nvv4l2_q_buffer(nvv4l2_ctx_t *ctx, struct v4l2_buffer *v4l2_buf,
+                NvBuffer *buffer, enum v4l2_buf_type buf_type,
+                enum v4l2_memory memory_type, int num_planes)
+{
+    int ret;
+
+    pthread_mutex_lock(&ctx->queue_lock);
+
+    if (!buffer && buf_type == ctx->op_buf_type)
+        buffer = ctx->op_buffers[v4l2_buf->index];
+    else if (!buffer && buf_type == ctx->cp_buf_type)
+        buffer = ctx->cp_buffers[v4l2_buf->index];
+
+    v4l2_buf->type = buf_type;
+    v4l2_buf->memory = memory_type;
+    v4l2_buf->length = num_planes;
+
+    switch (memory_type) {
+    case V4L2_MEMORY_USERPTR:
+        for (uint32_t i = 0; i < buffer->n_planes; i++) {
+            v4l2_buf->m.planes[i].m.userptr =
+                (unsigned long) buffer->planes[i].data;
+            v4l2_buf->m.planes[i].bytesused = buffer->planes[i].bytesused;
+        }
+        break;
+    case V4L2_MEMORY_MMAP:
+        for (uint32_t i = 0; i < buffer->n_planes; i++) {
+            v4l2_buf->m.planes[i].bytesused = buffer->planes[i].bytesused;
+        }
+        break;
+
+    case V4L2_MEMORY_DMABUF:
+        break;
+
+    default:
+        pthread_cond_broadcast(&ctx->queue_cond);
+        pthread_mutex_unlock(&ctx->queue_lock);
+        return -1;
+    }
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_QBUF, v4l2_buf);
+
+    if (ret == 0) {
+        if (v4l2_buf->type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE) {
+            ctx->num_queued_op_buffers++;
+        } else {
+            ctx->num_queued_cp_buffers++;
+        }
+        pthread_cond_broadcast(&ctx->queue_cond);
+    }
+    pthread_mutex_unlock(&ctx->queue_lock);
+
+    return ret;
+}
+
+int
+nvv4l2_req_buffers_on_capture_plane(nvv4l2_ctx_t *ctx,
+                                    enum v4l2_buf_type buf_type,
+                                    enum v4l2_memory mem_type,
+                                    int num_buffers)
+{
+    struct v4l2_requestbuffers reqbufs;
+    int ret;
+    memset(&reqbufs, 0, sizeof(struct v4l2_requestbuffers));
+
+    reqbufs.count = num_buffers;
+    reqbufs.memory = mem_type;
+    reqbufs.type = buf_type;
+
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_REQBUFS, &reqbufs);
+    if (ret)
+        return ret;
+
+    if (reqbufs.count) {
+        ctx->cp_buffers =
+            (NvBuffer **)NVMALLOC(reqbufs.count * sizeof(NvBuffer *));
+        for (uint32_t i = 0; i < reqbufs.count; ++i) {
+            ctx->cp_buffers[i] = (NvBuffer *)NVMALLOC(sizeof(NvBuffer));
+            nvv4l2_create_bufferfmt(ctx->cp_buffers[i], buf_type, mem_type,
+                             ctx->cp_num_planes, ctx->cp_planefmts, i);
+        }
+    } else if (ctx->cp_buffers) {
+        for (uint32_t i = 0; i < ctx->cp_num_buffers; ++i) {
+            for (uint32_t j = 0; j < ctx->cp_buffers[i]->n_planes &&
+                 mem_type == V4L2_MEMORY_USERPTR; j++) {
+                NVFREE(ctx->cp_buffers[i]->planes[j].data);
+            }
+            NVFREE(ctx->cp_buffers[i]);
+        }
+        NVFREE(ctx->cp_buffers);
+        ctx->cp_buffers = NULL;
+    }
+    ctx->cp_num_buffers = reqbufs.count;
+
+    return ret;
+}
+
+int
+nvv4l2_req_buffers_on_output_plane(nvv4l2_ctx_t *ctx,
+                                   enum v4l2_buf_type buf_type,
+                                   enum v4l2_memory mem_type,
+                                   int num_buffers)
+{
+    struct v4l2_requestbuffers reqbufs;
+    int ret;
+    memset(&reqbufs, 0, sizeof(struct v4l2_requestbuffers));
+
+    reqbufs.count = num_buffers;
+    reqbufs.memory = mem_type;
+    reqbufs.type = buf_type;
+
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_REQBUFS, &reqbufs);
+    if (ret)
+        return ret;
+
+    if (reqbufs.count) {
+        ctx->op_buffers =
+            (NvBuffer **)NVMALLOC(reqbufs.count * sizeof(NvBuffer *));
+        for (uint32_t i = 0; i < reqbufs.count; ++i) {
+            ctx->op_buffers[i] = (NvBuffer *)NVMALLOC(sizeof(NvBuffer));
+            nvv4l2_create_bufferfmt(ctx->op_buffers[i], buf_type, mem_type,
+                             ctx->op_num_planes, ctx->op_planefmts, i);
+        }
+    } else if (ctx->op_buffers) {
+        for (uint32_t i = 0; i < ctx->op_num_buffers; ++i) {
+            for (uint32_t j = 0; j < ctx->op_buffers[i]->n_planes &&
+                 mem_type == V4L2_MEMORY_USERPTR; j++) {
+                NVFREE(ctx->op_buffers[i]->planes[j].data);
+            }
+            NVFREE(ctx->op_buffers[i]);
+        }
+        NVFREE(ctx->op_buffers);
+        ctx->op_buffers = NULL;
+    }
+    ctx->op_num_buffers = reqbufs.count;
+
+    return ret;
+}
+
+int
+nvv4l2_set_ext_controls(int fd, uint32_t id,
+                        uint32_t class, uint32_t value)
+{
+    int ret;
+    struct v4l2_ext_control ctl;
+    struct v4l2_ext_controls ctrls;
+
+    memset(&ctl, 0, sizeof(struct v4l2_ext_control));
+    memset(&ctrls, 0, sizeof(struct v4l2_ext_controls));
+    ctl.id = id;
+    ctl.value = value;
+    ctrls.count = 1;
+    ctrls.controls = &ctl;
+    ctrls.ctrl_class = class;
+
+    ret = v4l2_ioctl(fd, VIDIOC_S_EXT_CTRLS, &ctrls);
+
+    return ret;
+}
+
+int
+nvv4l2_set_ext_control_qp_range(int fd, uint32_t qpmin,
+                                uint32_t qpmax)
+{
+    int ret;
+    struct v4l2_ext_control ctl;
+    struct v4l2_ext_controls ctrls;
+    v4l2_ctrl_video_qp_range qprange;
+
+    memset(&ctl, 0, sizeof(struct v4l2_ext_control));
+    memset(&ctrls, 0, sizeof(struct v4l2_ext_controls));
+
+    qprange.MinQpI = qpmin;
+    qprange.MaxQpI = qpmax;
+    qprange.MinQpP = qpmin;
+    qprange.MaxQpP = qpmax;
+    qprange.MinQpB = qpmin;
+    qprange.MaxQpB = qpmax;
+
+    ctl.id = V4L2_CID_MPEG_VIDEOENC_QP_RANGE;
+    ctl.string = (char *)&qprange;
+
+    ctrls.count = 1;
+    ctrls.controls = &ctl;
+    ctrls.ctrl_class = V4L2_CTRL_CLASS_MPEG;
+
+    ret = v4l2_ioctl(fd, VIDIOC_S_EXT_CTRLS, &ctrls);
+
+    return ret;
+}
+
+int
+nvv4l2_set_ext_control_constant_qp(int fd, uint32_t qpval)
+{
+    int ret;
+    struct v4l2_ext_control ctl[3];
+    struct v4l2_ext_controls ctrls;
+
+    memset(&ctl, 0, sizeof(ctl));
+    memset(&ctrls, 0, sizeof(ctrls));
+
+    ctl[0].id = V4L2_CID_MPEG_VIDEO_FRAME_RC_ENABLE;
+    ctl[0].value = 0; // disable rate control
+
+    ctl[1].id = V4L2_CID_MPEG_VIDEO_H264_I_FRAME_QP;
+    ctl[1].value = qpval;
+
+    ctl[2].id = V4L2_CID_MPEG_VIDEO_H264_P_FRAME_QP;
+    ctl[2].value = qpval;
+
+    ctrls.count = 3;
+    ctrls.controls = &ctl[0];
+    ctrls.ctrl_class = V4L2_CTRL_CLASS_MPEG;
+
+    ret = v4l2_ioctl(fd, VIDIOC_S_EXT_CTRLS, &ctrls);
+
+    return ret;
+}
+
+int
+nvv4l2_get_ext_control_metadata(int fd, uint32_t buffer_index,
+                    v4l2_ctrl_videoenc_outputbuf_metadata *enc_metadata)
+{
+    int ret;
+    struct v4l2_ext_control ctl;
+    struct v4l2_ext_controls ctrls;
+    v4l2_ctrl_video_metadata metadata;
+
+    memset(&ctl, 0, sizeof(struct v4l2_ext_control));
+    memset(&ctrls, 0, sizeof(struct v4l2_ext_controls));
+
+    metadata.buffer_index = buffer_index;
+    metadata.VideoEncMetadata =
+        (v4l2_ctrl_videoenc_outputbuf_metadata *)&enc_metadata;
+
+    ctl.id = V4L2_CID_MPEG_VIDEOENC_METADATA;
+    ctl.string = (char *)&metadata;
+
+    ctrls.count = 1;
+    ctrls.controls = &ctl;
+    ctrls.ctrl_class = V4L2_CTRL_CLASS_MPEG;
+
+    ret = v4l2_ioctl(fd, VIDIOC_S_EXT_CTRLS, &ctrls);
+
+    return ret;
+}
+
+int
+nvv4l2_set_stream_control_framerate(int fd,  uint32_t buf_type,
+                                    uint32_t framerate_num,
+                                    uint32_t framerate_den)
+{
+    int ret;
+    struct v4l2_streamparm parms;
+
+    memset(&parms, 0, sizeof(parms));
+
+    parms.parm.output.timeperframe.numerator = framerate_den;
+    parms.parm.output.timeperframe.denominator = framerate_num;
+    parms.type = buf_type;
+
+    ret = v4l2_ioctl(fd, VIDIOC_S_PARM, &parms);
+
+    return ret;
+}
+
+int
+nvv4l2_subscribe_event(int fd, uint32_t type, uint32_t id,
+                       uint32_t flags)
+{
+    struct v4l2_event_subscription sub;
+    int ret;
+
+    memset(&sub, 0, sizeof(struct v4l2_event_subscription));
+
+    sub.type = type;
+    sub.id = id;
+    sub.flags = flags;
+
+    ret = v4l2_ioctl(fd, VIDIOC_SUBSCRIBE_EVENT, &sub);
+
+    return ret;
+}
+
+void
+nvv4l2_dbg_plane_supported_formats(nvv4l2_ctx_t *ctx,
+                                   uint32_t buf_type)
+{
+    struct v4l2_fmtdesc fdesc;
+    char fourcc[5] = {0};
+    int ret;
+
+    memset(&fdesc, 0, sizeof(fdesc));
+    fdesc.type = buf_type;
+
+    av_log(ctx->avctx, AV_LOG_INFO,
+           "%s plane format support:\n",
+           buf_type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE ?
+                                    "Output" : "Capture");
+
+    while (true) {
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_ENUM_FMT, &fdesc);
+        if (ret)
+            break;
+
+        memcpy(fourcc, &fdesc.pixelformat, 4);
+        av_log(ctx->avctx, AV_LOG_INFO, "%d: %s (%s)\n",
+               fdesc.index, fourcc, fdesc.description);
+        fdesc.index++;
+    }
+}
+
+NvBufferPixFmtVersion
+nvv4l2_get_pixfmt_list_version(nvv4l2_ctx_t *ctx)
+{
+    NvBufferParams params;
+    NvBufferCreateParams iParams;
+    NvBufferPixFmtVersion version;
+    int dma_fd = -1;
+    int ret;
+
+    memset(&params, 0, sizeof(params));
+    memset(&iParams, 0, sizeof(NvBufferCreateParams));
+
+    iParams.width = 1280;
+    iParams.height = 720;
+    iParams.layout = NvBufferLayout_BlockLinear;
+    iParams.payloadType = NvBufferPayload_SurfArray;
+    iParams.nvbuf_tag = NvBufferTag_NONE;
+    iParams.colorFormat = NvBufferColorFormat_NV12;
+
+    /* Create assumed NV12 buffer */
+    ret = NvBufferCreateEx(&dma_fd, &iParams);
+    if (ret || dma_fd == -1) {
+        av_log(ctx->avctx, AV_LOG_ERROR,
+               "Error getting NvBuffer Pixel Format list version!\n");
+        return NvBufferPixFmtVersion_New; /* Fallback to new */
+    }
+
+    /* Query created buffer parameters */
+    ret = NvBufferGetParams(dma_fd, &params);
+    if (ret) {
+        av_log(ctx->avctx, AV_LOG_ERROR,
+               "Error getting NvBuffer Pixel Format list version!\n");
+        return NvBufferPixFmtVersion_New; /* Fallback to new */
+    }
+
+    /* Check if returned parameters match NV12 in old BSP. */
+    if (params.num_planes == 2 && params.pitch[1] == iParams.width) {
+        av_log(ctx->avctx, AV_LOG_VERBOSE, "Old NvBuffer Utils version\n");
+        version = NvBufferPixFmtVersion_Legacy;
+    } else {
+        av_log(ctx->avctx, AV_LOG_VERBOSE, "New NvBuffer Utils version\n");
+        version = NvBufferPixFmtVersion_New;
+    }
+
+    NvBufferDestroy(dma_fd);
+
+    return version;
+}
diff -Naur ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2_dec.c ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2_dec.c
--- ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2_dec.c	1970-01-01 01:00:00.000000000 +0100
+++ ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2_dec.c	2022-04-20 03:49:41.823220489 +0200
@@ -0,0 +1,1196 @@
+/*
+ * Copyright (c) 2021-2022, CTCaer <ctcaer@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include <stdatomic.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <stdint.h>
+#include <unistd.h>
+#include <pthread.h>
+#include <string.h>
+#include <fcntl.h>
+#include <errno.h>
+#include "internal.h"
+#include "libavutil/log.h"
+
+#include "nvv4l2.h"
+
+/*
+ ** Output plane format support:
+ **  S264 (H264  Encoded Slice bitstream)
+ **  VP8F (VP8   Encoded Slice bitstream)
+ **  H264 (H264  Encoded bitstream)
+ **  H265 (H265  Encoded bitstream)
+ **  VP80 (VP8   Encoded bitstream)
+ **  VP90 (VP9   Encoded bitstream)
+ **  MPG2 (MPEG2 Encoded bitstream)
+ **  MPG4 (MPEG4 Encoded bitstream)
+ **  JPEG (JPEG  Encoded bitstream)
+ **  MJPG (MJPEG Encoded bitstream)
+ **  DVX4 (divx  Encoded bitstream)
+ **  DVX5 (divx  Encoded bitstream)
+ **
+ ** Capture plane format support:
+ **  NM12 (YUV 4:2:0)
+ */
+
+/*
+ ** Output plane memory type support:
+ **  V4L2_MEMORY_MMAP
+ **  V4L2_MEMORY_USERPTR
+ ** Capture plane memory type support:
+ **  V4L2_MEMORY_MMAP
+ **  V4L2_MEMORY_DMABUF
+ */
+
+#define DECODER_DEV "/dev/nvhost-nvdec"
+#define OP_PLANE_REQ_SIZEIMAGE 4000000
+
+typedef struct {
+    char eos_reached;
+    nvv4l2_ctx_t *ctx;
+    AVClass *av_class;
+} nvv4l2DecodeContext;
+
+static int
+set_output_plane_format(nvv4l2_ctx_t *ctx, uint32_t pixfmt,
+                        uint32_t sizeimage)
+{
+    int ret;
+    struct v4l2_format format;
+
+    memset(&format, 0, sizeof(struct v4l2_format));
+    format.type = ctx->op_buf_type;
+    format.fmt.pix_mp.pixelformat = pixfmt;
+    format.fmt.pix_mp.num_planes = 1;
+    format.fmt.pix_mp.plane_fmt[0].sizeimage = sizeimage;
+
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_S_FMT, &format);
+
+    if (ret == 0) {
+        ctx->op_num_planes = format.fmt.pix_mp.num_planes;
+        for (uint32_t i = 0; i < ctx->op_num_planes; i++) {
+            ctx->op_planefmts[i].stride =
+                format.fmt.pix_mp.plane_fmt[i].bytesperline;
+            ctx->op_planefmts[i].sizeimage =
+                format.fmt.pix_mp.plane_fmt[i].sizeimage;
+        }
+    }
+
+    return ret;
+}
+
+static int
+set_capture_plane_format(AVCodecContext *avctx, nvv4l2_ctx_t *ctx,
+                         uint32_t pixfmt, uint32_t width, uint32_t height)
+{
+    int ret;
+    struct v4l2_format format;
+    uint32_t num_bufferplanes;
+    NvBufferPlaneFormat planefmts[NV_MAX_PLANES];
+
+    nvv4l2_fill_buffer_plane_format(ctx, &num_bufferplanes, planefmts, width,
+                             height, pixfmt);
+    ctx->cp_num_planes = num_bufferplanes;
+    for (uint32_t i = 0; i < num_bufferplanes; i++) {
+        ctx->cp_planefmts[i] = planefmts[i];
+    }
+    memset(&format, 0, sizeof(struct v4l2_format));
+    format.type = ctx->cp_buf_type;
+    format.fmt.pix_mp.width = width;
+    format.fmt.pix_mp.height = height;
+    format.fmt.pix_mp.pixelformat = pixfmt;
+    format.fmt.pix_mp.num_planes = num_bufferplanes;
+
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_S_FMT, &format);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR, "Error in VIDIOC_S_FMT!\n");
+        ctx->in_error = true;
+    } else {
+        ctx->cp_num_planes = format.fmt.pix_mp.num_planes;
+        for (uint32_t i = 0; i < ctx->cp_num_planes; i++) {
+            ctx->cp_planefmts[i].stride =
+                format.fmt.pix_mp.plane_fmt[i].bytesperline;
+            ctx->cp_planefmts[i].sizeimage =
+                format.fmt.pix_mp.plane_fmt[i].sizeimage;
+        }
+    }
+
+    return ret;
+}
+
+static void query_set_capture(AVCodecContext *avctx, nvv4l2_ctx_t *ctx)
+{
+    struct v4l2_format format;
+    struct v4l2_crop crop;
+    struct v4l2_control ctl;
+    int ret;
+    int32_t min_cap_buffers;
+    NvBufferCreateParams input_params = { 0 };
+    NvBufferCreateParams cap_params = { 0 };
+
+    if (ctx->in_error || ctx->eos)
+        return;
+
+    /* Get format on capture plane set by device.
+     ** This may change after an resolution change event.
+     */
+    format.type = ctx->cp_buf_type;
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_G_FMT, &format);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Could not get format from decoder capture plane!\n");
+        ctx->in_error = true;
+        return;
+    }
+
+    /* Query cropping size and position. */
+    crop.type = ctx->cp_buf_type;
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_G_CROP, &crop);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Could not get crop from decoder capture plane!\n");
+        ctx->in_error = true;
+        return;
+    }
+
+    av_log(avctx, AV_LOG_VERBOSE, "Resolution changed to: %dx%d\n",
+           crop.c.width, crop.c.height);
+
+    ctx->codec_width = crop.c.width;
+    ctx->codec_height = crop.c.height;
+
+    for (uint32_t i = 0; i < NV_MAX_BUFFERS; i++) {
+        if (ctx->plane_dma_fd[i] != -1) {
+            NvBufferDestroy(ctx->plane_dma_fd[i]);
+            ctx->plane_dma_fd[i] = -1;
+        }
+    }
+
+    /*
+     ** Due to VIC constrains the transformation from Block Linear to Pitch
+     ** must have aligned widths to 64B. Otherwise the frame might be produced
+     ** as scrambled.
+     */
+    ctx->plane_width_aligned = NVALIGN(crop.c.width, 64);
+    if (ctx->plane_width_aligned != crop.c.width)
+        av_log(avctx, AV_LOG_VERBOSE, "Linesize got aligned: %d -> %d\n",
+           crop.c.width, ctx->plane_width_aligned);
+    crop.c.width = ctx->plane_width_aligned;
+
+    /* Create transform/export DMA buffers. */
+    for (uint32_t i = 0; i < NV_MAX_BUFFERS; i++) {
+        input_params.width = crop.c.width;
+        input_params.height = crop.c.height;
+        input_params.layout = NvBufferLayout_Pitch;
+        input_params.payloadType = NvBufferPayload_SurfArray;
+        input_params.nvbuf_tag = NvBufferTag_VIDEO_DEC;
+
+        switch (ctx->cp_pixfmt) {
+        case V4L2_PIX_FMT_YUV420M:
+            input_params.colorFormat = NvBufferColorFormat_YUV420;
+            break;
+        case V4L2_PIX_FMT_NV12M:
+            input_params.colorFormat = NvBufferColorFormat_NV12;
+            if (ctx->pixfmt_list_ver == NvBufferPixFmtVersion_New)
+                input_params.colorFormat++;
+            break;
+        }
+
+        ret = NvBufferCreateEx(&ctx->plane_dma_fd[i], &input_params);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR, "Creation of dmabuf failed!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Stop streaming. */
+    pthread_mutex_lock(&ctx->queue_lock);
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMOFF, &ctx->cp_buf_type);
+    if (ret) {
+        ctx->in_error = true;
+    } else {
+        pthread_cond_broadcast(&ctx->queue_cond);
+    }
+    pthread_mutex_unlock(&ctx->queue_lock);
+
+    /* Request buffers with count 0 and destroy all
+     ** previously allocated buffers.
+     */
+    ret = nvv4l2_req_buffers_on_capture_plane(ctx,
+                                              ctx->cp_buf_type,
+                                              ctx->cp_mem_type, 0);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in requesting 0 capture plane buffers!\n");
+        ctx->in_error = true;
+        return;
+    }
+
+    /* Destroy previous DMA buffers. */
+    for (uint32_t i = 0; i < ctx->cp_num_buffers; i++) {
+        if (ctx->dmabuff_fd[i] != -1) {
+            ret = NvBufferDestroy(ctx->dmabuff_fd[i]);
+            if (ret) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Failed to Destroy NvBuffer!\n");
+                ctx->in_error = true;
+            }
+            ctx->dmabuff_fd[i] = -1;
+        }
+    }
+
+    /* Set capture plane format to update vars. */
+    ret = set_capture_plane_format(avctx, ctx,
+                                   format.fmt.pix_mp.pixelformat,
+                                   format.fmt.pix_mp.width,
+                                   format.fmt.pix_mp.height);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in setting capture plane format!\n");
+        ctx->in_error = true;
+        return;
+    }
+
+    /* Get control value for min buffers which have to
+     ** be requested on capture plane.
+     */
+    ctl.id = V4L2_CID_MIN_BUFFERS_FOR_CAPTURE;
+
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_G_CTRL, &ctl);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR, "Error getting value of control!\n");
+        ctx->in_error = true;
+        return;
+    } else {
+        min_cap_buffers = ctl.value;
+    }
+
+    /* Set quantization type. */
+    if (format.fmt.pix_mp.quantization == V4L2_QUANTIZATION_DEFAULT) {
+        av_log(avctx, AV_LOG_VERBOSE,
+            "Colorspace ITU-R BT.601 with standard range luma (16-235)\n");
+        cap_params.colorFormat = NvBufferColorFormat_NV12;
+    } else {
+        av_log(avctx, AV_LOG_VERBOSE,
+            "Colorspace ITU-R BT.601 with extended range luma (0-255)\n");
+        cap_params.colorFormat = NvBufferColorFormat_NV12_ER;
+    }
+
+    /* Increment color format if NvBuffer is newer. */
+    if (ctx->pixfmt_list_ver == NvBufferPixFmtVersion_New)
+        cap_params.colorFormat++;
+
+    /* Request number of buffers returned by ctrl, plus 10 more. */
+    ctx->cp_num_buffers = min_cap_buffers + 10;
+
+    /* Create DMA Buffers by defining the parameters for the HW Buffer.
+     ** @payloadType defines the memory handle for the NvBuffer, here
+     ** defined for the set of planes.
+     ** @nvbuf_tag identifies the type of device or component
+     ** requesting the operation.
+     ** @layout defines memory layout for the surfaces, either Pitch/BLockLinear.
+     */
+    for (uint32_t i = 0; i < ctx->cp_num_buffers; i++) {
+        cap_params.width = crop.c.width;
+        cap_params.height = crop.c.height;
+        cap_params.layout = NvBufferLayout_BlockLinear;
+        cap_params.payloadType = NvBufferPayload_SurfArray;
+        cap_params.nvbuf_tag = NvBufferTag_VIDEO_DEC;
+        ret = NvBufferCreateEx(&ctx->dmabuff_fd[i], &cap_params);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to create buffers!\n");
+            ctx->in_error = true;
+            break;
+        }
+    }
+
+    /* Request buffers on capture plane. */
+    ret = nvv4l2_req_buffers_on_capture_plane(ctx,
+                                              ctx->cp_buf_type,
+                                              ctx->cp_mem_type,
+                                              ctx->cp_num_buffers);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in requesting capture plane buffers!\n");
+        ctx->in_error = true;
+        return;
+    }
+
+    /* Enqueue all empty buffers on capture plane. */
+    for (uint32_t i = 0; i < ctx->cp_num_buffers; i++) {
+        struct v4l2_buffer v4l2_buf;
+        struct v4l2_plane planes[NV_MAX_PLANES];
+
+        memset(&v4l2_buf, 0, sizeof(v4l2_buf));
+        memset(planes, 0, sizeof(planes));
+
+        v4l2_buf.index = i;
+        v4l2_buf.m.planes = planes;
+        v4l2_buf.type = ctx->cp_buf_type;
+        v4l2_buf.memory = ctx->cp_mem_type;
+        v4l2_buf.length = ctx->cp_num_planes;
+        /* Set DMA plane handle. */
+        v4l2_buf.m.planes[0].m.fd = ctx->dmabuff_fd[i];
+        v4l2_buf.m.planes[1].m.fd = ctx->dmabuff_fd[i];
+
+        ret = nvv4l2_q_buffer(ctx, &v4l2_buf, ctx->cp_buffers[i],
+                              ctx->cp_buf_type, ctx->cp_mem_type,
+                              ctx->cp_num_planes);
+
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR, "Qing failed on capture plane!\n");
+            ctx->in_error = true;
+            return;
+        }
+    }
+
+    /* Set max performance mode if low latency is requested. */
+    if (ctx->low_latency) {
+        ret = nvv4l2_set_ext_controls(ctx->fd,
+                                V4L2_CID_MPEG_VIDEO_MAX_PERFORMANCE, 0, 1);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to set control max performance!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Set streaming status ON on capture plane. */
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMON, &ctx->cp_buf_type);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR, "Streaming error on capture plane!\n");
+        ctx->in_error = true;
+    }
+
+    ctx->cp_streamon = true;
+
+    av_log(avctx, AV_LOG_VERBOSE, "Query and set capture successful\n");
+
+    return;
+}
+
+static void *dec_capture_thread(void *arg)
+{
+    nvv4l2_ctx_t *ctx = (nvv4l2_ctx_t *)arg;
+    struct v4l2_event event;
+    int buf_index;
+    int ret;
+
+    av_log(ctx->avctx, AV_LOG_VERBOSE, "Starting capture thread\n");
+
+    /* Need to wait for the first Resolution change event, so that
+     ** the decoder knows the stream resolution and can allocate
+     ** appropriate buffers when REQBUFS is called.
+     */
+    do {
+        /* Dequeue the subscribed event. */
+        ret = nvv4l2_dq_event(ctx, &event, 50000);
+        if (ret) {
+            if (errno == EAGAIN) {
+                av_log(ctx->avctx, AV_LOG_VERBOSE,
+                       "Timeout waiting for first resolution event!\n");
+            } else {
+                av_log(ctx->avctx, AV_LOG_ERROR,
+                       "Error in dequeuing decoder event!\n");
+            }
+            ctx->in_error = true;
+            break;
+        }
+    }
+    while ((event.type != V4L2_EVENT_RESOLUTION_CHANGE) &&
+           !ctx->in_error && !ctx->eos);
+
+    /* Received first resolution change event
+     ** Format and buffers are now set on capture.
+     */
+    query_set_capture(ctx->avctx, ctx);
+
+    /* Check for resolution event to again
+     ** set format and buffers on capture plane.
+     */
+    while (!ctx->in_error && !ctx->eos) {
+        ret = nvv4l2_dq_event(ctx, &event, 0);
+        if (ret == 0) {
+            switch (event.type) {
+            case V4L2_EVENT_RESOLUTION_CHANGE:
+                query_set_capture(ctx->avctx, ctx);
+                continue;
+            }
+        }
+
+        /* Main Capture loop for DQ and Q. */
+        while (!ctx->eos) {
+            struct v4l2_buffer v4l2_cp_buf;
+            struct v4l2_plane capture_planes[NV_MAX_PLANES];
+            NvBufferRect src_rect, dest_rect;
+            NvBufferParams buf_params;
+            NvBufferTransformParams transform_params;
+
+            memset(&v4l2_cp_buf, 0, sizeof(v4l2_cp_buf));
+            memset(capture_planes, 0, sizeof(capture_planes));
+            v4l2_cp_buf.m.planes = capture_planes;
+
+            /* Dequeue the filled buffer. */
+            if (nvv4l2_dq_buffer(ctx, &v4l2_cp_buf, NULL,
+                 ctx->cp_buf_type, ctx->cp_mem_type, 0)) {
+                if (errno == EAGAIN) {
+                    usleep(1000);
+                }
+                break;
+            }
+
+            /* Transformation parameters are defined
+             ** which are passed to the NvBufferTransform
+             ** for required conversion.
+             */
+            src_rect.top = 0;
+            src_rect.left = 0;
+            src_rect.width = ctx->codec_width;
+            src_rect.height = ctx->codec_height;
+            dest_rect.top = 0;
+            dest_rect.left = 0;
+            dest_rect.width = ctx->codec_width;
+            dest_rect.height = ctx->codec_height;
+
+            /* @transform_flag defines the flags for enabling the
+             ** valid transforms. All the valid parameters are
+             **  present in the nvv4l2_ext_utils header.
+             */
+            transform_params.transform_flag = NVBUFFER_TRANSFORM_FILTER;
+            transform_params.transform_flip = NvBufferTransform_None;
+            transform_params.transform_filter =
+                                            NvBufferTransform_Filter_Smart;
+            transform_params.src_rect = src_rect;
+            transform_params.dst_rect = dest_rect;
+            transform_params.session = ctx->buf_session;
+
+            pthread_mutex_lock(&ctx->queue_lock);
+
+            buf_index = nvv4l2_pool_idx_next(ctx, ctx->export_pool);
+
+            /* Blocklinear to Pitch transformation is required
+             ** to dump the raw decoded buffer data.
+             */
+            if (buf_index >= 0) {
+                ret = NvBufferTransform(ctx->dmabuff_fd[v4l2_cp_buf.index],
+                                        ctx->plane_dma_fd[buf_index],
+                                        &transform_params);
+                if (ret == -1) {
+                    ctx->in_error = true;
+                    av_log(ctx->avctx, AV_LOG_ERROR, "Transform failed!\n");
+                    pthread_mutex_unlock(&ctx->queue_lock);
+                    break;
+                }
+
+                ret = NvBufferGetParams(ctx->plane_dma_fd[buf_index],
+                                        &buf_params);
+                if (ret) {
+                    ctx->in_error = true;
+                    av_log(ctx->avctx, AV_LOG_ERROR, "GetParams failed!\n");
+                    pthread_mutex_unlock(&ctx->queue_lock);
+                    break;
+                }
+            }
+
+            ctx->plane_width[0] = buf_params.width[0];
+            ctx->plane_height[0] = buf_params.height[0];
+            ctx->plane_width[1] = buf_params.width[1];
+            ctx->plane_height[1] = buf_params.height[1];
+            if (ctx->cp_pixfmt == V4L2_PIX_FMT_YUV420M) {
+                ctx->plane_width[2] = buf_params.width[2];
+                ctx->plane_height[2] = buf_params.height[2];
+            }
+
+            /* Set timestamp based on origin pts flags */
+            if (buf_index >= 0) {
+                if (v4l2_cp_buf.timestamp.tv_usec == 0 &&
+                     v4l2_cp_buf.timestamp.tv_sec == NV_V4L2_NOPTS_VALUE) {
+                    /* Origin packet had no pts and user pts values. */
+                    ctx->frame_pts[buf_index] = AV_NOPTS_VALUE;
+                    ctx->frame_user_pts[buf_index] = AV_NOPTS_VALUE;
+                } else if (v4l2_cp_buf.timestamp.tv_sec &
+                           NV_V4L2_REORDERED_OPAQUE_FLAG) {
+                    /* Origin packet had only user pts value. */
+                    v4l2_cp_buf.timestamp.tv_sec &=
+                                   (~NV_V4L2_REORDERED_OPAQUE_FLAG);
+                    ctx->frame_pts[buf_index] = AV_NOPTS_VALUE;
+                    ctx->frame_user_pts[buf_index] =
+                                v4l2_cp_buf.timestamp.tv_usec +
+                                (v4l2_cp_buf.timestamp.tv_sec * AV_TIME_BASE);
+                } else {
+                    /* Origin packet had pts value. */
+                    ctx->frame_pts[buf_index] =
+                                v4l2_cp_buf.timestamp.tv_usec +
+                                (v4l2_cp_buf.timestamp.tv_sec * AV_TIME_BASE);
+                   ctx->frame_user_pts[buf_index] = AV_NOPTS_VALUE;
+                }
+            }
+
+            nvv4l2_pool_push(ctx, ctx->export_pool);
+            pthread_mutex_unlock(&ctx->queue_lock);
+
+            if (ctx->low_latency) {
+                pthread_mutex_lock(&ctx->frame_lock);
+                pthread_cond_signal(&ctx->frame_cond);
+                pthread_mutex_unlock(&ctx->frame_lock);
+            }
+
+            /* Set DMA plane handle. */
+            v4l2_cp_buf.m.planes[0].m.fd = ctx->dmabuff_fd[v4l2_cp_buf.index];
+
+            /* Queue the buffer. */
+            ret = nvv4l2_q_buffer(ctx, &v4l2_cp_buf, NULL, ctx->cp_buf_type,
+                                  ctx->cp_mem_type, ctx->cp_num_planes);
+
+            if (ret) {
+                av_log(ctx->avctx, AV_LOG_ERROR,
+                       "Qing failed on capture plane!\n");
+                if (ctx->draining_event) {
+                    ctx->draining_event = false;
+                    av_log(ctx->avctx, AV_LOG_ERROR,
+                           "Draining event, rejecting error\n");
+                } else {
+                    ctx->in_error = true;
+                }
+                break;
+            }
+        }
+    }
+
+    if (ctx->low_latency) {
+        pthread_mutex_lock(&ctx->frame_lock);
+        pthread_cond_broadcast(&ctx->frame_cond);
+        pthread_mutex_unlock(&ctx->frame_lock);
+    }
+
+    av_log(ctx->avctx, AV_LOG_VERBOSE,
+           "Exiting decoder capture loop thread\n");
+    return NULL;
+}
+
+int
+nvv4l2_decoder_get_frame(AVCodecContext *avctx, nvv4l2_ctx_t *ctx,
+                         int *buf_index, NvFrame *frame)
+{
+    struct timespec timeout;
+    struct timeval now;
+    int _buf_index;
+    int ret = 0;
+
+    /* In low latency mode, block until a decoded frame is ready. */
+    if (ctx->low_latency) {
+        pthread_mutex_lock(&ctx->frame_lock);
+        while (atomic_load(&ctx->export_pool->capacity) == 0 &&
+               !ctx->eos && !ctx->in_error && ret != ETIMEDOUT) {
+            /* 500ms timeout */
+            gettimeofday(&now, NULL);
+            timeout.tv_nsec = (now.tv_usec + 500000L) * 1000L;
+            timeout.tv_sec = now.tv_sec + timeout.tv_nsec / 1000000000L;
+            timeout.tv_nsec = timeout.tv_nsec % 1000000000L;
+
+            ret = pthread_cond_timedwait(&ctx->frame_cond,
+                                         &ctx->frame_lock, &timeout);
+        }
+        pthread_mutex_unlock(&ctx->frame_lock);
+    }
+
+    if (ctx->export_pool->capacity == 0)
+        return 1;
+
+    _buf_index = nvv4l2_pool_pop(ctx, ctx->export_pool);
+
+    frame->width = ctx->codec_width;
+    frame->height = ctx->codec_height;
+    frame->pts = ctx->frame_pts[_buf_index];
+    frame->user_pts = ctx->frame_user_pts[_buf_index];
+
+    *buf_index = _buf_index;
+
+    return 0;
+
+}
+
+int
+nvv4l2_decoder_put_packet(AVCodecContext *avctx, nvv4l2_ctx_t *ctx,
+                          NvPacket *packet)
+{
+    int ret;
+    /* Read the encoded data and Enqueue the output
+     ** plane buffers. Exit loop in case file read is complete.
+     */
+    struct v4l2_buffer v4l2_buf_op;
+    struct v4l2_plane queue_op_planes[NV_MAX_PLANES];
+    NvBuffer *buffer;
+    memset(&v4l2_buf_op, 0, sizeof(v4l2_buf_op));
+    memset(queue_op_planes, 0, sizeof(queue_op_planes));
+    v4l2_buf_op.m.planes = queue_op_planes;
+
+    if (ctx->num_active_op_buffers < ctx->op_num_buffers) {
+        /* Get an unused buffer to add to the queue. */
+        buffer = ctx->op_buffers[ctx->num_active_op_buffers];
+        v4l2_buf_op.index = ctx->num_active_op_buffers;
+    } else {
+        /* Dequeue a finished buffer and reuse it. */
+        ret = nvv4l2_dq_buffer(ctx, &v4l2_buf_op, &buffer,
+                               ctx->op_buf_type, ctx->op_mem_type, -1);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Error DQing buffer at output plane!\n");
+            ctx->in_error = true;
+            return -1;
+        }
+    }
+
+    /* Copy packet data. */
+    memcpy(buffer->planes[0].data, packet->payload, packet->payload_size);
+    buffer->planes[0].bytesused = packet->payload_size;
+
+    v4l2_buf_op.m.planes[0].bytesused = buffer->planes[0].bytesused;
+
+    /* Set timestamp based on packet flags. */
+    v4l2_buf_op.flags |= V4L2_BUF_FLAG_TIMESTAMP_COPY;
+    if (packet->pts != AV_NOPTS_VALUE) {
+        /* Packet pts is valid */
+        v4l2_buf_op.timestamp.tv_sec = packet->pts / AV_TIME_BASE;
+        v4l2_buf_op.timestamp.tv_usec = packet->pts % AV_TIME_BASE;
+    } else if (packet->user_pts != AV_NOPTS_VALUE) {
+        /* User pts is valid */
+        v4l2_buf_op.timestamp.tv_sec = packet->user_pts / AV_TIME_BASE;
+        v4l2_buf_op.timestamp.tv_usec = packet->user_pts % AV_TIME_BASE;
+        v4l2_buf_op.timestamp.tv_sec |= NV_V4L2_REORDERED_OPAQUE_FLAG;
+    } else {
+        /* No valid pts or user pts */
+        v4l2_buf_op.timestamp.tv_sec = NV_V4L2_NOPTS_VALUE;
+        v4l2_buf_op.timestamp.tv_usec = 0;
+    }
+
+    /* Queue packet on output plane. */
+    ret = nvv4l2_q_buffer(ctx, &v4l2_buf_op, buffer,
+                   ctx->op_buf_type, ctx->op_mem_type, ctx->op_num_planes);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR, "Error Qing buffer at output plane!\n");
+        ctx->in_error = true;
+        return -1;
+    }
+
+    if (ctx->num_active_op_buffers < ctx->op_num_buffers) {
+        ctx->num_active_op_buffers++;
+    }
+
+    if (v4l2_buf_op.m.planes[0].bytesused == 0) {
+        ctx->eos = true;
+        av_log(avctx, AV_LOG_VERBOSE, "Input file read complete\n");
+    }
+
+    return 0;
+}
+
+nvv4l2_ctx_t *nvv4l2_create_decoder(AVCodecContext *avctx,
+                                    NvCodingType nv_codec_type,
+                                    int pix_fmt)
+{
+    nvv4l2_ctx_t *ctx = (nvv4l2_ctx_t *)NVCALLOC(1, sizeof(nvv4l2_ctx_t));
+    int ret = 0;
+    int flags = 0;
+    ctx->avctx = avctx;
+
+    /* The call creates a new V4L2 Video Decoder object
+     ** on the device node "/dev/nvhost-nvdec"
+     ** Additional flags can also be given with which the device
+     ** should be opened.
+     ** This opens the device in Blocking mode.
+     */
+    ctx->fd = v4l2_open(DECODER_DEV, flags | O_RDWR);
+    if (ctx->fd == -1) {
+        av_log(avctx, AV_LOG_ERROR, "Could not open device!\n");
+        ctx->in_error = true;
+        return ctx;
+    }
+
+    /* Initialization. */
+    ctx->cp_pixfmt = pix_fmt;
+    ctx->op_pixfmt = nvv4l2_map_nvcodec_type(nv_codec_type);
+
+    /* Get NvBuffer pixel format list version */
+    ctx->pixfmt_list_ver = nvv4l2_get_pixfmt_list_version(ctx);
+
+    /* Get a NvBuffer session for interprocess transforms */
+    ctx->buf_session = NvBufferSessionCreate();
+
+    /* Decoder code assumes that the following do not change.
+     ** If another memory type is wanted, relevant changes should be done
+     ** to the rest of the code.
+     */
+    ctx->op_mem_type = V4L2_MEMORY_USERPTR;
+    ctx->cp_mem_type = V4L2_MEMORY_DMABUF;
+
+    ctx->op_buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    ctx->cp_buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+
+    for (uint32_t i = 0; i < NV_MAX_BUFFERS; i++) {
+        ctx->dmabuff_fd[i] = -1;
+        ctx->plane_dma_fd[i] = -1;
+    }
+
+    /* Allocate packet pool. */
+    ctx->export_pool = (NvQueues *)NVCALLOC(1, sizeof(NvQueues));
+
+    /* Initialize mutexes */
+    pthread_mutex_init(&ctx->queue_lock, NULL);
+    pthread_mutex_init(&ctx->frame_lock, NULL);
+    pthread_cond_init(&ctx->queue_cond, NULL);
+    pthread_cond_init(&ctx->frame_cond, NULL);
+
+    /* Subscribe to Resolution change event.
+     ** This is required to catch whenever resolution change event
+     ** is triggered to set the format on capture plane.
+     */
+    ret = nvv4l2_subscribe_event(ctx->fd,
+                                 V4L2_EVENT_RESOLUTION_CHANGE,
+                                 0, 0);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to subscribe for resolution change!\n");
+        ctx->in_error = true;
+    }
+
+    /* Set format on output plane.
+     ** The format of the encoded bitstream is set.
+     */
+    ret = set_output_plane_format(ctx, ctx->op_pixfmt, OP_PLANE_REQ_SIZEIMAGE);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in setting output plane format!\n");
+        ctx->in_error = true;
+    }
+
+    /* Set appropriate controls.
+     ** V4L2_CID_MPEG_VIDEO_DISABLE_COMPLETE_FRAME_INPUT control is
+     ** set to false as the application always sends NALUs.
+     ** Also, mandatory when V4L2_BUF_FLAG_TIMESTAMP_COPY is used.
+     */
+    ret =
+        nvv4l2_set_ext_controls(ctx->fd,
+                         V4L2_CID_MPEG_VIDEO_DISABLE_COMPLETE_FRAME_INPUT,
+                         0, 0);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to set control enable complete frame!\n");
+        ctx->in_error = true;
+    }
+
+    /* Request buffers on output plane to fill
+     ** the input bitstream.
+     */
+    ret = nvv4l2_req_buffers_on_output_plane(ctx,
+                                             ctx->op_buf_type,
+                                             ctx->op_mem_type, 10);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in requesting buffers on output plane!\n");
+        ctx->in_error = true;
+    }
+
+    for (uint32_t i = 0; i < ctx->op_num_buffers; i++) {
+        if (nvv4l2_allocate_memory(ctx, ctx->op_buffers[i])) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Buffer mapping error on output plane!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Start stream processing on output plane
+     ** by setting the streaming status ON.
+     */
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMON, &ctx->op_buf_type);
+    if (ret != 0) {
+        av_log(avctx, AV_LOG_ERROR, "Streaming error on output plane!\n");
+        ctx->in_error = true;
+    }
+
+    ctx->op_streamon = true;
+
+    /* Create and start capture loop thread. */
+    pthread_create(&ctx->capture_thread, NULL, dec_capture_thread, ctx);
+
+    return ctx;
+}
+
+int nvv4l2_decoder_close(AVCodecContext *avctx, nvv4l2_ctx_t *ctx)
+{
+    int ret;
+
+    if (!ctx)
+        return 0;
+
+    pthread_mutex_lock(&ctx->queue_lock);
+    ctx->eos = true;
+    pthread_mutex_unlock(&ctx->queue_lock);
+    if (ctx->fd != -1) {
+        /* Stop streaming on both planes. */
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMOFF, &ctx->op_buf_type);
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMOFF, &ctx->cp_buf_type);
+        ctx->op_streamon = false;
+        ctx->cp_streamon = false;
+
+        /* Wait for capture thread to exit. */
+        if (ctx->capture_thread) {
+            pthread_join(ctx->capture_thread, NULL);
+        }
+
+        /* Request 0 buffers on both planes. */
+        ret = nvv4l2_req_buffers_on_output_plane(ctx,
+                                                 ctx->op_buf_type,
+                                                 ctx->op_mem_type, 0);
+
+        ret = nvv4l2_req_buffers_on_capture_plane(ctx,
+                                                  ctx->cp_buf_type,
+                                                  ctx->cp_mem_type, 0);
+
+        /* All allocated DMA buffers must be destroyed. */
+        for (uint32_t i = 0; i < ctx->cp_num_buffers; i++) {
+            if (ctx->dmabuff_fd[i] != -1) {
+                ret = NvBufferDestroy(ctx->dmabuff_fd[i]);
+                if (ret < 0) {
+                    av_log(avctx, AV_LOG_ERROR,
+                           "Failed to destroy dma buffer!\n");
+                }
+                ctx->dmabuff_fd[i] = -1;
+            }
+        }
+
+        /* Destroy all allocated transform/export DMA buffers. */
+        for (uint32_t i = 0; i < NV_MAX_BUFFERS; i++) {
+            if (ctx->plane_dma_fd[i] != -1) {
+                ret = NvBufferDestroy(ctx->plane_dma_fd[i]);
+                if (ret < 0) {
+                    av_log(avctx, AV_LOG_ERROR,
+                           "Failed to destroy plane buffer!\n");
+                }
+                ctx->plane_dma_fd[i] = -1;
+            }
+        }
+
+        /* Destroy NvBuffer session. */
+        if (ctx->buf_session)
+            NvBufferSessionDestroy(ctx->buf_session);
+
+        NVFREE(ctx->export_pool);
+
+        /* Close the opened V4L2 device. */
+        ret = v4l2_close(ctx->fd);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR, "Unable to close the device!\n");
+        }
+
+        /* Free mutexes */
+        pthread_mutex_destroy(&ctx->queue_lock);
+        pthread_mutex_destroy(&ctx->frame_lock);
+        pthread_cond_destroy(&ctx->queue_cond);
+        pthread_cond_destroy(&ctx->frame_cond);
+    }
+
+    /* Report application run status on exit. */
+    if (ctx->in_error) {
+        av_log(avctx, AV_LOG_VERBOSE, "Decoder Run failed\n");
+    } else {
+        av_log(avctx, AV_LOG_VERBOSE, "Decoder Run was successful\n");
+    }
+
+    NVFREE(ctx);
+
+    return ret;
+}
+
+static NvCodingType map_avcodec_id(enum AVCodecID id)
+{
+    switch (id) {
+    case AV_CODEC_ID_H264:
+        return NvVideoCodec_H264;
+    case AV_CODEC_ID_HEVC:
+        return NvVideoCodec_HEVC;
+    case AV_CODEC_ID_MPEG2VIDEO:
+        return NvVideoCodec_MPEG2;
+    case AV_CODEC_ID_MPEG4:
+        return NvVideoCodec_MPEG4;
+    case AV_CODEC_ID_VP8:
+        return NvVideoCodec_VP8;
+    case AV_CODEC_ID_VP9:
+        return NvVideoCodec_VP9;
+    }
+    return NvVideoCodec_UNDEFINED;
+}
+
+static int nvv4l2dec_init(AVCodecContext *avctx)
+{
+    nvv4l2DecodeContext *nvv4l2_ctx = avctx->priv_data;
+    NvCodingType nv_codec_type = map_avcodec_id(avctx->codec_id);
+    int pix_fmt;
+
+    if (nv_codec_type == NvVideoCodec_UNDEFINED) {
+        av_log(avctx, AV_LOG_ERROR, "Unsupported codec ID %d!\n",
+               avctx->codec_id);
+        return AVERROR_BUG;
+    }
+
+    switch (avctx->pix_fmt) {
+    case AV_PIX_FMT_NONE:
+        avctx->pix_fmt = AV_PIX_FMT_YUV420P;
+    case AV_PIX_FMT_YUV420P:
+        pix_fmt = V4L2_PIX_FMT_YUV420M;
+        break;
+    case AV_PIX_FMT_NV12:
+        pix_fmt = V4L2_PIX_FMT_NV12M;
+        break;
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Unsupported pixel format %d!\n",
+               avctx->pix_fmt);
+        return AVERROR_BUG;
+    }
+
+    nvv4l2_ctx->ctx = nvv4l2_create_decoder(avctx, nv_codec_type, pix_fmt);
+
+    if (!nvv4l2_ctx->ctx || nvv4l2_ctx->ctx->in_error) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create nvv4l2 decoder!\n");
+
+        if (nvv4l2_ctx->ctx && nvv4l2_ctx->ctx->in_error) {
+            nvv4l2_decoder_close(avctx, nvv4l2_ctx->ctx);
+        }
+
+        return AVERROR_UNKNOWN;
+    }
+
+    /*
+     ** Check if low latency is needed.
+     ** Depends on whole frames received instead of slices.
+     ** Otherwise the decoder only starts streaming after a
+     ** required amount of packets received.
+     */
+    nvv4l2_ctx->ctx->low_latency =
+                (avctx->flags & AV_CODEC_FLAG_LOW_DELAY) ? true : false;
+
+    return 0;
+}
+
+static void nvv4l2dec_flush(AVCodecContext *avctx)
+{
+    nvv4l2DecodeContext *nvv4l2_ctx = avctx->priv_data;
+    nvv4l2_ctx_t *ctx = nvv4l2_ctx->ctx;
+    int ret = 0;
+
+    pthread_mutex_lock(&ctx->queue_lock);
+    /* Flush all queued buffers from output and capture plane. */
+    if (ctx->op_streamon && ctx->cp_streamon &&
+       (ctx->num_queued_op_buffers || ctx->num_active_op_buffers)) {
+        /* Stop streaming on both planes. */
+        v4l2_ioctl(ctx->fd, VIDIOC_STREAMOFF, &ctx->op_buf_type);
+        v4l2_ioctl(ctx->fd, VIDIOC_STREAMOFF, &ctx->cp_buf_type);
+        ctx->op_streamon = false;
+        ctx->cp_streamon = false;
+
+        /* Turn on output plane streaming. */
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMON, &ctx->op_buf_type);
+        if (ret != 0) {
+            av_log(avctx, AV_LOG_ERROR, "Streaming error on output plane!\n");
+            ctx->in_error = true;
+        } else {
+            ctx->op_streamon = true;
+        }
+
+        ctx->draining_event = true;
+
+        /* Re-enqueue all now empty buffers on capture plane. */
+        for (uint32_t i = 0; i < ctx->cp_num_buffers; i++) {
+            struct v4l2_buffer v4l2_buf;
+            struct v4l2_plane planes[NV_MAX_PLANES];
+
+            memset(&v4l2_buf, 0, sizeof(v4l2_buf));
+            memset(planes, 0, sizeof(planes));
+
+            v4l2_buf.index = i;
+            v4l2_buf.m.planes = planes;
+            v4l2_buf.type = ctx->cp_buf_type;
+            v4l2_buf.memory = ctx->cp_mem_type;
+            v4l2_buf.length = ctx->cp_num_planes;
+            /* Set DMA plane handle */
+            v4l2_buf.m.planes[0].m.fd = ctx->dmabuff_fd[i];
+            v4l2_buf.m.planes[1].m.fd = ctx->dmabuff_fd[i];
+
+            pthread_mutex_unlock(&ctx->queue_lock);
+            ret = nvv4l2_q_buffer(ctx, &v4l2_buf, ctx->cp_buffers[i],
+                                  ctx->cp_buf_type, ctx->cp_mem_type,
+                                  ctx->cp_num_planes);
+            pthread_mutex_lock(&ctx->queue_lock);
+
+            if (ret) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Qing empty failed on capture plane!\n");
+            }
+        }
+
+        ctx->num_active_op_buffers = 0;
+        ctx->num_queued_op_buffers = 0;
+        ctx->num_queued_cp_buffers = 0;
+
+        /* Turn on capture plane streaming. */
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMON, &ctx->cp_buf_type);
+        if (ret != 0) {
+            av_log(avctx, AV_LOG_ERROR, "Streaming error on capture plane!\n");
+            ctx->in_error = true;
+        } else {
+            ctx->cp_streamon = true;
+        }
+    }
+
+    /* Flush all decoded frames from frame pool */
+    while (ctx->export_pool->capacity != 0) {
+        nvv4l2_pool_pop(ctx, ctx->export_pool);
+    }
+    ctx->export_pool->front = 0;
+    ctx->export_pool->back = 0;
+    pthread_mutex_unlock(&ctx->queue_lock);
+}
+
+static int nvv4l2dec_close(AVCodecContext *avctx)
+{
+    nvv4l2DecodeContext *nvv4l2_ctx = avctx->priv_data;
+    return nvv4l2_decoder_close(avctx, nvv4l2_ctx->ctx);
+}
+
+static int
+nvv4l2dec_decode(AVCodecContext *avctx, void *data, int *got_frame,
+                 AVPacket *avpkt)
+{
+    nvv4l2DecodeContext *nvv4l2_ctx = avctx->priv_data;
+    nvv4l2_ctx_t *ctx = nvv4l2_ctx->ctx;
+    AVFrame *avframe = (AVFrame *)data;
+    NvFrame _nvframe = { 0 };
+    int processed_size = 0;
+    int buf_index = -1;
+
+    if (ctx->in_error) {
+        return AVERROR_UNKNOWN;
+    }
+
+    if (avpkt->size) {
+        NvPacket packet;
+        packet.payload_size = avpkt->size;
+        packet.payload = avpkt->data;
+        packet.pts = avpkt->pts;
+        packet.user_pts = avctx->reordered_opaque;
+
+        if (!nvv4l2_decoder_put_packet(avctx, ctx, &packet)) {
+            processed_size = avpkt->size;
+        } else {
+            return AVERROR_UNKNOWN;
+        }
+    }
+
+    /* Get a decoded frame if any. */
+    if (nvv4l2_decoder_get_frame(avctx, ctx, &buf_index, &_nvframe))
+        return processed_size;
+
+    /* Set coded width to aligned size to fit the transformation.
+     ** It gets restored after transformation by default.
+     */
+    avctx->coded_width = ctx->plane_width_aligned;
+
+    /* Get frame data buffers. */
+    if (ff_get_buffer(avctx, avframe, 0) < 0)
+        return AVERROR(ENOMEM);
+
+    /* Export decoded frame data. */
+    if (buf_index >= 0 && avframe->data[0]) {
+        NvBuffer2Raw(ctx->plane_dma_fd[buf_index], 0,
+                     ctx->plane_width[0], ctx->plane_height[0],
+                     avframe->data[0]);
+        NvBuffer2Raw(ctx->plane_dma_fd[buf_index], 1,
+                     ctx->plane_width[1], ctx->plane_height[1],
+                     avframe->data[1]);
+        if (ctx->cp_pixfmt == V4L2_PIX_FMT_YUV420M) {
+            NvBuffer2Raw(ctx->plane_dma_fd[buf_index], 2,
+                         ctx->plane_width[2], ctx->plane_height[2],
+                         avframe->data[2]);
+        }
+    }
+
+    avframe->width = _nvframe.width;
+    avframe->height = _nvframe.height;
+
+    avframe->format = avctx->pix_fmt;
+    avframe->pkt_dts = AV_NOPTS_VALUE;
+
+    /* Decide which timestamps to set. */
+    if (_nvframe.pts != AV_NOPTS_VALUE) {
+        avframe->pts = _nvframe.pts;
+    } else {
+        avframe->pts = _nvframe.pts;
+        avframe->reordered_opaque = _nvframe.user_pts;
+    }
+
+    avframe->key_frame = 0;
+
+    avctx->coded_width = _nvframe.width;
+    avctx->coded_height = _nvframe.height;
+    avctx->width = _nvframe.width;
+    avctx->height = _nvframe.height;
+
+    *got_frame = 1;
+
+    return processed_size;
+}
+
+#define NVV4L2_DEC_CLASS(NAME)                         \
+    static const AVClass nvv4l2_##NAME##_dec_class = { \
+        .class_name = "nvv4l2_" #NAME "_dec",          \
+        .version    = LIBAVUTIL_VERSION_INT,           \
+    };
+
+#define NVV4L2_DEC(NAME, ID, BSFS)                                                    \
+    NVV4L2_DEC_CLASS(NAME)                                                            \
+    AVCodec ff_##NAME##_nvv4l2_decoder = {                                            \
+        .name           = #NAME "_nvv4l2",                                            \
+        .long_name      = NULL_IF_CONFIG_SMALL(#NAME " NVV4L2 HW decoder for Tegra"), \
+        .type           = AVMEDIA_TYPE_VIDEO,                                         \
+        .id             = ID,                                                         \
+        .priv_data_size = sizeof(nvv4l2DecodeContext),                                \
+        .init           = nvv4l2dec_init,                                             \
+        .close          = nvv4l2dec_close,                                            \
+        .decode         = nvv4l2dec_decode,                                           \
+        .flush          = nvv4l2dec_flush,                                            \
+        .priv_class     = &nvv4l2_##NAME##_dec_class,                                 \
+        .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_HARDWARE |                \
+                          AV_CODEC_CAP_AVOID_PROBING,                                 \
+        .bsfs           = BSFS,                                                       \
+        .wrapper_name   = "nvv4l2",                                                   \
+        .pix_fmts       =(const enum AVPixelFormat[]){ AV_PIX_FMT_YUV420P,            \
+                                                       AV_PIX_FMT_NV12,               \
+                                                       AV_PIX_FMT_NONE },             \
+    };
+
+NVV4L2_DEC(h264,  AV_CODEC_ID_H264,       "h264_mp4toannexb");
+NVV4L2_DEC(hevc,  AV_CODEC_ID_HEVC,       "hevc_mp4toannexb");
+NVV4L2_DEC(mpeg2, AV_CODEC_ID_MPEG2VIDEO, NULL);
+NVV4L2_DEC(mpeg4, AV_CODEC_ID_MPEG4,      NULL);
+NVV4L2_DEC(vp9,   AV_CODEC_ID_VP9,        NULL);
+NVV4L2_DEC(vp8,   AV_CODEC_ID_VP8,        NULL);
diff -Naur ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2_enc.c ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2_enc.c
--- ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2_enc.c	1970-01-01 01:00:00.000000000 +0100
+++ ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2_enc.c	2022-04-20 03:49:41.823220489 +0200
@@ -0,0 +1,1440 @@
+/*
+ * Copyright (c) 2021-2022, CTCaer <ctcaer@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <stdint.h>
+#include <unistd.h>
+#include <pthread.h>
+#include <string.h>
+#include <fcntl.h>
+#include <errno.h>
+#include "internal.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/log.h"
+#include "libavutil/opt.h"
+
+#include "nvv4l2.h"
+
+#define ENCODER_DEV "/dev/nvhost-msenc"
+#define PACKET_DEFAULT_SIZE (2*1024*1024)
+
+/*
+ ** Output plane format support:
+ **  YM12 (YUV 4:2:0)
+ **  NM12 (YUV 4:2:0 interleaved)
+ **  YM24 (YUV 4:4:4)
+ **  PM10 (YUV 4:2:0 10-bit interleaved)
+ **
+ ** Capture plane format support:
+ **  H264 (H264 Encoded bitstream)
+ **  H265 (H265 Encoded bitstream)
+ **  VP80 (VP8  Encoded bitstream)
+ */
+
+/*
+ ** Output plane memory type support:
+ **  V4L2_MEMORY_MMAP
+ **  V4L2_MEMORY_DMABUF
+ ** Capture plane memory type support:
+ **  V4L2_MEMORY_MMAP
+ */
+
+typedef struct {
+    const AVClass *class;
+    nvv4l2_ctx_t *ctx;
+    int num_capture_buffers;
+    int profile;
+    int level;
+    int tier;
+    int rc;
+    int preset;
+    int lossless;
+    int twopass;
+} nvv4l2EncodeContext;
+
+static int
+set_output_plane_format(AVCodecContext *avctx, nvv4l2_ctx_t *ctx,
+                        uint32_t pixfmt, uint32_t width, uint32_t height)
+{
+    int ret;
+    struct v4l2_format format;
+    uint32_t num_bufferplanes;
+    NvBufferPlaneFormat planefmts[NV_MAX_PLANES];
+
+    /* Get plane format */
+    ret = nvv4l2_fill_buffer_plane_format(ctx, &num_bufferplanes, planefmts,
+                                          width, height, pixfmt);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error getting output plane format!\n");
+        ctx->in_error = true;
+        return ret;
+    }
+    ctx->op_num_planes = num_bufferplanes;
+
+    /* Set plane format. */
+    for (uint32_t j = 0; j < num_bufferplanes; ++j) {
+        ctx->op_planefmts[j] = planefmts[j];
+    }
+    memset(&format, 0, sizeof(struct v4l2_format));
+    format.type = ctx->op_buf_type;
+    format.fmt.pix_mp.width = width;
+    format.fmt.pix_mp.height = height;
+    format.fmt.pix_mp.pixelformat = pixfmt;
+    format.fmt.pix_mp.num_planes = num_bufferplanes;
+
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_S_FMT, &format);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in setting output plane format!\n");
+        ctx->in_error = true;
+    } else {
+        ctx->op_num_planes = format.fmt.pix_mp.num_planes;
+        for (uint32_t j = 0; j < ctx->op_num_planes; j++) {
+            ctx->op_planefmts[j].stride =
+                format.fmt.pix_mp.plane_fmt[j].bytesperline;
+            ctx->op_planefmts[j].sizeimage =
+                format.fmt.pix_mp.plane_fmt[j].sizeimage;
+        }
+    }
+
+    return ret;
+}
+
+static int
+set_capture_plane_format(AVCodecContext *avctx, nvv4l2_ctx_t *ctx,
+                         uint32_t pixfmt, uint32_t width,
+                         uint32_t height, uint32_t sizeimage)
+{
+    int ret;
+    struct v4l2_format format;
+
+    memset(&format, 0, sizeof(struct v4l2_format));
+    format.type = ctx->cp_buf_type;
+    format.fmt.pix_mp.pixelformat = pixfmt;
+    format.fmt.pix_mp.width = width;
+    format.fmt.pix_mp.height = height;
+    format.fmt.pix_mp.num_planes = 1;
+    format.fmt.pix_mp.plane_fmt[0].sizeimage = sizeimage;
+
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_S_FMT, &format);
+
+    if (ret == 0) {
+        ctx->cp_num_planes = format.fmt.pix_mp.num_planes;
+        for (uint32_t i = 0; i < ctx->cp_num_planes; ++i) {
+            ctx->cp_planefmts[i].stride =
+                format.fmt.pix_mp.plane_fmt[i].bytesperline;
+            ctx->cp_planefmts[i].sizeimage =
+                format.fmt.pix_mp.plane_fmt[i].sizeimage;
+        }
+    } else {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in setting capture plane format!\n");
+        ctx->in_error = true;
+    }
+
+    return ret;
+}
+
+static void *enc_capture_thread(void *arg)
+{
+    nvv4l2_ctx_t *ctx = (nvv4l2_ctx_t *)arg;
+    uint32_t packet_size;
+    int buf_index;
+    int ret;
+
+    /* Check for EOS event in case stream finished. */
+    while (!ctx->in_error && !ctx->eos) {
+        /* Main Capture loop for DQ and Q. */
+        struct v4l2_buffer v4l2_cp_buf;
+        struct v4l2_plane capture_planes[NV_MAX_PLANES];
+        v4l2_ctrl_videoenc_outputbuf_metadata enc_metadata;
+        NvBuffer *cp_buffer = NULL;
+
+        memset(&v4l2_cp_buf, 0, sizeof(v4l2_cp_buf));
+        memset(capture_planes, 0, sizeof(capture_planes));
+        v4l2_cp_buf.m.planes = capture_planes;
+        v4l2_cp_buf.length = 1;
+
+        /* Dequeue the filled buffer. */
+        if (nvv4l2_dq_buffer(ctx, &v4l2_cp_buf, &cp_buffer,
+             ctx->cp_buf_type, ctx->cp_mem_type, 0)) {
+            if (errno == EAGAIN) {
+                usleep(1000);
+            }
+            continue;
+        }
+
+        packet_size = cp_buffer->planes[0].bytesused;
+
+        if (packet_size == 0) {
+            av_log(ctx->avctx, AV_LOG_ERROR,
+                   "Got 0 size buffer in capture!\n");
+            ctx->in_error = true;
+            break;
+        }
+
+        buf_index = nvv4l2_pool_idx_next(ctx, ctx->export_pool);
+
+        if (buf_index >= 0) {
+            /* Ensure packet buffer fits new packet */
+            if (ctx->packet_buf_size[buf_index] < packet_size) {
+                NVFREE(ctx->packet[buf_index]);
+                ctx->packet[buf_index] = (unsigned char *)NVMALLOC(packet_size);
+                ctx->packet_buf_size[buf_index] = packet_size;
+            }
+
+            ctx->packet_size[buf_index] = packet_size;
+            memcpy(ctx->packet[buf_index], cp_buffer->planes[0].data,
+                   packet_size);
+
+            ctx->frame_pts[buf_index] = v4l2_cp_buf.timestamp.tv_usec +
+                                        (v4l2_cp_buf.timestamp.tv_sec *
+                                         AV_TIME_BASE);
+
+            ret = nvv4l2_get_ext_control_metadata(ctx->fd,
+                                                  v4l2_cp_buf.index,
+                                                  &enc_metadata);
+            if (ret) {
+                av_log(ctx->avctx, AV_LOG_ERROR,
+                       "Failed getting metadata!\n");
+                ctx->in_error = true;
+                break;
+            }
+            ctx->packet_keyflag[buf_index] =
+                                    enc_metadata.KeyFrame ? true : false;
+        }
+
+        nvv4l2_pool_push(ctx, ctx->export_pool);
+
+        /* Queue the buffer. */
+        ret = nvv4l2_q_buffer(ctx, &v4l2_cp_buf, cp_buffer, ctx->cp_buf_type,
+                              ctx->cp_mem_type, ctx->cp_num_planes);
+
+        if (ret) {
+            av_log(ctx->avctx, AV_LOG_ERROR,
+                   "Qing failed on capture plane!\n");
+            ctx->in_error = true;
+            break;
+        }
+    }
+
+    av_log(ctx->avctx, AV_LOG_VERBOSE,
+           "Exiting encoder capture loop thread\n");
+
+    return NULL;
+}
+
+nvv4l2_ctx_t *nvv4l2_create_encoder(AVCodecContext *avctx,
+                                    NvEncoder *encoder,
+                                    NvCodingType nv_codec_type,
+                                    int pix_fmt)
+{
+    nvv4l2EncodeContext *nvv4l2_ctx = avctx->priv_data;
+
+    int ret;
+    int flags = 0;
+    nvv4l2_ctx_t *ctx = (nvv4l2_ctx_t *)NVCALLOC(1, sizeof(nvv4l2_ctx_t));
+    ctx->avctx = avctx;
+    ctx->enc = encoder;
+
+    /* The call creates a new V4L2 Video Decoder object
+     ** on the device node "/dev/nvhost-msenc"
+     ** Additional flags can also be given with which the device
+     ** should be opened.
+     ** This opens the device in Blocking mode.
+     */
+    ctx->fd = v4l2_open(ENCODER_DEV, flags | O_RDWR);
+    if (ctx->fd == -1) {
+        av_log(avctx, AV_LOG_ERROR, "Could not open device!\n");
+        ctx->in_error = true;
+        return ctx;
+    }
+
+    /* Initialization. */
+    ctx->codec_width = encoder->width;
+    ctx->codec_height = encoder->height;
+    ctx->low_latency = encoder->low_latency;
+    ctx->op_pixfmt = pix_fmt;
+    ctx->cp_pixfmt = nvv4l2_map_nvcodec_type(nv_codec_type);
+
+    /* Get NvBuffer pixel format list version */
+    ctx->pixfmt_list_ver = nvv4l2_get_pixfmt_list_version(ctx);
+
+    /* Encoder code assumes that the following do not change.
+     ** If another memory type is wanted, relevant changes should be done
+     ** to the rest of the code.
+     */
+    ctx->op_mem_type = V4L2_MEMORY_DMABUF;
+    ctx->cp_mem_type = V4L2_MEMORY_MMAP;
+
+    ctx->op_buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    ctx->cp_buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+
+    for (uint32_t i = 0; i < NV_MAX_BUFFERS; i++)
+        ctx->plane_dma_fd[i] = -1;
+
+    /* Allocate packet pool. */
+    ctx->export_pool = (NvQueues *)NVCALLOC(1, sizeof(NvQueues));
+    for(int index = 0; index < NV_MAX_BUFFERS; index++) {
+        ctx->packet[index] = (unsigned char *)NVMALLOC(PACKET_DEFAULT_SIZE);
+        ctx->packet_buf_size[index] = PACKET_DEFAULT_SIZE;
+    }
+
+    /* Initialize mutexes */
+    pthread_mutex_init(&ctx->queue_lock, NULL);
+    pthread_cond_init(&ctx->queue_cond, NULL);
+
+    /* Set format on capture plane. */
+    ret = set_capture_plane_format(avctx, ctx, ctx->cp_pixfmt,
+                                   ctx->codec_width, ctx->codec_height,
+                                   PACKET_DEFAULT_SIZE);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in setting capture plane format!\n");
+        ctx->in_error = true;
+    }
+
+    /* Set format on output plane. */
+    ret = set_output_plane_format(avctx, ctx, ctx->op_pixfmt,
+                                  ctx->codec_width, ctx->codec_height);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in setting output plane format!\n");
+        ctx->in_error = true;
+    }
+
+    /* Set max performance mode if low latency is requested. */
+    if (ctx->low_latency) {
+        ret =
+        nvv4l2_set_ext_controls(ctx->fd,
+                                V4L2_CID_MPEG_VIDEO_MAX_PERFORMANCE, 0, 1);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to set control max performance!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Set encoder bitrate. */
+    ret = nvv4l2_set_ext_controls(ctx->fd, V4L2_CID_MPEG_VIDEO_BITRATE,
+                                  V4L2_CTRL_CLASS_MPEG,
+                                  ctx->enc->bitrate);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to set encoder bitrate!\n");
+        ctx->in_error = true;
+    }
+
+    /* Set encoder HW Preset Type. */
+    ret = nvv4l2_set_ext_controls(ctx->fd,
+                                  V4L2_CID_MPEG_VIDEOENC_HW_PRESET_TYPE_PARAM,
+                                  V4L2_CTRL_CLASS_MPEG,
+                                  ctx->enc->preset_type);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to set encoder HW Preset Type!\n");
+        ctx->in_error = true;
+    }
+
+    /* Set number of reference frames. */
+    if (ctx->enc->num_ref) {
+        ret = nvv4l2_set_ext_controls(ctx->fd,
+                                V4L2_CID_MPEG_VIDEOENC_NUM_REFERENCE_FRAMES,
+                                V4L2_CTRL_CLASS_MPEG,
+                                ctx->enc->num_ref);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to set num reference frames!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Set number of B Frames. */
+    if (ctx->enc->num_b_frames && nv_codec_type == NvVideoCodec_H264) {
+        ret = nvv4l2_set_ext_controls(ctx->fd,
+                                      V4L2_CID_MPEG_VIDEOENC_NUM_BFRAMES,
+                                      V4L2_CTRL_CLASS_MPEG,
+                                      ctx->enc->num_b_frames);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to set number of B Frames!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Set encoder profile. */
+    ret = nvv4l2_set_ext_controls(ctx->fd, nv_codec_type == NvVideoCodec_H264 ?
+                                  V4L2_CID_MPEG_VIDEO_H264_PROFILE :
+                                  V4L2_CID_MPEG_VIDEO_H265_PROFILE,
+                                  V4L2_CTRL_CLASS_MPEG,
+                                  ctx->enc->profile);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to set encoder profile!\n");
+        ctx->in_error = true;
+    }
+
+    /* Set encoder level. */
+    ret = nvv4l2_set_ext_controls(ctx->fd, nv_codec_type == NvVideoCodec_H264 ?
+                                  V4L2_CID_MPEG_VIDEO_H264_LEVEL :
+                                  V4L2_CID_MPEG_VIDEOENC_H265_LEVEL,
+                                  V4L2_CTRL_CLASS_MPEG,
+                                  ctx->enc->level);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to set encoder level!\n");
+        ctx->in_error = true;
+    }
+
+    if (!ctx->enc->lossless) {
+        /* Set encoder rate control mode. */
+        ret = nvv4l2_set_ext_controls(ctx->fd, V4L2_CID_MPEG_VIDEO_BITRATE_MODE,
+                                      V4L2_CTRL_CLASS_MPEG,
+                                      ctx->enc->ratecontrol);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to set encoder rate control mode!\n");
+            ctx->in_error = true;
+        }
+
+        /* Set encoder max bitrate for VBR. */
+        if (ctx->enc->ratecontrol == V4L2_MPEG_VIDEO_BITRATE_MODE_VBR) {
+
+            uint32_t max_bitrate = 1.2f * ctx->enc->bitrate;
+            ret = nvv4l2_set_ext_controls(ctx->fd,
+                                          V4L2_CID_MPEG_VIDEO_BITRATE_PEAK,
+                                          V4L2_CTRL_CLASS_MPEG,
+                                          max_bitrate);
+            if (ret) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Failed to set encoder max bitrate for VBR!\n");
+                ctx->in_error = true;
+            }
+        }
+    } else {
+        /* Set constant qp configuration for lossless encoding enabled */
+        ret = nvv4l2_set_ext_control_constant_qp(ctx->fd, 0);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to set encoder qp to 0 for lossless encoding!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Set Two-pass CBR mode. */
+    if (ctx->enc->twopass) {
+        /* Set encoder IDR interval. */
+        ret = nvv4l2_set_ext_controls(ctx->fd,
+                                      V4L2_CID_MPEG_VIDEOENC_TWO_PASS_CBR,
+                                      V4L2_CTRL_CLASS_MPEG,
+                                      1);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to set encoder 2-pass cbr!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Set encoder IDR interval. */
+    ret = nvv4l2_set_ext_controls(ctx->fd, V4L2_CID_MPEG_VIDEO_IDR_INTERVAL,
+                                  V4L2_CTRL_CLASS_MPEG,
+                                  ctx->enc->idr_interval);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to set encoder IDR interval!\n");
+        ctx->in_error = true;
+    }
+
+    /* Set encoder quantization parameters. */
+    if (ctx->enc->qmin != -1 || ctx->enc->qmax != -1) {
+        ret = nvv4l2_set_ext_control_qp_range(ctx->fd,
+                                              ctx->enc->qmin, ctx->enc->qmax);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to set encoder quantization parameters!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Set encoder I-Frame interval. */
+    ret = nvv4l2_set_ext_controls(ctx->fd, V4L2_CID_MPEG_VIDEO_GOP_SIZE,
+                                  V4L2_CTRL_CLASS_MPEG,
+                                  ctx->enc->iframe_interval);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to set encoder I-Frame interval!\n");
+        ctx->in_error = true;
+    }
+
+    /* Set insertSPSPPSAtIDR. */
+    if (ctx->enc->sps_pps_at_idr) {
+        ret = nvv4l2_set_ext_controls(ctx->fd,
+                                V4L2_CID_MPEG_VIDEOENC_INSERT_SPS_PPS_AT_IDR,
+                                V4L2_CTRL_CLASS_MPEG,
+                                1);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to set insertSPSPPSAtIDR!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Set encoder framerate. */
+    ret = nvv4l2_set_stream_control_framerate(ctx->fd,
+                                              ctx->op_mem_type,
+                                              ctx->enc->fps_n,
+                                              ctx->enc->fps_d);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Failed to set framerate!\n");
+        ctx->in_error = true;
+    }
+
+    /* Request max 10 buffers on output plane.
+     ** Number of received buffers normally is lower (6). */
+    ret = nvv4l2_req_buffers_on_output_plane(ctx,
+                                             ctx->op_buf_type,
+                                             ctx->op_mem_type,
+                                             10);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in requesting buffers on output plane!\n");
+        ctx->in_error = true;
+    }
+
+    /* Create import DMA buffers. */
+    for (uint32_t i = 0; i < ctx->op_num_buffers; i++) {
+        NvBufferCreateParams iParams;
+        memset(&iParams, 0, sizeof(NvBufferCreateParams));
+        iParams.width = ctx->codec_width;
+        iParams.height = ctx->codec_height;
+        iParams.layout = NvBufferLayout_Pitch;
+        iParams.payloadType = NvBufferPayload_SurfArray;
+        iParams.nvbuf_tag = NvBufferTag_VIDEO_ENC;
+        switch (ctx->op_pixfmt) {
+        case V4L2_PIX_FMT_YUV444M:
+            iParams.colorFormat = NvBufferColorFormat_YUV444;
+            break;
+        case V4L2_PIX_FMT_P010M:
+            iParams.layout = NvBufferLayout_BlockLinear;
+            iParams.colorFormat = NvBufferColorFormat_NV12_10LE;
+            break;
+        case V4L2_PIX_FMT_NV12M:
+            iParams.colorFormat = NvBufferColorFormat_NV12;
+            break;
+        default:
+            iParams.colorFormat = NvBufferColorFormat_YUV420;
+            break;
+        }
+
+        if (ctx->enc->profile == V4L2_MPEG_VIDEO_H265_PROFILE_MAIN10) {
+            iParams.layout = NvBufferLayout_BlockLinear;
+            iParams.colorFormat = NvBufferColorFormat_NV12_10LE;
+        }
+
+        /* Increment color format if NvBuffer is newer. */
+        if (ctx->pixfmt_list_ver == NvBufferPixFmtVersion_New &&
+             iParams.colorFormat > NvBufferColorFormat_YUV420) {
+            iParams.colorFormat++;
+        }
+
+        ret = NvBufferCreateEx(&ctx->plane_dma_fd[i], &iParams);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR, "Creation of dmabuf failed!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Request buffers on capture plane. */
+    ret = nvv4l2_req_buffers_on_capture_plane(ctx,
+                                         ctx->cp_buf_type,
+                                         ctx->cp_mem_type,
+                                         nvv4l2_ctx->num_capture_buffers);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Error in requesting buffers on capture plane!\n");
+        ctx->in_error = true;
+    }
+
+    /* Map buffers on capture plane */
+    for (uint32_t i = 0; i < ctx->cp_num_buffers; i++) {
+        ret = nvv4l2_query_buffer(ctx, ctx->cp_buf_type,
+                                  ctx->cp_mem_type, ctx->cp_num_planes, i);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to query buffer on capture plane!\n");
+            ctx->in_error = true;
+        }
+        ret = nvv4l2_export_buffer(ctx, ctx->cp_buf_type,
+                                   ctx->cp_num_planes, i);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to export buffer on capture plane!\n");
+            ctx->in_error = true;
+        }
+        ret = nvv4l2_map(ctx, ctx->cp_buffers[i]);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Failed to map buffer on capture plane!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    /* Start stream processing on output plane. */
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMON, &ctx->op_buf_type);
+    if (ret != 0) {
+        av_log(avctx, AV_LOG_ERROR, "Streaming error on output plane!\n");
+        ctx->in_error = true;
+    }
+    ctx->op_streamon = true;
+
+     /* Set streaming status ON on capture plane. */
+    ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMON, &ctx->cp_buf_type);
+    if (ret != 0) {
+        av_log(avctx, AV_LOG_ERROR, "Streaming error on capture plane!\n");
+        ctx->in_error = true;
+    }
+    ctx->cp_streamon = true;
+
+    /* Create and start capture loop thread. */
+    pthread_create(&ctx->capture_thread, NULL, enc_capture_thread, ctx);
+
+    /* Enqueue all the empty capture plane buffers. */
+    for (uint32_t i = 0; i < ctx->cp_num_buffers; i++){
+        struct v4l2_buffer v4l2_buf;
+        struct v4l2_plane planes[NV_MAX_PLANES];
+        memset(&v4l2_buf, 0, sizeof(v4l2_buf));
+        memset(planes, 0, NV_MAX_PLANES * sizeof(struct v4l2_plane));
+
+        v4l2_buf.index = i;
+        v4l2_buf.m.planes = planes;
+
+        ret = nvv4l2_q_buffer(ctx, &v4l2_buf, ctx->cp_buffers[i],
+                              ctx->cp_buf_type, ctx->cp_mem_type,
+                              ctx->cp_num_planes);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR, "Qing failed on capture plane!\n");
+            ctx->in_error = true;
+        }
+    }
+
+    return ctx;
+}
+
+int nvv4l2_encoder_put_frame(AVCodecContext *avctx, nvv4l2_ctx_t *ctx,
+                             NvFrame *frame)
+{
+    int ret;
+    struct v4l2_buffer v4l2_buf_op;
+    struct v4l2_plane queue_op_planes[NV_MAX_PLANES];
+    NvBuffer *buffer;
+    memset(&v4l2_buf_op, 0, sizeof(v4l2_buf_op));
+    memset(queue_op_planes, 0, sizeof(queue_op_planes));
+    v4l2_buf_op.m.planes = queue_op_planes;
+
+    if (ctx->in_error)
+        return -1;
+
+    if (ctx->num_active_op_buffers < ctx->op_num_buffers) {
+        /* Get an unused buffer to add to the queue. */
+        buffer = ctx->op_buffers[ctx->num_active_op_buffers];
+        v4l2_buf_op.index = ctx->num_active_op_buffers;
+
+        /* Map new plane buffer for memory type DMABUF. */
+        v4l2_buf_op.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        v4l2_buf_op.memory = ctx->op_mem_type;
+        ret = nvv4l2_map_out(ctx, &v4l2_buf_op, ctx->op_buf_type,
+                             ctx->op_mem_type,
+                             ctx->plane_dma_fd[v4l2_buf_op.index]);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Error while mapping buffer at output plane!\n");
+            ctx->in_error = true;
+            return -1;
+        }
+    } else {
+        /* Dequeue a finished buffer and reuse it. */
+        ret = nvv4l2_dq_buffer(ctx, &v4l2_buf_op, &buffer,
+                               ctx->op_buf_type, ctx->op_mem_type, -1);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Error DQing buffer at output plane!\n");
+            ctx->in_error = true;
+            return -1;
+        }
+    }
+
+    /* Import frame into output plane */
+    for (uint32_t i = 0; i < buffer->n_planes; i++) {
+        Raw2NvBuffer(frame->payload[i], i, ctx->op_planefmts[i].width,
+                     ctx->op_planefmts[i].height, buffer->planes[i].fd);
+        buffer->planes[i].bytesused = ctx->op_planefmts[i].width *
+                                      ctx->op_planefmts[i].height *
+                                      ctx->op_planefmts[i].bytesperpixel;
+        v4l2_buf_op.m.planes[i].bytesused = buffer->planes[i].bytesused;
+    }
+
+    /* Set timestamp */
+    v4l2_buf_op.flags |= V4L2_BUF_FLAG_TIMESTAMP_COPY;
+    v4l2_buf_op.timestamp.tv_usec = frame->pts % AV_TIME_BASE;
+    v4l2_buf_op.timestamp.tv_sec = frame->pts / AV_TIME_BASE;
+
+    /* Queue frame on output plane. */
+    ret = nvv4l2_q_buffer(ctx, &v4l2_buf_op, buffer,
+                   ctx->op_buf_type, ctx->op_mem_type, ctx->op_num_planes);
+    if (ret) {
+        av_log(avctx, AV_LOG_ERROR, "Error Qing buffer at output plane!\n");
+        ctx->in_error = true;
+        return -1;
+    }
+
+    if (ctx->num_active_op_buffers < ctx->op_num_buffers) {
+        ctx->num_active_op_buffers++;
+    }
+
+    return 0;
+}
+
+int nvv4l2_encoder_get_packet(AVCodecContext *avctx,
+                              nvv4l2_ctx_t *ctx,
+                              NvPacket *packet)
+{
+    int packet_index;
+
+    if (ctx->export_pool->capacity == 0)
+        return 1;
+
+    packet_index = nvv4l2_pool_pop(ctx, ctx->export_pool);
+
+    packet->payload = ctx->packet[packet_index];
+    packet->payload_size = ctx->packet_size[packet_index];
+    packet->pts = ctx->frame_pts[packet_index];
+
+    if (ctx->packet_keyflag[packet_index])
+        packet->flags |= AV_PKT_FLAG_KEY;
+
+    return 0;
+}
+
+int nvv4l2_encoder_close(AVCodecContext *avctx, nvv4l2_ctx_t *ctx)
+{
+    int ret;
+
+    if (!ctx)
+        return 0;
+
+    pthread_mutex_lock(&ctx->queue_lock);
+    ctx->eos = true;
+    pthread_mutex_unlock(&ctx->queue_lock);
+    if (ctx->fd != -1) {
+        /* Stop streaming on both planes. */
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMOFF, &ctx->op_buf_type);
+        ret = v4l2_ioctl(ctx->fd, VIDIOC_STREAMOFF, &ctx->cp_buf_type);
+
+        /* Wait for capture thread to exit. */
+        if (ctx->capture_thread) {
+            pthread_join(ctx->capture_thread, NULL);
+        }
+
+        /* Unmap MMAPed buffers. */
+        for (uint32_t i = 0; i < ctx->cp_num_buffers; ++i) {
+            nvv4l2_destroyBuffer(ctx, ctx->cp_buffers[i]);
+        }
+
+        /* Request 0 buffers on both planes. */
+        ret = nvv4l2_req_buffers_on_output_plane(ctx,
+                                                 ctx->op_buf_type,
+                                                 ctx->op_mem_type, 0);
+
+        ret = nvv4l2_req_buffers_on_capture_plane(ctx,
+                                                  ctx->cp_buf_type,
+                                                  ctx->cp_mem_type, 0);
+
+        /* Unmap and destroy all allocated DMA buffers. */
+        for (uint32_t i = 0; i < ctx->op_num_buffers; i++) {
+            if (ctx->plane_dma_fd[i] != -1) {
+                nvv4l2_unmap_out(ctx, i, ctx->op_buf_type,
+                                 ctx->op_mem_type, ctx->plane_dma_fd[i]);
+                ret = NvBufferDestroy(ctx->plane_dma_fd[i]);
+                ctx->plane_dma_fd[i] = -1;
+                if (ret) {
+                    av_log(avctx, AV_LOG_ERROR,
+                           "Failed to destroy output plane dma buffer!\n");
+                }
+            }
+        }
+
+        /* Free packet pool */
+        for (int index = 0; index < NV_MAX_BUFFERS; index++) {
+            NVFREE(ctx->packet[index]);
+        }
+        NVFREE(ctx->export_pool);
+
+        /* Close the opened V4L2 device. */
+        ret = v4l2_close(ctx->fd);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR, "Unable to close the device!\n");
+        }
+
+        /* Free mutexes */
+        pthread_mutex_destroy(&ctx->queue_lock);
+        pthread_cond_destroy(&ctx->queue_cond);
+    }
+
+    /* Free encoder parameters */
+    NVFREE(ctx->enc);
+
+    /* Report application run status on exit. */
+    if (ctx->in_error) {
+        av_log(avctx, AV_LOG_ERROR, "Encoder Run failed\n");
+    } else {
+        av_log(avctx, AV_LOG_VERBOSE, "Encoder Run is successful\n");
+    }
+
+    NVFREE(ctx);
+
+    return ret;
+}
+
+static void
+nvv4l2_set_h264_profile_params(nvv4l2EncodeContext *nvv4l2_ctx,
+                               NvEncoder *enc,
+                               int *pix_fmt)
+{
+    switch (nvv4l2_ctx->profile & ~FF_PROFILE_H264_INTRA) {
+    case FF_PROFILE_H264_MAIN:
+        enc->profile = V4L2_MPEG_VIDEO_H264_PROFILE_MAIN;
+        break;
+    case FF_PROFILE_H264_BASELINE:
+        enc->profile = V4L2_MPEG_VIDEO_H264_PROFILE_BASELINE;
+        break;
+    case FF_PROFILE_H264_HIGH:
+        enc->profile = V4L2_MPEG_VIDEO_H264_PROFILE_HIGH;
+        break;
+    case FF_PROFILE_H264_HIGH_444_PREDICTIVE:
+        enc->profile = V4L2_MPEG_VIDEO_H264_PROFILE_HIGH_444_PREDICTIVE;
+        break;
+
+    default:
+        enc->profile = V4L2_MPEG_VIDEO_H264_PROFILE_MAIN;
+        break;
+    }
+
+    if (enc->lossless && *pix_fmt == V4L2_PIX_FMT_YUV444M)
+        enc->profile = V4L2_MPEG_VIDEO_H264_PROFILE_HIGH_444_PREDICTIVE;
+
+    switch (nvv4l2_ctx->level) {
+    case 9:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_1B;
+        break;
+    case 10:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_1_0;
+        break;
+    case 11:
+        if (nvv4l2_ctx->profile & FF_PROFILE_H264_INTRA)
+            enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_1B;
+        else
+            enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_1_1;
+        break;
+    case 12:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_1_2;
+        break;
+    case 13:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_1_3;
+        break;
+    case 20:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_2_0;
+        break;
+    case 21:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_2_1;
+        break;
+    case 22:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_2_2;
+        break;
+    case 30:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_3_0;
+        break;
+    case 31:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_3_1;
+        break;
+    case 32:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_3_2;
+        break;
+    case 40:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_4_0;
+        break;
+    case 41:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_4_1;
+        break;
+    case 42:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_4_2;
+        break;
+    case 50:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_5_0;
+        break;
+    case 51:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_5_1;
+        break;
+    default:
+        enc->level = V4L2_MPEG_VIDEO_H264_LEVEL_5_1;
+        break;
+    }
+}
+
+static void
+nvv4l2_set_hevc_profile_params(nvv4l2EncodeContext *nvv4l2_ctx,
+                               NvEncoder *enc,
+                               int *pix_fmt)
+{
+    switch (nvv4l2_ctx->profile & ~FF_PROFILE_H264_INTRA) {
+    case FF_PROFILE_HEVC_MAIN:
+        enc->profile = V4L2_MPEG_VIDEO_H265_PROFILE_MAIN;
+        break;
+    case FF_PROFILE_HEVC_MAIN_10:
+        enc->profile = V4L2_MPEG_VIDEO_H265_PROFILE_MAIN10;
+        *pix_fmt = V4L2_PIX_FMT_P010M;
+        break;
+
+    default:
+        enc->profile = V4L2_MPEG_VIDEO_H265_PROFILE_MAIN;
+        break;
+    }
+
+    if (*pix_fmt == V4L2_PIX_FMT_P010M)
+        enc->profile = V4L2_MPEG_VIDEO_H265_PROFILE_MAIN10;
+
+    switch (nvv4l2_ctx->tier) {
+    case 0:
+    case 1:
+        enc->tier = nvv4l2_ctx->tier;
+        break;
+
+    default:
+        enc->tier = 0;
+        break;
+    }
+
+    switch (nvv4l2_ctx->level) {
+    case 30:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_1_0_MAIN_TIER;
+        break;
+    case 60:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_2_0_MAIN_TIER;
+        break;
+    case 63:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_2_1_MAIN_TIER;
+        break;
+    case 90:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_3_0_MAIN_TIER;
+        break;
+    case 93:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_3_1_MAIN_TIER;
+        break;
+    case 120:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_4_0_MAIN_TIER;
+        break;
+    case 123:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_4_1_MAIN_TIER;
+        break;
+    case 150:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_5_0_MAIN_TIER;
+        break;
+    case 153:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_5_1_MAIN_TIER;
+        break;
+    case 156:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_5_2_MAIN_TIER;
+        break;
+    case 180:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_6_0_MAIN_TIER;
+        break;
+    case 183:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_6_1_MAIN_TIER;
+        break;
+    case 186:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_6_2_MAIN_TIER;
+        break;
+    default:
+        enc->level = V4L2_MPEG_VIDEO_H265_LEVEL_6_2_MAIN_TIER;
+        break;
+    }
+
+    enc->level += enc->tier;
+}
+
+static NvEncoder *set_encoder_parameters(AVCodecContext *avctx,
+                                         nvv4l2EncodeContext *nvv4l2_ctx,
+                                         NvCodingType nv_codec_type,
+                                         int *pix_fmt)
+{
+    NvEncoder *enc = (NvEncoder *)NVCALLOC(1, sizeof(NvEncoder));
+
+    enc->lossless = nvv4l2_ctx->lossless;
+    enc->ratecontrol = nvv4l2_ctx->rc == 1 ?
+                            V4L2_MPEG_VIDEO_BITRATE_MODE_VBR :
+                            V4L2_MPEG_VIDEO_BITRATE_MODE_CBR;
+    if (nvv4l2_ctx->twopass) {
+        enc->twopass = 1;
+        enc->ratecontrol = V4L2_MPEG_VIDEO_BITRATE_MODE_CBR;
+    }
+
+    enc->width = avctx->width;
+    enc->height = avctx->height;
+    enc->bitrate = avctx->bit_rate;
+
+    if (nv_codec_type == NvVideoCodec_H264) {
+        nvv4l2_set_h264_profile_params(nvv4l2_ctx, enc, pix_fmt);
+    } else if (nv_codec_type == NvVideoCodec_HEVC) {
+        nvv4l2_set_hevc_profile_params(nvv4l2_ctx, enc, pix_fmt);
+    }
+
+    switch (nvv4l2_ctx->preset) {
+    case 1:
+        enc->preset_type = V4L2_ENC_HW_PRESET_ULTRAFAST;
+        break;
+    case 2:
+        enc->preset_type = V4L2_ENC_HW_PRESET_FAST;
+        break;
+    case 3:
+        enc->preset_type = V4L2_ENC_HW_PRESET_MEDIUM;
+        break;
+    case 4:
+        enc->preset_type = V4L2_ENC_HW_PRESET_SLOW;
+        break;
+    default:
+        enc->preset_type = V4L2_ENC_HW_PRESET_MEDIUM;
+        break;
+    }
+
+    if (avctx->gop_size > 0) {
+        enc->idr_interval = avctx->gop_size;
+        enc->iframe_interval = avctx->gop_size;
+    } else {
+        enc->idr_interval = 60;
+        enc->iframe_interval = 30;
+    }
+    enc->fps_n = avctx->framerate.num;
+    enc->fps_d = avctx->framerate.den;
+
+    if (avctx->qmin >= 0 && avctx->qmax >= 0) {
+        enc->qmin = avctx->qmin;
+        enc->qmax = avctx->qmax;
+    } else {
+        enc->qmin = -1;
+        enc->qmax = -1;
+    }
+
+    if (avctx->max_b_frames >= 0 && avctx->max_b_frames < 3)
+        enc->num_b_frames = avctx->max_b_frames;
+
+    if (avctx->refs > 0)
+        enc->num_ref = avctx->refs;
+
+    enc->sps_pps_at_idr = !(avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER);
+    enc->low_latency = (avctx->flags & AV_CODEC_FLAG_LOW_DELAY) ? true : false;
+
+    return enc;
+}
+
+static NvCodingType map_avcodec_id(enum AVCodecID id)
+{
+    switch (id) {
+    case AV_CODEC_ID_H264:
+        return NvVideoCodec_H264;
+    case AV_CODEC_ID_HEVC:
+        return NvVideoCodec_HEVC;
+    }
+    return NvVideoCodec_UNDEFINED;
+}
+
+static int nvv4l2enc_init(AVCodecContext *avctx)
+{
+    nvv4l2EncodeContext *nvv4l2_ctx = avctx->priv_data;
+    NvCodingType nv_codec_type;
+    NvEncoder *encoder;
+    int pix_fmt;
+
+    nv_codec_type = map_avcodec_id(avctx->codec_id);
+    if (nv_codec_type == NvVideoCodec_UNDEFINED) {
+        av_log(avctx, AV_LOG_ERROR, "Unsupported codec ID %d!\n",
+               avctx->codec_id);
+        return AVERROR_BUG;
+    }
+
+    /* Set output plane pixel format. */
+    switch (avctx->pix_fmt) {
+    case AV_PIX_FMT_YUV444P:
+        pix_fmt = V4L2_PIX_FMT_YUV444M;
+        break;
+    case AV_PIX_FMT_NV12:
+        pix_fmt = V4L2_PIX_FMT_NV12M;
+        break;
+    case AV_PIX_FMT_P010:
+        pix_fmt = V4L2_PIX_FMT_P010M;
+        break;
+    case AV_PIX_FMT_NONE:
+        avctx->pix_fmt = AV_PIX_FMT_YUV420P;
+    case AV_PIX_FMT_YUV420P:
+        pix_fmt = V4L2_PIX_FMT_YUV420M;
+        break;
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Unsupported pixel format %d!\n",
+               avctx->pix_fmt);
+        return AVERROR_BUG;
+    }
+
+    /* Set encoder parameters. */
+    encoder = set_encoder_parameters(avctx, nvv4l2_ctx, nv_codec_type,
+                                     &pix_fmt);
+
+    /* Check if global SPS/PPS header is required and sample it. */
+    if (nv_codec_type == NvVideoCodec_H264 &&
+        (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER)) {
+        NvFrame _nvframe = {0};
+        NvPacket packet = {0};
+        uint8_t *dst[4];
+        int linesize[4];
+        int header_size = 0;
+        int ret = 0;
+
+        nvv4l2_ctx->ctx = nvv4l2_create_encoder(avctx, encoder,
+                                                NvVideoCodec_H264,
+                                                pix_fmt);
+        if (!nvv4l2_ctx->ctx || nvv4l2_ctx->ctx->in_error) {
+            ret = 1;
+            goto out;
+        }
+
+        /* Get a blank packet to extract metadata */
+        av_image_alloc(dst, linesize, avctx->width, avctx->height,
+                       avctx->pix_fmt, 1);
+
+        while (true) {
+            _nvframe.payload[0] = dst[0];
+            _nvframe.payload[1] = dst[1];
+            _nvframe.payload[2] = dst[2];
+
+            ret = nvv4l2_encoder_put_frame(avctx, nvv4l2_ctx->ctx, &_nvframe);
+            if (ret)
+                goto out;
+
+            /* Try several times to get a packet before queuing a new one. */
+            for (uint32_t i = 0; i < 100; i++) {
+                ret = nvv4l2_encoder_get_packet(avctx, nvv4l2_ctx->ctx,
+                                                &packet);
+                if (!ret)
+                    break;
+                usleep(1000);
+            }
+            if (ret)
+                continue;
+
+            /* Find H264_NAL_IDR_SLICE */
+            for (header_size = 0;
+                 (header_size + 4) < packet.payload_size;
+                 header_size++) {
+                if (packet.payload[header_size]     == 0 &&
+                    packet.payload[header_size + 1] == 0 &&
+                    packet.payload[header_size + 2] == 0 &&
+                    packet.payload[header_size + 3] == 1 &&
+                    packet.payload[header_size + 4] == 0x65) {
+                    break;
+                }
+            }
+
+            if (header_size >= packet.payload_size) {
+                av_log(avctx, AV_LOG_ERROR, "Header was not found!\n");
+                return AVERROR_BUG;
+            }
+
+            avctx->extradata_size = header_size;
+            avctx->extradata = av_mallocz(header_size +
+                                          AV_INPUT_BUFFER_PADDING_SIZE);
+            memcpy(avctx->extradata, packet.payload, header_size);
+
+            break;
+        }
+        av_free(dst[0]);
+
+out:
+        nvv4l2_encoder_close(avctx, nvv4l2_ctx->ctx);
+        if (ret) {
+            av_log(avctx, AV_LOG_ERROR, "Error in initializing!\n");
+            return AVERROR_BUG;
+        }
+
+        /* Set encoder parameters again */
+        encoder = set_encoder_parameters(avctx, nvv4l2_ctx, nv_codec_type,
+                                         &pix_fmt);
+    }
+
+    nvv4l2_ctx->ctx = nvv4l2_create_encoder(avctx, encoder, nv_codec_type,
+                                            pix_fmt);
+
+    if (!nvv4l2_ctx->ctx || nvv4l2_ctx->ctx->in_error) {
+        nvv4l2_encoder_close(avctx, nvv4l2_ctx->ctx);
+        return AVERROR_BUG;
+    } else
+        return 0;
+}
+
+static int
+nvv4l2enc_encode(AVCodecContext *avctx, AVPacket *pkt,
+                 const AVFrame *frame, int *got_packet)
+{
+    nvv4l2EncodeContext *nvv4l2_ctx = avctx->priv_data;
+    nvv4l2_ctx_t *ctx = nvv4l2_ctx->ctx;
+    NvFrame _nvframe = {0};
+    NvPacket packet = {0};
+
+    if (ctx->in_error) {
+        return AVERROR_UNKNOWN;
+    }
+
+    if (frame) {
+        _nvframe.payload[0] = frame->data[0];
+        _nvframe.payload[1] = frame->data[1];
+        _nvframe.payload[2] = frame->data[2];
+
+        _nvframe.pts = frame->pts;
+
+        if (nvv4l2_encoder_put_frame(avctx, ctx, &_nvframe))
+            return AVERROR_UNKNOWN;
+    }
+
+    if (nvv4l2_encoder_get_packet(avctx, ctx, &packet))
+        return 0;
+
+    ff_alloc_packet2(avctx, pkt, packet.payload_size, packet.payload_size);
+
+    memcpy(pkt->data, packet.payload, packet.payload_size);
+    pkt->dts = pkt->pts = packet.pts;
+
+    if (packet.flags & AV_PKT_FLAG_KEY)
+        pkt->flags = AV_PKT_FLAG_KEY;
+
+    *got_packet = 1;
+
+    return 0;
+}
+
+static av_cold int nvv4l2enc_close(AVCodecContext *avctx)
+{
+    nvv4l2EncodeContext *nvv4l2_ctx = avctx->priv_data;
+    nvv4l2_encoder_close(avctx, nvv4l2_ctx->ctx);
+
+    return 0;
+}
+
+static const AVCodecDefault defaults[] = {
+    { "b",     "5M" },
+    { "qmin",  "-1" },
+    { "qmax",  "-1" },
+    { "qdiff", "-1" },
+    { "qblur", "-1" },
+    { "qcomp", "-1" },
+    { "g",     "50" },
+    { "bf",    "0" },
+    { "refs",  "0" },
+    { NULL },
+};
+
+#define OFFSET(x) offsetof(nvv4l2EncodeContext, x)
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+
+static const AVOption options_h264[] = {
+    { "num_capture_buffers", "Number of buffers in the capture context",
+        OFFSET(num_capture_buffers), AV_OPT_TYPE_INT, {.i64 = 10 }, 1, 32, VE },
+
+    { "profile",  "Set the encoding profile", OFFSET(profile), AV_OPT_TYPE_INT,
+        { .i64 = FF_PROFILE_H264_MAIN }, FF_PROFILE_H264_BASELINE,
+        FF_PROFILE_H264_HIGH_444_PREDICTIVE, VE, "profile" },
+#define PROFILE(name, value)  name, NULL, 0, AV_OPT_TYPE_CONST, \
+                              { .i64 = value }, 0, 0, VE, "profile"
+    { PROFILE("baseline", FF_PROFILE_H264_BASELINE) },
+    { PROFILE("main",     FF_PROFILE_H264_MAIN) },
+    { PROFILE("high",     FF_PROFILE_H264_HIGH) },
+    { PROFILE("high444",  FF_PROFILE_H264_HIGH_444_PREDICTIVE) },
+#undef PROFILE
+
+    { "level", "Profile Level", OFFSET(level), AV_OPT_TYPE_INT,
+        { .i64 = 51 }, 9, 51, VE, "level" },
+#define LEVEL(name, value) name, NULL, 0, AV_OPT_TYPE_CONST, \
+                           { .i64 = value }, 0, 0, VE, "level"
+    { LEVEL("1.0", 10) },
+    { LEVEL("1b",  9 ) },
+    { LEVEL("1.1", 11) },
+    { LEVEL("1.2", 12) },
+    { LEVEL("1.3", 13) },
+    { LEVEL("2.0", 20) },
+    { LEVEL("2.1", 21) },
+    { LEVEL("2.2", 22) },
+    { LEVEL("3.0", 30) },
+    { LEVEL("3.1", 31) },
+    { LEVEL("3.2", 32) },
+    { LEVEL("4.0", 40) },
+    { LEVEL("4.1", 41) },
+    { LEVEL("4.2", 42) },
+    { LEVEL("5.0", 50) },
+    { LEVEL("5.1", 51) },
+#undef LEVEL
+
+    { "lossless", "Enable lossless encoding", OFFSET(lossless), AV_OPT_TYPE_INT,
+        { .i64 = 0 }, 0, 1, VE, "lossless"},
+#define LOSSLESS(name, value)  name, NULL, 0, AV_OPT_TYPE_CONST, \
+                           { .i64 = value }, 0, 0, VE, "lossless"
+    { LOSSLESS("off", 0) },
+    { LOSSLESS("on",  1) },
+#undef LOSSLESS
+
+    { "rc",  "Override the preset rate-control",
+        OFFSET(rc), AV_OPT_TYPE_INT,   { .i64 = 1 }, 0, 1, VE, "rc" },
+    { "cbr", "Constant bitrate mode", 0, AV_OPT_TYPE_CONST,
+        { .i64 = 0  },  0, 0, VE, "rc" },
+    { "vbr", "Variable bitrate mode", 0, AV_OPT_TYPE_CONST,
+        { .i64 = 1  },  0, 0, VE, "rc" },
+
+    { "preset",    "Set the encoding preset", OFFSET(preset),
+        AV_OPT_TYPE_INT,   { .i64 = 3 }, 1, 4, VE, "preset" },
+    { "default",   "", 0, AV_OPT_TYPE_CONST, { .i64 = 3 }, 0, 0, VE, "preset" },
+    { "slow",      "", 0, AV_OPT_TYPE_CONST, { .i64 = 4 }, 0, 0, VE, "preset" },
+    { "medium",    "", 0, AV_OPT_TYPE_CONST, { .i64 = 3 }, 0, 0, VE, "preset" },
+    { "fast",      "", 0, AV_OPT_TYPE_CONST, { .i64 = 2 }, 0, 0, VE, "preset" },
+    { "ultrafast", "", 0, AV_OPT_TYPE_CONST, { .i64 = 1 }, 0, 0, VE, "preset" },
+
+    { "2pass", "Enable Two-Pass CBR. (Forces CBR).",
+        OFFSET(twopass), AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 1, VE },
+#define TWOPASS(name, value)  name, NULL, 0, AV_OPT_TYPE_CONST, \
+                           { .i64 = value }, 0, 0, VE, "twopass"
+    { TWOPASS("off", 0) },
+    { TWOPASS("on",  1) },
+#undef TWOPASS
+    { NULL }
+};
+
+static const AVOption options_hevc[] = {
+    { "num_capture_buffers", "Number of buffers in the capture context",
+        OFFSET(num_capture_buffers), AV_OPT_TYPE_INT, {.i64 = 10 }, 1, 32, VE },
+
+    { "profile",  "Set the encoding profile", OFFSET(profile), AV_OPT_TYPE_INT,
+        { .i64 = FF_PROFILE_HEVC_MAIN }, FF_PROFILE_HEVC_MAIN,
+        FF_PROFILE_HEVC_MAIN_10, VE, "profile" },
+#define PROFILE(name, value)  name, NULL, 0, AV_OPT_TYPE_CONST, \
+                              { .i64 = value }, 0, 0, VE, "profile"
+    { PROFILE("main",   FF_PROFILE_HEVC_MAIN) },
+    { PROFILE("main10", FF_PROFILE_HEVC_MAIN_10) },
+#undef PROFILE
+
+    { "tier", "Set the encoding tier", OFFSET(tier), AV_OPT_TYPE_INT,
+        { .i64 = 0 }, 0, 1, VE, "tier"},
+#define TIER(name, value)  name, NULL, 0, AV_OPT_TYPE_CONST, \
+                           { .i64 = value }, 0, 0, VE, "tier"
+    { TIER("main", 0) },
+    { TIER("high", 1) },
+#undef TIER
+
+    { "level", "Profile Level", OFFSET(level), AV_OPT_TYPE_INT,
+        { .i64 = 186 }, 30, 186, VE, "level" },
+#define LEVEL(name, value) name, NULL, 0, AV_OPT_TYPE_CONST, \
+                           { .i64 = value }, 0, 0, VE, "level"
+    { LEVEL("1",    30) },
+    { LEVEL("2",    60) },
+    { LEVEL("2.1",  63) },
+    { LEVEL("3",    90) },
+    { LEVEL("3.1",  93) },
+    { LEVEL("4",   120) },
+    { LEVEL("4.1", 123) },
+    { LEVEL("5",   150) },
+    { LEVEL("5.1", 153) },
+    { LEVEL("5.2", 156) },
+    { LEVEL("6",   180) },
+    { LEVEL("6.1", 183) },
+    { LEVEL("6.2", 186) },
+#undef LEVEL
+
+    { "lossless", "Enable lossless encoding", OFFSET(lossless), AV_OPT_TYPE_INT,
+        { .i64 = 0 }, 0, 1, VE, "lossless"},
+#define LOSSLESS(name, value)  name, NULL, 0, AV_OPT_TYPE_CONST, \
+                           { .i64 = value }, 0, 0, VE, "lossless"
+    { LOSSLESS("off", 0) },
+    { LOSSLESS("on",  1) },
+#undef LOSSLESS
+
+    { "rc",  "Override the preset rate-control", OFFSET(rc),
+        AV_OPT_TYPE_INT,   { .i64 = 1 }, 0, 1, VE, "rc" },
+    { "cbr", "Constant bitrate mode", 0, AV_OPT_TYPE_CONST,
+        { .i64 = 0  },  0, 0, VE, "rc" },
+    { "vbr", "Variable bitrate mode", 0, AV_OPT_TYPE_CONST,
+        { .i64 = 1  },  0, 0, VE, "rc" },
+
+    { "preset",    "Set the encoding preset", OFFSET(preset),
+        AV_OPT_TYPE_INT,   { .i64 = 3 }, 3, 4, VE, "preset" },
+    { "default",   "", 0, AV_OPT_TYPE_CONST, { .i64 = 3 }, 0, 0, VE, "preset" },
+    { "slow",      "", 0, AV_OPT_TYPE_CONST, { .i64 = 4 }, 0, 0, VE, "preset" },
+    { "medium",    "", 0, AV_OPT_TYPE_CONST, { .i64 = 3 }, 0, 0, VE, "preset" },
+    { "fast",      "", 0, AV_OPT_TYPE_CONST, { .i64 = 2 }, 0, 0, VE, "preset" },
+    { "ultrafast", "", 0, AV_OPT_TYPE_CONST, { .i64 = 1 }, 0, 0, VE, "preset" },
+
+    { "2pass", "Enable Two-Pass CBR. (Forces CBR).",
+        OFFSET(twopass), AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 1, VE },
+#define TWOPASS(name, value)  name, NULL, 0, AV_OPT_TYPE_CONST, \
+                           { .i64 = value }, 0, 0, VE, "twopass"
+    { TWOPASS("off", 0) },
+    { TWOPASS("on",  1) },
+#undef TWOPASS
+    { NULL }
+};
+
+#define NVV4L2_ENC_CLASS(NAME)                         \
+    static const AVClass nvv4l2_##NAME##_enc_class = { \
+        .class_name = "nvv4l2_" #NAME "_enc",          \
+        .item_name  = av_default_item_name,            \
+        .option     = options_##NAME,                  \
+        .version    = LIBAVUTIL_VERSION_INT,           \
+    };
+
+#define NVV4L2_ENC(NAME, ID)                                                          \
+    NVV4L2_ENC_CLASS(NAME)                                                            \
+    AVCodec ff_##NAME##_nvv4l2_encoder = {                                            \
+        .name           = #NAME "_nvv4l2" ,                                           \
+        .long_name      = NULL_IF_CONFIG_SMALL(#NAME " NVV4L2 HW encoder for Tegra"), \
+        .type           = AVMEDIA_TYPE_VIDEO,                                         \
+        .id             = ID,                                                         \
+        .priv_data_size = sizeof(nvv4l2EncodeContext),                                \
+        .init           = nvv4l2enc_init,                                             \
+        .close          = nvv4l2enc_close,                                            \
+        .encode2        = nvv4l2enc_encode,                                           \
+        .priv_class     = &nvv4l2_##NAME##_enc_class,                                 \
+        .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_HARDWARE,                 \
+        .defaults       = defaults,                                                   \
+        .wrapper_name   = "nvv4l2",                                                   \
+        .pix_fmts       = (const enum AVPixelFormat[]) { AV_PIX_FMT_YUV420P,          \
+                                                         AV_PIX_FMT_YUV444P,          \
+                                                         AV_PIX_FMT_NV12,             \
+                                                         AV_PIX_FMT_P010,             \
+                                                         AV_PIX_FMT_NONE },           \
+    };
+
+NVV4L2_ENC(h264, AV_CODEC_ID_H264);
+NVV4L2_ENC(hevc, AV_CODEC_ID_HEVC);
diff -Naur ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2_ext_utils.h ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2_ext_utils.h
--- ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2_ext_utils.h	1970-01-01 01:00:00.000000000 +0100
+++ ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2_ext_utils.h	2022-04-20 03:49:41.823220489 +0200
@@ -0,0 +1,2463 @@
+/*
+ * Copyright (c) 2016-2022, NVIDIA CORPORATION.  All rights reserved.
+ *
+ *  Redistribution and use in source and binary forms, with or without
+ *  modification, are permitted provided that the following conditions
+ *  are met:
+ *  1. Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *  2. Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *  3. The names of its contributors may not be used to endorse or promote
+ *     products derived from this software without specific prior written
+ *     permission.
+ *
+ *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+ *  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+ *  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+ *  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ *  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* This file contains amendments to the V4L2 headers made after the
+ * supported kernel version and NVIDIA extensions.
+ */
+
+#ifndef __NVV4L2_EXT_UTILS_H__
+#define __NVV4L2_EXT_UTILS_H__
+
+#include <errno.h>
+
+/**
+ * @file
+ * <b>NVIDIA V4L2 API Extensions</b>
+ *
+ * @b Description: This file declares NVIDIA V4L2 extensions,
+ * controls and structures.
+ */
+
+/**
+ *
+ * @defgroup ee_extensions_group V4L2 NV Extensions API
+ *
+ * This file declares NVIDIA V4L2 extensions, controls, and structures.
+ *
+ */
+/**
+ * Defines V4L2 pixel format for DIVX.
+ */
+#define V4L2_PIX_FMT_DIVX4     v4l2_fourcc('D', 'V', 'X', '4')
+
+#define V4L2_PIX_FMT_DIVX5     v4l2_fourcc('D', 'V', 'X', '5')
+/**
+ * Defines V4L2 pixel format for H.265.
+ */
+#define V4L2_PIX_FMT_H265     v4l2_fourcc('H', '2', '6', '5')
+
+/**
+ * Defines the V4L2 pixel format for VP9.
+ */
+#define V4L2_PIX_FMT_VP9      v4l2_fourcc('V', 'P', '9', '0')
+
+/**
+ * Defines the V4L2 pixel format for representing single plane 10-bit Y/CbCr 4:2:0 decoder data.
+ */
+#define V4L2_PIX_FMT_P010    v4l2_fourcc('P', '0', '1', '0') /* Y/CbCr 4:2:0, 10 bits per channel */
+
+/**
+ * Defines the V4L2 pixel format for representing semi-planar 10-bit Y/CbCr 4:2:0 decoder data.
+ */
+#define V4L2_PIX_FMT_P010M   v4l2_fourcc('P', 'M', '1', '0') /* Y/CbCr 4:2:0, 10 bits per channel */
+
+/**
+ * Defines the V4L2 pixel format for representing single plane 12-bit Y/CbCr 4:2:0 decoder data.
+ */
+#define V4L2_PIX_FMT_P012    v4l2_fourcc('P', '0', '1', '2') /* Y/CbCr 4:2:0, 12 bits per channel */
+
+/**
+ * Defines the V4L2 pixel format for representing semi-planar 12-bit Y/CbCr 4:2:0 decoder data.
+ */
+#define V4L2_PIX_FMT_P012M   v4l2_fourcc('P', 'M', '1', '2') /* Y/CbCr 4:2:0, 12 bits per channel */
+
+/**
+ * Defines the V4L2 pixel format for representing semi-planar 8-bit Y/CbCr 4:4:4 decoder data.
+ */
+#define V4L2_PIX_FMT_NV24M   v4l2_fourcc('N', 'M', '2', '4') /* Y/CbCr 4:4:4, 8 bits per channel */
+
+/**
+ * Defines the V4L2 pixel format for representing semi-planar 10-bit Y/CbCr 4:4:4 decoder data.
+ */
+#define V4L2_PIX_FMT_NV24_10LE   v4l2_fourcc('N', 'V', '1', '0') /* Y/CbCr 4:4:4, 10 bits per channel */
+
+
+/** @cond UNUSED */
+/* >> The declarations from here to the next endcond statement are not
+ * >> currently implemented. DO NOT USE. */
+
+#define V4L2_PIX_FMT_YUV422RM v4l2_fourcc('4', '2', 'R', 'M')
+
+
+#define V4L2_PIX_FMT_H264_SLICE v4l2_fourcc('S', '2', '6', '4') /** H264 parsed slices. */
+#define V4L2_PIX_FMT_VP8_FRAME v4l2_fourcc('V', 'P', '8', 'F') /** VP8 parsed frames. */
+
+#define V4L2_CTRL_FLAG_CAN_STORE    0x0200
+
+/** @endcond */
+
+/**
+ * Defines the V4L2 event type for decoder resolution event change.
+ */
+#define V4L2_EVENT_RESOLUTION_CHANGE        5
+
+/** @cond UNUSED */
+/* >> The declarations from here to the next endcond statement are not
+ * >> currently implemented. DO NOT USE. */
+
+/*---------------Below are changes from the v4l2-controls.h----------------------*/
+
+#define V4L2_CID_MPEG_VIDEO_H264_SPS        (V4L2_CID_MPEG_BASE+383)
+#define V4L2_CID_MPEG_VIDEO_H264_PPS        (V4L2_CID_MPEG_BASE+384)
+#define V4L2_CID_MPEG_VIDEO_H264_SCALING_MATRIX (V4L2_CID_MPEG_BASE+385)
+#define V4L2_CID_MPEG_VIDEO_H264_SLICE_PARAM    (V4L2_CID_MPEG_BASE+386)
+#define V4L2_CID_MPEG_VIDEO_H264_DECODE_PARAM   (V4L2_CID_MPEG_BASE+387)
+
+#define V4L2_CID_MPEG_VIDEO_VP8_FRAME_HDR       (V4L2_CID_MPEG_BASE+512)
+
+/** @endcond */
+
+/**
+ * Defines the control ID to set the H.265 encoder profile.
+ *
+ * A v4l2_mpeg_video_h265_profile must be passed.
+ */
+#define V4L2_CID_MPEG_VIDEO_H265_PROFILE        (V4L2_CID_MPEG_BASE+513)
+
+/**
+ * Defines the possible profiles for H.265 encoder.
+ */
+enum v4l2_mpeg_video_h265_profile {
+    /** H.265 Main profile. */
+    V4L2_MPEG_VIDEO_H265_PROFILE_MAIN = 0,
+    /** H.265 Main10 profile. */
+    V4L2_MPEG_VIDEO_H265_PROFILE_MAIN10 = 1,
+    /** H.265 MainStillPicture profile. */
+    V4L2_MPEG_VIDEO_H265_PROFILE_MAINSTILLPICTURE = 2,
+};
+
+/**
+ * Defines the control ID to set the encoder IDR frame interval.
+ * Must be used with \c VIDIOC_S_EXT_CTRLS IOCTL.
+ */
+#define V4L2_CID_MPEG_VIDEO_IDR_INTERVAL        (V4L2_CID_MPEG_BASE+514)
+
+/** @cond UNUSED */
+/* >> The declarations from here to the next endcond statement are not
+ * >> currently implemented. DO NOT USE. */
+
+/* Complex controls */
+
+#define V4L2_H264_SPS_CONSTRAINT_SET0_FLAG          0x01
+#define V4L2_H264_SPS_CONSTRAINT_SET1_FLAG          0x02
+#define V4L2_H264_SPS_CONSTRAINT_SET2_FLAG          0x04
+#define V4L2_H264_SPS_CONSTRAINT_SET3_FLAG          0x08
+#define V4L2_H264_SPS_CONSTRAINT_SET4_FLAG          0x10
+#define V4L2_H264_SPS_CONSTRAINT_SET5_FLAG          0x20
+
+#define V4L2_H264_SPS_FLAG_SEPARATE_COLOUR_PLANE        0x01
+#define V4L2_H264_SPS_FLAG_QPPRIME_Y_ZERO_TRANSFORM_BYPASS  0x02
+#define V4L2_H264_SPS_FLAG_DELTA_PIC_ORDER_ALWAYS_ZERO      0x04
+#define V4L2_H264_SPS_FLAG_GAPS_IN_FRAME_NUM_VALUE_ALLOWED  0x08
+#define V4L2_H264_SPS_FLAG_FRAME_MBS_ONLY           0x10
+#define V4L2_H264_SPS_FLAG_MB_ADAPTIVE_FRAME_FIELD      0x20
+#define V4L2_H264_SPS_FLAG_DIRECT_8X8_INFERENCE         0x40
+struct v4l2_ctrl_h264_sps {
+    __u8 profile_idc;
+    __u8 constraint_set_flags;
+    __u8 level_idc;
+    __u8 seq_parameter_set_id;
+    __u8 chroma_format_idc;
+    __u8 bit_depth_luma_minus8;
+    __u8 bit_depth_chroma_minus8;
+    __u8 log2_max_frame_num_minus4;
+    __u8 pic_order_cnt_type;
+    __u8 log2_max_pic_order_cnt_lsb_minus4;
+    __s32 offset_for_non_ref_pic;
+    __s32 offset_for_top_to_bottom_field;
+    __u8 num_ref_frames_in_pic_order_cnt_cycle;
+    __s32 offset_for_ref_frame[255];
+    __u8 max_num_ref_frames;
+    __u16 pic_width_in_mbs_minus1;
+    __u16 pic_height_in_map_units_minus1;
+    __u8 flags;
+};
+
+#define V4L2_H264_PPS_FLAG_ENTROPY_CODING_MODE              0x0001
+#define V4L2_H264_PPS_FLAG_BOTTOM_FIELD_PIC_ORDER_IN_FRAME_PRESENT  0x0002
+#define V4L2_H264_PPS_FLAG_WEIGHTED_PRED                0x0004
+#define V4L2_H264_PPS_FLAG_DEBLOCKING_FILTER_CONTROL_PRESENT        0x0008
+#define V4L2_H264_PPS_FLAG_CONSTRAINED_INTRA_PRED           0x0010
+#define V4L2_H264_PPS_FLAG_REDUNDANT_PIC_CNT_PRESENT            0x0020
+#define V4L2_H264_PPS_FLAG_TRANSFORM_8X8_MODE               0x0040
+#define V4L2_H264_PPS_FLAG_PIC_SCALING_MATRIX_PRESENT           0x0080
+struct v4l2_ctrl_h264_pps {
+    __u8 pic_parameter_set_id;
+    __u8 seq_parameter_set_id;
+    __u8 num_slice_groups_minus1;
+    __u8 num_ref_idx_l0_default_active_minus1;
+    __u8 num_ref_idx_l1_default_active_minus1;
+    __u8 weighted_bipred_idc;
+    __s8 pic_init_qp_minus26;
+    __s8 pic_init_qs_minus26;
+    __s8 chroma_qp_index_offset;
+    __s8 second_chroma_qp_index_offset;
+    __u8 flags;
+};
+
+struct v4l2_ctrl_h264_scaling_matrix {
+    __u8 scaling_list_4x4[6][16];
+    __u8 scaling_list_8x8[6][64];
+};
+
+struct v4l2_h264_weight_factors {
+    __s8 luma_weight[32];
+    __s8 luma_offset[32];
+    __s8 chroma_weight[32][2];
+    __s8 chroma_offset[32][2];
+};
+
+struct v4l2_h264_pred_weight_table {
+    __u8 luma_log2_weight_denom;
+    __u8 chroma_log2_weight_denom;
+    struct v4l2_h264_weight_factors weight_factors[2];
+};
+
+#define V4L2_SLICE_FLAG_FIELD_PIC       0x01
+#define V4L2_SLICE_FLAG_BOTTOM_FIELD        0x02
+#define V4L2_SLICE_FLAG_DIRECT_SPATIAL_MV_PRED  0x04
+#define V4L2_SLICE_FLAG_SP_FOR_SWITCH       0x08
+struct v4l2_ctrl_h264_slice_param {
+    /** Holds the size in bytes, including the header. */
+    __u32 size;
+    /** Holds the offset in bits to slice_data() from the beginning of this slice. */
+    __u32 header_bit_size;
+
+    __u16 first_mb_in_slice;
+    __u8 slice_type;
+    __u8 pic_parameter_set_id;
+    __u8 colour_plane_id;
+    __u16 frame_num;
+    __u16 idr_pic_id;
+    __u16 pic_order_cnt_lsb;
+    __s32 delta_pic_order_cnt_bottom;
+    __s32 delta_pic_order_cnt0;
+    __s32 delta_pic_order_cnt1;
+    __u8 redundant_pic_cnt;
+
+    struct v4l2_h264_pred_weight_table pred_weight_table;
+    /* Size in bits of dec_ref_pic_marking() syntax element. */
+    __u32 dec_ref_pic_marking_bit_size;
+    /* Size in bits of pic order count syntax. */
+    __u32 pic_order_cnt_bit_size;
+
+    __u8 cabac_init_idc;
+    __s8 slice_qp_delta;
+    __s8 slice_qs_delta;
+    __u8 disable_deblocking_filter_idc;
+    __s8 slice_alpha_c0_offset_div2;
+    __s8 slice_beta_offset_div2;
+    __u32 slice_group_change_cycle;
+
+    __u8 num_ref_idx_l0_active_minus1;
+    __u8 num_ref_idx_l1_active_minus1;
+    /*  Entries on each list are indices
+     *  into v4l2_ctrl_h264_decode_param.dpb[]. */
+    __u8 ref_pic_list0[32];
+    __u8 ref_pic_list1[32];
+
+    __u8 flags;
+};
+
+/** Defines whether the v4l2_h264_dpb_entry structure is used.
+If not set, this entry is unused for reference. */
+#define V4L2_H264_DPB_ENTRY_FLAG_ACTIVE     0x01
+#define V4L2_H264_DPB_ENTRY_FLAG_LONG_TERM  0x02
+struct v4l2_h264_dpb_entry {
+    __u32 buf_index; /**< v4l2_buffer index. */
+    __u16 frame_num;
+    __u16 pic_num;
+    /** @note `v4l2_buffer.field` specifies this field. */
+    __s32 top_field_order_cnt;
+    __s32 bottom_field_order_cnt;
+    __u8 flags; /* V4L2_H264_DPB_ENTRY_FLAG_* */
+};
+
+struct v4l2_ctrl_h264_decode_param {
+    __u32 num_slices;
+    __u8 idr_pic_flag;
+    __u8 nal_ref_idc;
+    __s32 top_field_order_cnt;
+    __s32 bottom_field_order_cnt;
+    __u8 ref_pic_list_p0[32];
+    __u8 ref_pic_list_b0[32];
+    __u8 ref_pic_list_b1[32];
+    struct v4l2_h264_dpb_entry dpb[16];
+};
+
+#define V4L2_VP8_SEGMNT_HDR_FLAG_ENABLED              0x01
+#define V4L2_VP8_SEGMNT_HDR_FLAG_UPDATE_MAP           0x02
+#define V4L2_VP8_SEGMNT_HDR_FLAG_UPDATE_FEATURE_DATA  0x04
+struct v4l2_vp8_sgmnt_hdr {
+    __u8 segment_feature_mode;
+
+    __s8 quant_update[4];
+    __s8 lf_update[4];
+    __u8 segment_probs[3];
+
+    __u8 flags;
+};
+
+#define V4L2_VP8_LF_HDR_ADJ_ENABLE  0x01
+#define V4L2_VP8_LF_HDR_DELTA_UPDATE    0x02
+struct v4l2_vp8_loopfilter_hdr {
+    __u8 type;
+    __u8 level;
+    __u8 sharpness_level;
+    __s8 ref_frm_delta_magnitude[4];
+    __s8 mb_mode_delta_magnitude[4];
+
+    __u8 flags;
+};
+
+struct v4l2_vp8_quantization_hdr {
+    __u8 y_ac_qi;
+    __s8 y_dc_delta;
+    __s8 y2_dc_delta;
+    __s8 y2_ac_delta;
+    __s8 uv_dc_delta;
+    __s8 uv_ac_delta;
+    __u16 dequant_factors[4][3][2];
+};
+
+struct v4l2_vp8_entropy_hdr {
+    __u8 coeff_probs[4][8][3][11];
+    __u8 y_mode_probs[4];
+    __u8 uv_mode_probs[3];
+    __u8 mv_probs[2][19];
+};
+
+#define V4L2_VP8_FRAME_HDR_FLAG_EXPERIMENTAL        0x01
+#define V4L2_VP8_FRAME_HDR_FLAG_SHOW_FRAME      0x02
+#define V4L2_VP8_FRAME_HDR_FLAG_MB_NO_SKIP_COEFF    0x04
+struct v4l2_ctrl_vp8_frame_hdr {
+    /** 0: keyframe, 1: not a keyframe. */
+    __u8 key_frame;
+    __u8 version;
+
+    /** Populated also if not a key frame. */
+    __u16 width;
+    __u8 horizontal_scale;
+    __u16 height;
+    __u8 vertical_scale;
+
+    struct v4l2_vp8_sgmnt_hdr sgmnt_hdr;
+    struct v4l2_vp8_loopfilter_hdr lf_hdr;
+    struct v4l2_vp8_quantization_hdr quant_hdr;
+    struct v4l2_vp8_entropy_hdr entropy_hdr;
+
+    __u8 sign_bias_golden;
+    __u8 sign_bias_alternate;
+
+    __u8 prob_skip_false;
+    __u8 prob_intra;
+    __u8 prob_last;
+    __u8 prob_gf;
+
+    __u32 first_part_size;
+    /**
+     * Holds the offset in bits of the MB data in the first partition,
+     * i.e. bit offset starting from first_part_offset.
+     */
+    __u32 first_part_offset;
+    __u32 macroblock_bit_offset;
+
+    __u8 num_dct_parts;
+    __u32 dct_part_sizes[8];
+
+    __u8 bool_dec_range;
+    __u8 bool_dec_value;
+    __u8 bool_dec_count;
+
+    /** Holds the v4l2_buffer index of the last reference frame. */
+    __u32 last_frame;
+     /** Holds the v4l2_buffer index of the golden reference frame. */
+   __u32 golden_frame;
+    /** Holds the v4l2_buffer index of the alt reference frame. */
+    __u32 alt_frame;
+
+    __u8 flags;
+};
+
+/** @endcond */
+
+/*---------------Add below NVIDIA specific extensions ----------------------*/
+
+/**
+ * @defgroup V4L2Dec V4L2 Video Decoder
+ *
+ * @brief NVIDIA V4L2 Video Decoder Description and Extensions
+ *
+ * The video decoder device node is
+ *
+ *     /dev/nvhost-nvdec
+ *
+ * ### Supported Pixel Formats
+ * OUTPUT PLANE       | CAPTURE PLANE
+ * :----------------: | :----------------:
+ * V4L2_PIX_FMT_H264  | V4L2_PIX_FMT_NV12M
+ * V4L2_PIX_FMT_H265  | V4L2_PIX_FMT_NV12M
+ *
+ * ### Supported Memory Types
+ * MEMORY               | OUTPUT PLANE | CAPTURE PLANE
+ * :------------------: | :----------: | :-----------:
+ * V4L2_MEMORY_MMAP     | Y            | Y
+ * V4L2_MEMORY_DMABUF   | N            | Y
+ * V4L2_MEMORY_USERPTR  | Y            | N
+ *
+ * ### Supported Controls
+ * - #V4L2_CID_MPEG_VIDEO_DISABLE_COMPLETE_FRAME_INPUT
+ * - #V4L2_CID_MPEG_VIDEO_DISABLE_DPB
+ * - #V4L2_CID_MPEG_VIDEO_ERROR_REPORTING
+ * - #V4L2_CID_MPEG_VIDEO_SKIP_FRAMES
+ * - V4L2_CID_MIN_BUFFERS_FOR_CAPTURE (Get the minimum buffers to be allocated on capture plane.
+ * Read only. Valid after #V4L2_EVENT_RESOLUTION_CHANGE)
+ * - #V4L2_CID_MPEG_VIDEODEC_INPUT_METADATA
+ * - #V4L2_CID_MPEG_VIDEODEC_METADATA
+ * - #V4L2_CID_MPEG_VIDEO_BUF_API_TYPE
+ * - #V4L2_CID_MPEG_VIDEO_CUDA_MEM_TYPE
+ * - #V4L2_CID_MPEG_VIDEO_CUDA_GPU_ID
+ * - #V4L2_CID_MPEG_VIDEODEC_DROP_FRAME_INTERVAL
+ *
+ * ### Supported Events
+ * Event                         | Purpose
+ * ----------------------------- | :----------------------------:
+ * #V4L2_EVENT_RESOLUTION_CHANGE | Resolution of the stream has changed.
+ *
+ * ### Handling Resolution Change Events
+ * When the decoder generates a \c V4L2_EVENT_RESOLUTION_CHANGE event, the
+ * application calls \c STREAMOFF on the capture plane to tell the decoder to
+ * deallocate the current buffers by calling REQBUF with count zero, get
+ * the new capture plane format, and then proceed with setting up the buffers
+ * for the capture plane.
+ *
+ * In case of decoder, the buffer format might differ from the display resolution.
+ * The application must use \c VIDIOC_G_CROP to get the display resolution.
+ *
+ * ### EOS Handling
+ * The following sequence must be followed for sending EOS and recieving EOS
+ * from the decoder.
+ * -# Send EOS to decoder by queueing on the output plane a buffer with
+ * bytesused = 0 for the 0th plane (`v4l2_buffer.m.planes[0].bytesused = 0`).
+ * -# Dequeues buffers on the output plane until it gets a buffer with bytesused = 0
+ * for the 0th plane (`v4l2_buffer.m.planes[0].bytesused == 0`)
+ * -# Dequeues buffers on the capture plane until it gets a buffer with bytesused = 0
+ * for the 0th plane.
+ *
+ * ### Decoder Input Frame Metadata
+ * Decoder supports reporting stream header parsing error info as input frame metadata.
+ * See \c V4L2_CID_MPEG_VIDEO_ERROR_REPORTING, \c V4L2_CID_MPEG_VIDEODEC_INPUT_METADATA
+ * and \c v4l2_ctrl_video_metadata for more information.
+ *
+ * ### Decoder Output Frame Metadata
+ * Decoder supports reporting frame related metadata, including error reports and
+ * DPB info. See \c V4L2_CID_MPEG_VIDEO_ERROR_REPORTING, \c V4L2_CID_MPEG_VIDEODEC_METADATA
+ * and \c v4l2_ctrl_video_metadata for more information.
+ *
+ * @note Currently, V4L2 plugins do not support odd resolution.
+ * @{
+ * @ingroup ee_extensions_group
+ */
+
+/**
+ * Defines the Control ID to indicate to the decoder that the input
+ * buffers do not contain complete buffers.
+ *
+ * @note This control must be set in case of frames containing multiple slices
+ * when the input buffers do not contain all the slices of the frame.
+ *
+ * A boolean value must be supplied with this control.
+ *
+ */
+#define V4L2_CID_MPEG_VIDEO_DISABLE_COMPLETE_FRAME_INPUT (V4L2_CID_MPEG_BASE+515)
+
+/**
+ * Defines the Control ID to disable decoder DPB management.
+ *
+ * @note This only works for streams having a single reference frame.
+ *
+ * A boolean value must be supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEO_DISABLE_DPB (V4L2_CID_MPEG_BASE+516)
+
+/**
+ * Defines the Control ID to enable decoder error and metadata reporting.
+ *
+ * A boolean value must be supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEO_ERROR_REPORTING (V4L2_CID_MPEG_BASE+517)
+
+/**
+ * Defines the Control ID to set the skip frames property of the decoder.
+ *
+ * Decoder must be configured to skip certain types of frames. One
+ * \c v4l2_skip_frames_type must be passed.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ * This control ID is supported only for H264.
+ */
+#define V4L2_CID_MPEG_VIDEO_SKIP_FRAMES (V4L2_CID_MPEG_BASE+518)
+
+/**
+ * Defines the Control ID to get the decoder output metadata.
+ *
+ * @note Metadata reporting must be enabled using
+ * #V4L2_CID_MPEG_VIDEO_ERROR_REPORTING IOCTL for this.
+ *
+ * A pointer to a valid \c v4l2_ctrl_video_metadata structure must be supplied
+ * with this control.
+ *
+ * @attention This control must be read after dequeueing a buffer successfully from
+ * the capture plane. The values in the structure are valid until the buffer is queued
+ * again.
+ */
+#define V4L2_CID_MPEG_VIDEODEC_METADATA (V4L2_CID_MPEG_BASE+519)
+
+/**
+ * Defines the Control ID to get the decoder input header error metadata.
+ *
+ * @note Metadata reporting must be enabled using
+ * #V4L2_CID_MPEG_VIDEO_ERROR_REPORTING IOCTL for this.
+ *
+ * A pointer to a valid \c v4l2_ctrl_video_metadata structure must be supplied
+ * with this control.
+ *
+ * @attention This control must be read after dequeueing a buffer successfully from
+ * the output plane. The values in the structure are valid until the buffer is queued
+ * again.
+ */
+#define V4L2_CID_MPEG_VIDEODEC_INPUT_METADATA (V4L2_CID_MPEG_BASE+520)
+
+/**
+ * Defines the Control ID to check if display data is present.
+ *
+ * This control returns true if HDR metadata is present in the stream.
+ *
+ */
+#define V4L2_CID_VIDEODEC_DISPLAYDATA_PRESENT (V4L2_CID_MPEG_BASE+521)
+
+/**
+ * Defines the Control ID to get display data if V4L2_CID_VIDEODEC_DISPLAYDATA_PRESENT returns true.
+ *
+ * This control returns display data such as display_primaries, white_point and
+ * display_parameter_luminance required for display module.
+ *
+ */
+#define V4L2_CID_VIDEODEC_HDR_MASTERING_DISPLAY_DATA (V4L2_CID_MPEG_BASE+522)
+
+/**
+ * Defines the Control ID to get Sample Aspect Ratio width for decoding.
+ *
+ * This control returns unsigned integer of Sample Aspect Ratio width.
+ *
+ * @attention This control must be set after receiving V4L2_EVENT_RESOLUTION_CHANGE.
+ *
+ */
+#define V4L2_CID_MPEG_VIDEODEC_SAR_WIDTH (V4L2_CID_MPEG_BASE+569)
+
+/**
+ * Defines the Control ID to get Sample Aspect Ratio height for decoding.
+ *
+ * This control returns unsigned integer of Sample Aspect Ratio height.
+ *
+ * @attention This control must be set after receiving V4L2_EVENT_RESOLUTION_CHANGE.
+ *
+ */
+#define V4L2_CID_MPEG_VIDEODEC_SAR_HEIGHT (V4L2_CID_MPEG_BASE+570)
+
+/** @} */
+
+/**
+ * @defgroup V4L2Conv V4L2 Video Converter
+ *
+ * @brief NVIDIA V4L2 Video Converter Description and Extensions
+ *
+ * Use the video converter for color space conversion, scaling, and
+ * conversion between hardware buffer memory (\c V4L2_MEMORY_MMAP/\c
+ * V4L2_MEMORY_DMABUF), software buffer memory (\c V4L2_MEMORY_USERPTR), and
+ * other operations such as cropping, flipping/rotating, and
+ * temporal noise reduction (TNR).
+ * The video converter device node is \c "/dev/nvhost-vic".
+ *
+ * ### Supported Pixelformats
+ *  PIXEL FORMAT           | PIXEL FORMAT
+ * :---------------------: | :--------------:
+ * V4L2_PIX_FMT_YUV444M    | V4L2_PIX_FMT_YVU422M
+ * V4L2_PIX_FMT_YUV420M    | V4L2_PIX_FMT_YVU420M
+ * V4L2_PIX_FMT_NV12M      | V4L2_PIX_FMT_GREY
+ * V4L2_PIX_FMT_YUYV       | V4L2_PIX_FMT_YVYU
+ * V4L2_PIX_FMT_UYVY       | V4L2_PIX_FMT_VYUY
+ * V4L2_PIX_FMT_ABGR32     | V4L2_PIX_FMT_XBGR32
+ *
+ * ### Supported Pixel Formats for TNR
+ *  PIXEL FORMAT           | PIXEL FORMAT
+ * :---------------------: | :--------------:
+ * V4L2_PIX_FMT_YUV420M    | V4L2_PIX_FMT_NV12M
+ * V4L2_PIX_FMT_UYVY       | V4L2_PIX_FMT_YUYV
+ *
+ * ### Supported Memory Types
+ * MEMORY               | OUTPUT PLANE | CAPTURE PLANE
+ * :------------------: | :----------: | :-----------:
+ * V4L2_MEMORY_MMAP     | Y            | Y
+ * V4L2_MEMORY_DMABUF   | Y            | Y
+ * V4L2_MEMORY_USERPTR  | Y            | Y
+ *
+ * ### Supported Controls
+ * - #V4L2_CID_VIDEO_CONVERT_OUTPUT_PLANE_LAYOUT
+ * - #V4L2_CID_VIDEO_CONVERT_CAPTURE_PLANE_LAYOUT
+ * - #V4L2_CID_VIDEO_CONVERT_FLIP_METHOD
+ * - #V4L2_CID_VIDEO_CONVERT_INTERPOLATION_METHOD
+ * - #V4L2_CID_VIDEO_CONVERT_TNR_ALGORITHM
+ * - #V4L2_CID_VIDEO_CONVERT_YUV_RESCALE_METHOD
+ *
+ * ### Cropping
+ * Video converter supports cropping using \c VIDIOC_S_SELECTION IOCTL with type
+ * \c V4L2_BUF_TYPE_VIDEO_CAPTURE and target \c V4L2_SEL_TGT_CROP. This must
+ * be set before requesting buffers on either plane.
+ *
+ * ### EOS Handling
+ * The following sequence must be followed for sending EOS and recieving EOS
+ * from the converter.
+ * -# Send EOS to converter by queueing on the output plane a buffer with
+ * bytesused = 0 for the 0th plane (`v4l2_buffer.m.planes[0].bytesused = 0`).
+ * -# Dequeues buffers on the capture plane until it gets a buffer with bytesused = 0
+ * for the 0th plane.
+ *
+ * @note Currently, V4L2 plugins do not support odd resolution.
+ * @{
+ * @ingroup ee_extensions_group
+ */
+
+/**
+ * Defines the Control ID to set converter output plane buffer layout.
+ *
+ * A value of type \c v4l2_nv_buffer_layout must be supplied with this control.
+ *
+ * @attention This control must be set before requesting buffers on the output plane.
+ */
+#define V4L2_CID_VIDEO_CONVERT_OUTPUT_PLANE_LAYOUT   (V4L2_CID_MPEG_BASE+523)
+
+/**
+ * Defines the Control ID to set converter capture plane buffer layout.
+ *
+ * A value of type \c v4l2_nv_buffer_layout must be supplied with this control.
+ *
+ * @attention This control must be set before requesting buffers on the capture plane.
+ */
+#define V4L2_CID_VIDEO_CONVERT_CAPTURE_PLANE_LAYOUT  (V4L2_CID_MPEG_BASE+524)
+
+/**
+ * Defines the Control ID to set the converter flip/rotation method.
+ *
+ * A value of type \c v4l2_flip_method must be supplied with this control.
+ *
+ * @attention This control must be set before requesting buffers on either plane.
+ */
+#define V4L2_CID_VIDEO_CONVERT_FLIP_METHOD           (V4L2_CID_MPEG_BASE+525)
+
+/**
+ * Defines the Control ID to set the converter interpolation method.
+ *
+ * A value of type \c v4l2_interpolation_method must be supplied with this control.
+ *
+ * @attention This control must be set before requesting buffers on either plane.
+ */
+#define V4L2_CID_VIDEO_CONVERT_INTERPOLATION_METHOD  (V4L2_CID_MPEG_BASE+526)
+
+/**
+ * Defines the Control ID to set the converter Temporal Noise Reduction (TNR) algorithm.
+ *
+ * A value of type \c v4l2_tnr_algorithm must be supplied with this control.
+ *
+ * @attention This control must be set before requesting buffers on either plane.
+ * @attention TNR algorithms are not supported with YUV422 and YUV444 capture
+ *            plane formats.
+ */
+#define V4L2_CID_VIDEO_CONVERT_TNR_ALGORITHM         (V4L2_CID_MPEG_BASE+527)
+/** @} */
+
+/**
+ * @defgroup V4L2Enc V4L2 Video Encoder
+ *
+ * @brief NVIDIA V4L2 Video Encoder Description and Extensions
+ *
+ * The video encoder device node is \c "/dev/nvhost-msenc".
+ *
+ * ### Supported Pixelformats
+ * OUTPUT PLANE            | CAPTURE PLANE
+ * :---------------------: | :--------------
+ * V4L2_PIX_FMT_YUV420M    | V4L2_PIX_FMT_H264
+ *           -             | V4L2_PIX_FMT_H265
+ *
+ * ### Supported Memory Types
+ * MEMORY               | OUTPUT PLANE | CAPTURE PLANE
+ * :------------------: | :----------: | :-----------:
+ * V4L2_MEMORY_MMAP     | Y            | Y
+ * V4L2_MEMORY_DMABUF   | Y            | N
+ * V4L2_MEMORY_USERPTR  | N            | N
+ * \attention For the video encoder, it is necessary that the capture plane
+ *  format be set before the output plane format and only then request buffers on
+ *  any of the planes.
+ *
+ * ### Supported Controls
+ * The following sections describe the supported controls.
+ *
+ * #### Controls From the Open Source V4L2-Controls Header
+ * Control ID                       | Purpose              | Runtime Configurable
+ * -------------------------------- | -------------------- | :------------------:
+ * V4L2_CID_MPEG_VIDEO_BITRATE      | Bitrate              | Y
+ * V4L2_CID_MPEG_VIDEO_H264_PROFILE | H.264 Encode Profile | N
+ * V4L2_CID_MPEG_VIDEO_BITRATE_MODE | Rate Control Mode    | N
+ * V4L2_CID_MPEG_VIDEO_GOP_SIZE     | I-frame Interval     | N
+ * V4L2_CID_MPEG_VIDEO_H264_LEVEL   | Encode Level         | N
+ * V4L2_CID_MPEG_MFC51_VIDEO_FORCE_FRAME_TYPE | Force I-frame on one of queued output plane buffer | Y
+ *
+ * All non-runtime configurable options must be set after setting formats on
+ * both the planes and before requesting buffers on either plane.
+ *
+ * The runtime configurable parameters can be called anytime after setting
+ * formats on both the planes.
+ *
+ * #### NVIDIA-Specific Controls
+ * - #V4L2_CID_MPEG_VIDEO_H265_PROFILE
+ * - #V4L2_CID_MPEG_VIDEO_IDR_INTERVAL
+ * - #V4L2_CID_MPEG_VIDEOENC_TEMPORAL_TRADEOFF_LEVEL
+ * - #V4L2_CID_MPEG_VIDEOENC_SLICE_LENGTH_PARAM
+ * - #V4L2_CID_MPEG_VIDEOENC_ROI_PARAMS
+ * - #V4L2_CID_MPEG_VIDEOENC_VIRTUALBUFFER_SIZE
+ * - #V4L2_CID_MPEG_VIDEOENC_NUM_REFERENCE_FRAMES
+ * - #V4L2_CID_MPEG_VIDEOENC_SLICE_INTRAREFRESH_PARAM
+ * - #V4L2_CID_MPEG_VIDEOENC_NUM_BFRAMES
+ * - #V4L2_CID_MPEG_VIDEOENC_INSERT_SPS_PPS_AT_IDR
+ * - #V4L2_CID_MPEG_VIDEOENC_METADATA
+ * - #V4L2_CID_MPEG_VIDEOENC_METADATA_MV
+ * - #V4L2_CID_MPEG_VIDEOENC_ENABLE_METADATA_MV
+ * - #V4L2_CID_MPEG_VIDEOENC_QP_RANGE
+ * - #V4L2_CID_MPEG_VIDEOENC_HW_PRESET_TYPE_PARAM
+ * - #V4L2_CID_MPEG_VIDEOENC_INPUT_METADATA
+ * - #V4L2_CID_MPEG_VIDEOENC_ENABLE_EXTERNAL_RPS_CONTROL
+ * - #V4L2_CID_MPEG_VIDEOENC_ENABLE_EXTERNAL_RATE_CONTROL
+ * - #V4L2_CID_MPEG_VIDEOENC_ENABLE_ROI_PARAM
+ * - #V4L2_CID_MPEG_VIDEOENC_ENABLE_RECONCRC_PARAM
+ * - #V4L2_CID_MPEG_VIDEOENC_INSERT_VUI
+ * - #V4L2_CID_MPEG_VIDEOENC_INSERT_AUD
+ * - #V4L2_CID_MPEG_VIDEOENC_EXTEDED_COLORFORMAT
+ * - #V4L2_CID_MPEG_VIDEOENC_ENABLE_ALLIFRAME_ENCODE
+ * - #V4L2_CID_MPEG_VIDEOENC_H265_LEVEL
+ * - #V4L2_CID_MPEG_VIDEOENC_ENABLE_SLICE_LEVEL_ENCODE
+ *
+ * #### Setting Framerate
+ * The encoder framerate can be set with \c VIDIOC_S_PARM IOCTL by setting the numerator
+ * and denominator in `v4l2_streamparm.parm.output.timeperframe`.
+ *
+ * ### Supported Encoder Profiles
+ * #### H.264
+ * - V4L2_MPEG_VIDEO_H264_PROFILE_MAIN
+ * - V4L2_MPEG_VIDEO_H264_PROFILE_BASELINE
+ * - V4L2_MPEG_VIDEO_H264_PROFILE_HIGH
+ *
+ * #### H.265
+ * - V4L2_MPEG_VIDEO_H265_PROFILE_MAIN
+ * - V4L2_MPEG_VIDEO_H265_PROFILE_MAIN10
+ *
+ * ### Encoder Output Metadata
+ * The encoder supports reporting frame related metadata, including motion vectors
+ * for that frame. See \c V4L2_CID_MPEG_VIDEOENC_METADATA,
+ * \c V4L2_CID_MPEG_VIDEOENC_METADATA_MV and \c V4L2_CID_MPEG_VIDEOENC_ENABLE_METADATA_MV
+ * for more information.
+ *
+ * ### EOS Handling
+ * The following sequence must be followed for sending EOS and recieving EOS
+ * from the encoder.
+ * -# Send EOS to encoder by queueing on the output plane a buffer with
+ * bytesused = 0 for the 0th plane (`v4l2_buffer.m.planes[0].bytesused = 0`).
+ * -# Dequeues buffers on the capture plane until it gets a buffer with bytesused = 0
+ * for the 0th plane.
+ *
+ * @note Currently, V4L2 plugins do not support odd resolution.
+ * @{
+ * @ingroup ee_extensions_group
+ */
+
+
+/**
+ * Defines the Control ID to configure encoder to drop frames while encoding.
+ *
+ * A value of type \c v4l2_enc_temporal_tradeoff_level_type must be supplied
+ * with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_TEMPORAL_TRADEOFF_LEVEL (V4L2_CID_MPEG_BASE+528)
+
+/**
+ * Defines the Control ID to configure encoder slice length either in terms of MBs or bits.
+ *
+ * A pointer to a valid \c v4l2_enc_slice_length_param structure must be supplied
+ * with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_SLICE_LENGTH_PARAM (V4L2_CID_MPEG_BASE+529)
+
+/**
+ * Defines the Control ID to configure encoder to encode particular region of frame in high
+ * quality.
+ *
+ * A pointer to a valid \c v4l2_enc_frame_ROI_params structure must be supplied
+ * with this control.
+ *
+ * @attention This control must be set after requesting buffers on both the
+ * planes.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_ROI_PARAMS (V4L2_CID_MPEG_BASE+530)
+
+/**
+ * Defines the Control ID to specify virtual buffer size in bits for encoder.
+ *
+ * A pointer to a valid \c v4l2_enc_virtual_buffer_size structure must be
+ * supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_VIRTUALBUFFER_SIZE (V4L2_CID_MPEG_BASE+531)
+
+/**
+ * Defines the Control ID to specify maximum number of reference frames that can be used.
+ *
+ * An integer value must be supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_NUM_REFERENCE_FRAMES (V4L2_CID_MPEG_BASE+532)
+
+/**
+ * Defines the Control ID to specify the encoder slice intra refresh interval.
+ *
+ * A pointer to a valid \c v4l2_enc_slice_intrarefresh_param structure must be
+ * supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_SLICE_INTRAREFRESH_PARAM (V4L2_CID_MPEG_BASE+533)
+
+/**
+ * Defines the Control ID to set number of B frames to be encoded between two P frames.
+ *
+ * This works with H.264 encoder. This also works with H.265 encoder for Jetson Xavier and
+ * Jetson Xavier NX platforms. An integer value must be supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_NUM_BFRAMES (V4L2_CID_MPEG_BASE+534)
+
+/**
+ * Defines the Control ID to enable/disable inserting SPS and PPS explicitly at IDR interval.
+ *
+ * A boolean value must be supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_INSERT_SPS_PPS_AT_IDR (V4L2_CID_MPEG_BASE+535)
+
+/**
+ * Defines the Control ID to get encoder output metadata.
+ *
+ * A pointer to valid #v4l2_ctrl_video_metadata structure must be supplied with
+ * this control.
+ *
+ * @attention This control must be read after dequeueing a buffer successfully from
+ * the capture plane. The values in the structure are valid until the buffer is queued
+ * again.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_METADATA               (V4L2_CID_MPEG_BASE+536)
+
+/**
+ * Defines the Control ID to enable/disable encoder motion vector reporting.
+ *
+ * A boolean value must be supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_ENABLE_METADATA_MV     (V4L2_CID_MPEG_BASE+537)
+
+/**
+ * Defines the Control ID to get encoder output motion vector metadata.
+ *
+ * A pointer to valid \c v4l2_ctrl_videoenc_outputbuf_metadata_MV structure must
+ * be supplied with this control.
+ *
+ * @attention This control must be read after dequeueing a buffer successfully from
+ * the capture plane. The values in the structure are valid until the buffer is queued
+ * again.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_METADATA_MV            (V4L2_CID_MPEG_BASE+538)
+
+/**
+ * Defines the Control ID to set QP range for I/P/B frames.
+ *
+ * A pointer to a valid \c v4l2_ctrl_video_qp_range structure must
+ * be supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_QP_RANGE               (V4L2_CID_MPEG_BASE+539)
+
+/**
+ * Defines the Control ID to set encoder HW Preset type.
+ *
+ * A pointer to valid #v4l2_enc_hw_preset_type_param structure must
+ * be supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_HW_PRESET_TYPE_PARAM   (V4L2_CID_MPEG_BASE+540)
+
+/**
+ * Defines the Control ID to provide input metadata for encoder buffer.
+ *
+ * A pointer to valid #v4l2_ctrl_videoenc_input_metadata structure must be
+ * supplied with this control.
+ *
+ * @attention This control must be called before queueing a buffer on the output
+ * plane. Use the bitwise OR of v4l2_enc_input_metadata_param in the
+ * v4l2_ctrl_videoenc_input_metadata.metadata_flag to provide different input
+ * metadata parameters in one s_ctrl call.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_INPUT_METADATA         (V4L2_CID_MPEG_BASE+541)
+
+/**
+ * Defines the Control ID to configure encoder for external RPS control.
+ *
+ * A pointer to a valid #v4l2_enc_enable_ext_rps_ctr structure must be supplied
+ * with this control.
+ *
+ * @attention This control must be set after requesting buffers on both the
+ * planes. The value for V4L2_CID_MPEG_VIDEOENC_NUM_REFERENCE_FRAMES, if being entered,
+ * must be set after this control.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_ENABLE_EXTERNAL_RPS_CONTROL (V4L2_CID_MPEG_BASE+542)
+
+/**
+ * Defines the Control ID to configure encoder for external rate control.
+ *
+ * A pointer to a valid #v4l2_enc_enable_ext_rate_ctr structure must be supplied
+ * with this control.
+ *
+ * @attention This control must be set after requesting buffers on both the
+ * planes.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_ENABLE_EXTERNAL_RATE_CONTROL (V4L2_CID_MPEG_BASE+543)
+
+/**
+ * Defines the Control ID to configure ROI encoding for a session.
+ *
+ * A pointer to a valid #v4l2_enc_enable_roi_param structure must be supplied
+ * with this control.
+ *
+ * @attention This control must be set after requesting buffers on both the
+ * planes.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_ENABLE_ROI_PARAM (V4L2_CID_MPEG_BASE+544)
+
+/**
+ * Defines the Control ID to configure Reconstructed CRC for a session.
+ *
+ * A pointer to a valid #v4l2_enc_enable_reconcrc_param structure must be supplied
+ * with this control.
+ *
+ * @attention This control must be set after requesting buffers on both the
+ * planes.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_ENABLE_RECONCRC_PARAM  (V4L2_CID_MPEG_BASE+545)
+
+/**
+ * Control ID to enable/disable inserting VUI in SPS.
+ *
+ * A boolean value should be supplied with this control.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_INSERT_VUI (V4L2_CID_MPEG_BASE+546)
+
+/**
+ * Control ID to enable/disable inserting AUD(Access Unit Delimiter).
+ *
+ * A boolean value should be supplied with this control.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_INSERT_AUD (V4L2_CID_MPEG_BASE+547)
+
+/**
+ * Control ID to enable/disable setting extended color format.
+ *
+ * A boolean value should be supplied with this control.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane. Also this control should be
+ * enabled/disabled only after V4L2_CID_MPEG_VIDEOENC_INSERT_VUI is set
+ */
+#define V4L2_CID_MPEG_VIDEOENC_EXTEDED_COLORFORMAT (V4L2_CID_MPEG_BASE+548)
+
+/**
+ * Control ID to select which NVDEC IP to decode.
+ *
+ * @note This functionality is currently being deprecated and no longer
+ * functional.
+ *
+ * A v4l2_decode_instance_type should be supplied with this control.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEO_DECODE_INSTANCE (V4L2_CID_MPEG_BASE+549)
+/**
+ * Control ID to issue a pseudo POLL call on the fd opened in non blocking mode.
+ *
+ * A pointer to a valid #v4l2_ctrl_video_device_poll must be supplied with this control.
+ *
+ * @attention This should only be called when the Decoder or Encoder is opened with
+ * O_NONBLOCK flag.
+ */
+#define V4L2_CID_MPEG_VIDEO_DEVICE_POLL (V4L2_CID_MPEG_BASE+550)
+
+/**
+ * Control ID to set/clear the polling interrupt mode. Useful when a POLL issued from the
+ * application but wants the wait to be interrupted.
+ *
+ * A boolean value must be supplied with this control, True indicates polling interrupt shall be
+ * enabled and it shall stay enabled (i.e calls to POLL will return immediately) until a call to
+ * same control ID is made by passing a boolean 0 value.
+ *
+ * @attention This should only be called when the Decoder or Encoder is opened with
+ * O_NONBLOCK flag.
+ */
+#define V4L2_CID_MPEG_SET_POLL_INTERRUPT (V4L2_CID_MPEG_BASE+551)
+
+/**
+ * Control ID to enable/disable setting rate control two pass CBR.
+ *
+ * A boolean value should be supplied with this control.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_TWO_PASS_CBR (V4L2_CID_MPEG_BASE+552)
+
+/**
+ * Defines the Control ID to set the converter YUV Rescale method.
+ *
+ * A value of type \c v4l2_yuv_rescale_method must be supplied with this control.
+ *
+ * @attention This control must be set before requesting buffers on either plane.
+ */
+#define V4L2_CID_VIDEO_CONVERT_YUV_RESCALE_METHOD (V4L2_CID_MPEG_BASE+553)
+
+/**
+ * Control ID to enable maximum Performance.
+ *
+ * An integer value must be supplied with this control.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEO_MAX_PERFORMANCE (V4L2_CID_MPEG_BASE+554)
+
+/**
+ * Control ID to enable/disable setting for all i-Frame encoding.
+ *
+ * A boolean value should be supplied with this control.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_ENABLE_ALLIFRAME_ENCODE (V4L2_CID_MPEG_BASE+555)
+
+/**
+ * Defines the Control ID to set buf api to be used by decoder/encoder.
+ *
+ * A boolean value should be supplied with this control, default is 0
+ * This has to be called before any other ioctls are used and cannot be changed.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ * This is internal ioctl due to be removed later.
+ */
+#define V4L2_CID_MPEG_VIDEO_BUF_API_TYPE (V4L2_CID_MPEG_BASE+556)
+
+/**
+ * Defines the Control ID to set cuda memory type to be used by decoder/encoder.
+ *
+ * This control can be used by the decoder to set the memory type for surfaces.
+ * A value of \c v4l2_cuda_mem_type needs to be set with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEO_CUDA_MEM_TYPE (V4L2_CID_MPEG_BASE+557)
+
+/**
+ * Defines the Control ID to set GPU ID to be used by decoder/encoder.
+ *
+ * An integer value should be supplied with this control.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEO_CUDA_GPU_ID (V4L2_CID_MPEG_BASE+558)
+
+/**
+ * Defines the Control ID to set drop frames interval for decoder.
+ *
+ * An integer value should be supplied with this control. A value of "x"
+ * indicates every "x"th frame should be given out from the decoder, rest shall
+ * dropped after decoding.
+ *
+ * @attention This control must be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEODEC_DROP_FRAME_INTERVAL (V4L2_CID_MPEG_BASE+559)
+
+/**
+ * Control ID to enable/disable setting for attaching VP8/9 headers.
+ * Only to be used for VP8/9 pixel format not for H264/5.
+ *
+ * A boolean value should be supplied with this control.
+ * If value is false headers will be disabled and true will enable the headers.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+ #define V4L2_CID_MPEG_VIDEOENC_VPX_HEADERS_WITH_FRAME (V4L2_CID_MPEG_BASE+560)
+
+/**
+ * Defines the control ID to set the H.265 encoder level.
+ *
+ * A v4l2_mpeg_video_h265_level must be passed.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_H265_LEVEL (V4L2_CID_MPEG_BASE+561)
+
+/**
+ * Control ID to enable/disable slice level encode output.
+ *
+ * A boolean value should be supplied with this control.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_ENABLE_SLICE_LEVEL_ENCODE (V4L2_CID_MPEG_BASE+562)
+
+/* L4T BSP 32.5.x */
+/**
+ * Defines the Control ID to set Picture Order Count property in frames.
+ *
+ * This works only with H.264 encoder. An integer value must be supplied with this
+ * control.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_POC_TYPE (V4L2_CID_MPEG_BASE+563)
+
+/* L4T BSP 32.6.x */
+/**
+ * Defines the Control ID to set Sample Aspect Ratio width for H265 VUI encoding.
+ *
+ * An integer value must be supplied with this control.
+ * The VUI Sample Aspect Ratio indicator for H265 follows the standard enum defined for
+ * v4l2_mpeg_video_h264_vui_sar_idc.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_H265_VUI_EXT_SAR_WIDTH (V4L2_CID_MPEG_BASE+564)
+
+/**
+ * Defines the Control ID to set Sample Aspect Ratio height for H265 VUI encoding.
+ *
+ * An integer value must be supplied with this control.
+ * The VUI Sample Aspect Ratio indicator for H265 follows the standard enum defined
+ * for v4l2_mpeg_video_h264_vui_sar_idc.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_H265_VUI_EXT_SAR_HEIGHT (V4L2_CID_MPEG_BASE+565)
+
+/**
+ * Defines the Control ID to force INTRA frame.
+ *
+ * This control can be used by encoder to force encoding an intra frame.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_FORCE_INTRA_FRAME (V4L2_CID_MPEG_BASE+566)
+
+/**
+ * Defines the Control ID to force IDR frame.
+ *
+ * This control can be used by encoder to force encoding an idr frame.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_FORCE_IDR_FRAME (V4L2_CID_MPEG_BASE+567)
+
+ /**
+ * Defines the Control ID to set low latency to be used by decoder.
+ *
+ * This control can be used by decoder to set low latency for streams having
+ * I and IPPP frames.
+ *
+ * @attention This control must be set before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEO_CUDA_LOW_LATENCY (V4L2_CID_MPEG_BASE+568)
+
+/* L4T BSP 32.7.x */
+/**
+ * Defines the Control ID to enable lossless H.264/H.265 encoding.
+ *
+ * An boolean value must be supplied with this control. Default is 0.
+ * Lossless encoding is supported only for YUV444 8/10-bit format.
+ * @note This control must be set in case of H.264 YUV444 encoding as
+ * it does not support lossy encoding.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_ENABLE_LOSSLESS (V4L2_CID_MPEG_BASE+569)
+
+/**
+ * Defines the Control ID to set chroma_factor_idc for H.265 encoding.
+ *
+ * An integer value must be supplied with this control. Default is 1, and
+ * 3 for YUV444 8/10-bit format.
+ *
+ * @attention This control should be set after setting formats on both the planes
+ * and before requesting buffers on either plane.
+ */
+#define V4L2_CID_MPEG_VIDEOENC_H265_CHROMA_FACTOR_IDC (V4L2_CID_MPEG_BASE+570)
+/** @} */
+
+/** @addtogroup V4L2Dec */
+/** @{ */
+/**
+ * Enum v4l2_skip_frames_type, possible methods for decoder skip frames. */
+enum v4l2_skip_frames_type {
+    /** Do not skip any frame. */
+    V4L2_SKIP_FRAMES_TYPE_NONE = 0,
+    /** Skip all non-reference frames. */
+    V4L2_SKIP_FRAMES_TYPE_NONREF = 1,
+    /** Skip all frames except IDR */
+    V4L2_SKIP_FRAMES_TYPE_DECODE_IDR_ONLY = 2,
+};
+
+/**
+ * Enum v4l2_cuda_mem_type, possible methods for cuda memory tpye. */
+enum v4l2_cuda_mem_type {
+    /** Memory type device. */
+    V4L2_CUDA_MEM_TYPE_DEVICE = 0,
+    /** Memory type host. */
+    V4L2_CUDA_MEM_TYPE_PINNED = 1,
+    /** Memory type unified. */
+    V4L2_CUDA_MEM_TYPE_UNIFIED = 2,
+};
+
+/**
+ * Enum v4l2_videodec_input_error_type, possible error types for input stream. */
+enum v4l2_videodec_input_error_type {
+    /** no error. */
+    V4L2_DEC_ERROR_NONE = 0x0,
+    /** sps error. */
+    V4L2_DEC_ERROR_SPS = 0x1,
+    /** pps error. */
+    V4L2_DEC_ERROR_PPS = 0x2,
+    /** slice header error. */
+    V4L2_DEC_ERROR_SLICE_HDR = 0x4,
+    /** missing reference frame error. */
+    V4L2_DEC_ERROR_MISSING_REF_FRAME = 0x8,
+    /** VPS error. */
+    V4L2_DEC_ERROR_VPS = 0x10,
+};
+
+/**
+ * Holds the decoder error status metadata for the frame.
+ */
+typedef struct v4l2_ctrl_videodec_statusmetadata_
+{
+    /** Error types:
+     *  bit 0: Fatal
+     *  bit 1: MB level syntax
+     *  bit 2: Missing Slice(s)
+     *  bit 3: PrevFrameLostFlag */
+    __u32  DecodeError;
+    /** Number of macro blocks decoded without error. */
+    __u32  DecodedMBs;
+    /** Number of macro blocks where error was concealed. */
+    __u32  ConcealedMBs;
+    /** POC of the reference frame used for concealment. */
+    __u32  nConcealedFromPOC;
+    /** Time required to decode the frame, in microseconds. */
+    __u32  FrameDecodeTime;
+}v4l2_ctrl_videodec_statusmetadata;
+
+/**
+ * Holds the the frame specific metadata for a reference frame.
+ */
+typedef struct v4l2_ctrl_videodec_refframe_metadata_
+{
+    /** Boolean value indicating if the frame is present in DPB. */
+    __u32 bPresent;
+    /** Boolean value indicating if the frame is an IDR. */
+    __u32 bIdrFrame;
+    /** Boolean value indicating if the frame is a long term reference frame. */
+    __u32 bLTRefFrame;
+    /** Boolean value indicating if it is a predicted frame. */
+    __u32 bPredicted;
+    /** Picture order count of the frame. */
+    __u32 nPictureOrderCnt;
+    /** Frame number. Resets to zero for an IDR frame. */
+    __u32 nFrameNum;
+    /** Long Term Frame Index of the frame. */
+    __u32 nLTRFrameIdx;
+} v4l2_ctrl_videodec_refframe_metadata;
+
+/**
+ * Holds the the frame specific metadata for the current frame.
+ */
+typedef struct v4l2_ctrl_videodec_currentframe_metadata_
+{
+    /** Boolean value indicating if the current frame is a reference frame. */
+    __u32 bRefFrame;
+    /** Boolean value indicating if the current frame is an IDR. */
+    __u32 bIdrFrame;
+    /** Boolean value indicating if the current frame is a long term reference frame. */
+    __u32 bLTRefFrame;
+    /** Picture order count of the current frame. */
+    __u32 nPictureOrderCnt;
+    /** Frame number. Resets to zero for an IDR frame. */
+    __u32 nFrameNum;
+    /** Long Term Frame Index of the current frame. */
+    __u32 nLTRFrameIdx;
+} v4l2_ctrl_videodec_currentframe_metadata;
+
+/**
+ * Holds the decoder DPB info metadata.
+ */
+typedef struct v4l2_ctrl_videodec_dpbinfometadata_
+{
+    /** Metadata for the current decoded frame. */
+    v4l2_ctrl_videodec_currentframe_metadata currentFrame;
+    /** Number of active frames present in the DPB. */
+    __u32 nActiveRefFrames;
+    /** An array of metadatas for the active frames in the DPB. Only
+     *  nActiveRefFrames elements in the array are valid. */
+    v4l2_ctrl_videodec_refframe_metadata RPSList[16];
+} v4l2_ctrl_videodec_dpbinfometadata;
+
+/**
+ * Holds H.264 specific decoder metadata for the frame.
+ */
+typedef struct v4l2_ctrl_h264dec_bufmetadata_
+{
+    /** Holds the number of bits in the frame. */
+    __u32 nFrameNumBits;
+    /** Type of frame:
+     *  0 = B
+     *  1 = P
+     *  2 = I */
+    __u32  FrameType;
+    /** Holds the current DPB information of the decoder. */
+    v4l2_ctrl_videodec_dpbinfometadata dpbInfo;
+}v4l2_ctrl_h264dec_bufmetadata;
+
+/**
+ * Holds H.265 specific decoder metadata for the frame.
+ */
+typedef struct v4l2_ctrl_hevcdec_bufmetadata_
+{
+    /** Holds the number of bits in the frame. */
+    __u32 nPocLsbBits;
+    /** Type of frame:
+     *  0 = B
+     *  1 = P
+     *  2 = I */
+    __u32  FrameType;
+    /** Holds the current DPB information of the decoder. */
+    v4l2_ctrl_videodec_dpbinfometadata dpbInfo;
+}v4l2_ctrl_hevcdec_bufmetadata;
+
+/**
+ * Holds the video decoder input header error metadata for a frame.
+ */
+typedef struct v4l2_ctrl_videodec_inputbuf_metadata_
+{
+    /** Bits represent types of error as defined
+     *  with v4l2_videodec_input_error_type. */
+    __u32 nBitStreamError;
+} v4l2_ctrl_videodec_inputbuf_metadata;
+
+/**
+ * Holds the video decoder output metadata for a frame.
+ */
+typedef struct v4l2_ctrl_videodec_outputbuf_metadata_
+{
+    /** Color primaries. */
+    __u8 ucColorPrimaries;
+    /** Transfer characteristics. */
+    __u8 ucTransferCharacteristics;
+    /** Matrix coefficients. */
+    __u8 ucMatrixCoefficients;
+    /** Boolean value indicating if \c FrameDecStats has valid contents. */
+    __u32 bValidFrameStatus;
+    /** Frame decode statistics. */
+    v4l2_ctrl_videodec_statusmetadata    FrameDecStats;
+    /** Codec specific metadata for the frame. */
+    union {
+        /** H.264 specific metadata. */
+        v4l2_ctrl_h264dec_bufmetadata H264DecParams;
+        /** H.265 specific metadata. */
+        v4l2_ctrl_hevcdec_bufmetadata HEVCDecParams;
+    }CodecParams;
+} v4l2_ctrl_videodec_outputbuf_metadata;
+/** @} */
+
+/** @addtogroup V4L2Enc */
+/** @{ */
+
+/**
+ * Specifies the types of encoder temporal tradeoff levels
+ */
+enum v4l2_enc_temporal_tradeoff_level_type {
+    /** Do not drop any buffers. */
+    V4L2_ENC_TEMPORAL_TRADEOFF_LEVEL_DROPNONE = 0,
+    /** Drop 1 in every 5 buffers. */
+    V4L2_ENC_TEMPORAL_TRADEOFF_LEVEL_DROP1IN5,
+    /** Drop 1 in every 3 buffers. */
+    V4L2_ENC_TEMPORAL_TRADEOFF_LEVEL_DROP1IN3,
+    /** Drop 1 in every 2 buffers. */
+    V4L2_ENC_TEMPORAL_TRADEOFF_LEVEL_DROP1IN2,
+    /** Drop 2 in every 3 buffers. */
+    V4L2_ENC_TEMPORAL_TRADEOFF_LEVEL_DROP2IN3,
+};
+
+/**
+ * Specifies the encoder HW Preset type.
+ */
+enum v4l2_enc_hw_preset_type {
+    /** Encoder HWPreset DISABLED. */
+    V4L2_ENC_HW_PRESET_DISABLE = 0,
+    /** Encoder HWPreset with per frame encode time UltraFast. */
+    V4L2_ENC_HW_PRESET_ULTRAFAST = 1,
+    /** Encoder HWPreset with per frame encode time Fast. */
+    V4L2_ENC_HW_PRESET_FAST,
+    /** Encoder HWPreset with per frame encode time Medium. */
+    V4L2_ENC_HW_PRESET_MEDIUM,
+    /** Encoder HWPreset with per frame encode time Slow. */
+    V4L2_ENC_HW_PRESET_SLOW,
+};
+
+/**
+ * Holds encoder HW Preset type parameters
+ * to be used with #V4L2_CID_MPEG_VIDEOENC_HW_PRESET_TYPE_PARAM IOCTL.
+ */
+typedef struct v4l2_enc_hw_preset_type_param_
+{
+    /** Type in which the encoder hw preset is specified, one of type #v4l2_enc_hw_preset_type. */
+    enum v4l2_enc_hw_preset_type hw_preset_type;
+    /** Boolean value indicating if encoder set to max clock. */
+    __u8 set_max_enc_clock;
+}v4l2_enc_hw_preset_type_param;
+
+/**
+ * Enum specifying the type of slice length.
+ */
+enum v4l2_enc_slice_length_type {
+    /** Slice size is specified in terms of number of bytes. */
+    V4L2_ENC_SLICE_LENGTH_TYPE_BITS = 0,
+    /** Slice size is specified in terms of number of macroblocks. */
+    V4L2_ENC_SLICE_LENGTH_TYPE_MBLK,
+};
+
+/**
+ * Specifies the input buffer metadata flag.
+ */
+enum v4l2_enc_input_metadata_param {
+    /** Input metadata structure contains ROI parameters.  */
+    V4L2_ENC_INPUT_ROI_PARAM_FLAG = 1,
+    /** Input metadata structure contains GDR parameters.  */
+    V4L2_ENC_INPUT_GDR_PARAM_FLAG = 1 << 1,
+    /** Input metadata structure contains External RPS parameters.  */
+    V4L2_ENC_INPUT_RPS_PARAM_FLAG = 1 << 2,
+    /** Input metadata structure contains External RC parameters.  */
+    V4L2_ENC_INPUT_RC_PARAM_FLAG = 1 << 3,
+    /** Input metadata structure contains ReconCRC parameters.  */
+    V4L2_ENC_INPUT_RECONCRC_PARAM_FLAG = 1 << 4,
+};
+
+/**
+ * Defines the possible levels for H.265 encoder.
+ */
+enum v4l2_mpeg_video_h265_level {
+
+    V4L2_MPEG_VIDEO_H265_LEVEL_1_0_MAIN_TIER = 0,
+    V4L2_MPEG_VIDEO_H265_LEVEL_1_0_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_2_0_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_2_0_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_2_1_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_2_1_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_3_0_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_3_0_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_3_1_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_3_1_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_4_0_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_4_0_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_4_1_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_4_1_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_5_0_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_5_0_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_5_1_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_5_1_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_5_2_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_5_2_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_6_0_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_6_0_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_6_1_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_6_1_HIGH_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_6_2_MAIN_TIER,
+    V4L2_MPEG_VIDEO_H265_LEVEL_6_2_HIGH_TIER,
+};
+
+/**
+ * Holds encoder slice length parameters, to be used with
+ * \c V4L2_CID_MPEG_VIDEOENC_SLICE_LENGTH_PARAM IOCTL.
+ */
+typedef struct v4l2_enc_slice_length_param_
+{
+    /** Type in which the slice length is specified, one of type \c v4l2_enc_slice_length_type. */
+    enum v4l2_enc_slice_length_type slice_length_type;
+    /** Size of the slice in either number of bytes or number of macro blocks. */
+    __u32   slice_length;
+}v4l2_enc_slice_length_param;
+
+/**
+ * Holds encoder virtual buffer size parameters, to be used with
+ * \c V4L2_CID_MPEG_VIDEOENC_VIRTUALBUFFER_SIZE IOCTL.
+ */
+typedef struct v4l2_enc_virtual_buffer_size_
+{
+    /** Size of the virtual buffer, in bits. */
+    __u32   size;
+}v4l2_enc_virtual_buffer_size;
+
+/**
+ * Holds encoder number of reference frame parameters, to be used with
+ * \c V4L2_CID_MPEG_VIDEOENC_NUM_REFERENCE_FRAMES IOCTL.
+ *
+ * This is not supported for H.265.
+ */
+typedef struct v4l2_enc_num_ref_frames_
+{
+    /** Number of reference frames. */
+    __u32   frames;
+}v4l2_enc_num_ref_frames;
+
+/**
+ * Holds encoder slice intrareferesh parameters, to be used with
+ * \c V4L2_CID_MPEG_VIDEOENC_SLICE_INTRAREFRESH_PARAM IOCTL.
+ */
+typedef struct v4l2_enc_slice_intrarefresh_param_
+{
+    /** Slice intrarefresh interval, in number of slices. */
+    __u32   interval;
+}v4l2_enc_slice_intrarefresh_param;
+
+/**
+ * Defines the maximum number of ROI regions supported by the encoder.
+ */
+#define V4L2_MAX_ROI_REGIONS 8
+
+/**
+ * Holds the encoder quality parameters for a single ROI region.
+ */
+typedef struct v4l2_enc_ROI_param_
+{
+    /** Region of interest rectangle. */
+    struct v4l2_rect  ROIRect;
+    /** QP delta for the region. */
+    __s32   QPdelta;
+} v4l2_enc_ROI_param;
+
+/**
+ * Holds the encoder frame ROI parameters
+ * to be used with #V4L2_CID_MPEG_VIDEOENC_ROI_PARAMS IOCTL.
+ */
+typedef struct v4l2_enc_frame_ROI_params_
+{
+    /** Number of regions. */
+    __u32 num_ROI_regions;
+    /** Array of indiviudal ROI parameters. */
+    v4l2_enc_ROI_param ROI_params[V4L2_MAX_ROI_REGIONS];
+    /** Config store integer to which this control is to be applied.
+     *  This must be same as the value of config store of \c v4l2_buffer to which
+     *  the ROI params is applied. */
+    __u32   config_store;
+}v4l2_enc_frame_ROI_params;
+
+/**
+ * Holds the motion vector parameters for a single block.
+ * For H.264, nvenc provides one motion vector per 16x16 block(Macroblock).
+ * For H.265, nvenc provides one motion vector per 32x32 block(Coded Tree Block).
+ */
+typedef struct MVInfo_ {
+    /** Number of pixels the macro block moved in horizontal direction. */
+    __s32 mv_x   : 16;
+    /** Number of pixels the macro block moved in vertical direction. */
+    __s32 mv_y   : 14;
+    /** Temporal hints used by hardware for Motion Estimation. */
+    __u32 weight : 2;
+} MVInfo;
+
+/**
+ * Holds the motion vector parameters for one complete frame.
+ */
+typedef struct v4l2_ctrl_videoenc_outputbuf_metadata_MV_ {
+    /** Size of the pMVInfo buffer, in bytes. */
+    __u32 bufSize;
+    /** Pointer to the buffer containing the motion vectors. */
+    MVInfo *pMVInfo;
+} v4l2_ctrl_videoenc_outputbuf_metadata_MV;
+
+/**
+ * Maximum number of reference frames supported by the encoder.
+ */
+#define V4L2_MAX_REF_FRAMES  8
+
+/**
+ * Holds the RPS List parameters of encoded frame.
+ */
+typedef struct v4l2_enc_frame_full_prop_
+{
+    /** Unique frame ID. */
+    __u32  nFrameId;
+    /** Boolean value indicating if current frame is an IDR. */
+    __u8   bIdrFrame;
+    /** Boolean value indicating if set Long Term Ref Flag. */
+    __u8   bLTRefFrame;
+    /** Picture Order Count. */
+    __u32  nPictureOrderCnt;
+    /** FrameNum. */
+    __u32  nFrameNum;
+    /** LongTermFrameIdx of a picture. */
+    __u32  nLTRFrameIdx;
+} v4l2_enc_frame_full_prop;
+
+/**
+ * Holds the encoder output metadata for a frame, to be used with
+ * \c V4L2_CID_MPEG_VIDEOENC_METADATA IOCTL.
+ */
+typedef struct v4l2_ctrl_videoenc_outputbuf_metadata_
+{
+    /** Boolean value indicating if current frame is a key frame. */
+    __u8 KeyFrame;
+    /** Boolean value indicating end of frame in case of multi slice encoding. */
+    __u8 EndofFrame;
+    /** Average QP value of the frame. */
+    __u16 AvgQP;
+    /** Boolean value indicating if current frame is a golden or alternate frame. */
+    __u8 bIsGoldenOrAlternateFrame;
+    /** CRC for Reconstructed frame. */
+    __u8 bValidReconCRC;
+    /** Recon Y-frame CRC */
+    __u32 ReconFrame_Y_CRC;
+    /** Recon U-frame CRC */
+    __u32 ReconFrame_U_CRC;
+    /** Recon V-frame CRC */
+    __u32 ReconFrame_V_CRC;
+    /** Number of bits needed to encode the frame. */
+    __u32 EncodedFrameBits;
+    /** Minumum QP value in the frame. */
+    __u32 FrameMinQP;
+    /** Maximum QP value in the frame. */
+    __u32 FrameMaxQP;
+    /** RPS Feedback. */
+    __u32 bRPSFeedback_status;
+    /**  Reference frame ID used for Motion Estimation of current frame,
+         ignored for IDR */
+    __u32 nCurrentRefFrameId;
+    /** Number of active reference frames. */
+    __u32 nActiveRefFrames;
+    /** RPS List including most recent frame if it is reference frame. */
+    v4l2_enc_frame_full_prop RPSList[V4L2_MAX_REF_FRAMES];
+} v4l2_ctrl_videoenc_outputbuf_metadata;
+
+/**
+ * Holds the metadata parameters for video encoder and decoder.
+ *
+ * The metadata is valid for the buffer with index \c buffer_index after the
+ * buffer is dequeued until it is queued again.
+ */
+typedef struct v4l2_ctrl_video_metadata_
+{
+    /** A pointer to #v4l2_ctrl_videodec_inputbuf_metadata structure.
+     * This must be a valid pointer when used with #V4L2_CID_MPEG_VIDEODEC_INPUT_METADATA
+     * IOCTL. */
+    v4l2_ctrl_videodec_inputbuf_metadata *VideoDecHeaderErrorMetadata;
+    /** A pointer to #v4l2_ctrl_videodec_outputbuf_metadata structure.
+     * This must be a valid pointer when used with #V4L2_CID_MPEG_VIDEODEC_METADATA
+     * IOCTL. */
+    v4l2_ctrl_videodec_outputbuf_metadata *VideoDecMetadata;
+    /** A pointer to #v4l2_ctrl_videoenc_outputbuf_metadata structure.
+     * This must be a valid pointer when used with #V4L2_CID_MPEG_VIDEOENC_METADATA
+     * IOCTL. */
+    v4l2_ctrl_videoenc_outputbuf_metadata *VideoEncMetadata;
+    /** A pointer to #v4l2_ctrl_videoenc_outputbuf_metadata_MV structure.
+     * This must be a valid pointer when used with #V4L2_CID_MPEG_VIDEOENC_METADATA_MV
+     * IOCTL. */
+    v4l2_ctrl_videoenc_outputbuf_metadata_MV *VideoEncMetadataMV;
+    /** Index of the buffer whose metadata is required. */
+    __u32 buffer_index;
+} v4l2_ctrl_video_metadata;
+
+/**
+ * Holds the encoder GDR parameters
+ * to be used with #V4L2_CID_MPEG_VIDEOENC_INPUT_METADATA IOCTL.
+ */
+typedef struct v4l2_enc_gdr_params_
+{
+    /** Parameter for GDR (Intra Refresh) for specified number of frames. */
+    __u32 nGDRFrames;
+} v4l2_enc_gdr_params;
+
+/**
+ * Holds the params to configure encoder for external rps control
+ * to be used with #V4L2_CID_MPEG_VIDEOENC_ENABLE_EXTERNAL_RPS_CONTROL IOCTL.
+ */
+typedef struct v4l2_enc_enable_ext_rps_ctrl_
+{
+    /** Boolean value indicating if enabled External RPS control. */
+    __u8 bEnableExternalRPS;
+    /** Boolean value indicating if allowed gap in frame number. */
+    __u8 bGapsInFrameNumAllowed;
+    /* TODO : Check for field details. */
+    __u32 nH264FrameNumBits;
+    /* TODO : Check for field details. */
+    __u32 nH265PocLsbBits;
+}v4l2_enc_enable_ext_rps_ctr;
+
+
+/**
+ * Holds the encoder frame property.
+ */
+typedef struct _v4l2_enc_frame_prop
+{
+    /** unique Id. */
+    __u32 nFrameId;
+    /** Long Term Ref Flag. */
+    __u8 bLTRefFrame;
+} v4l2_enc_frame_prop;
+
+/**
+ * Holds the encoder frame external rps control parameters
+ * to be used with #V4L2_CID_MPEG_VIDEOENC_INPUT_METADATA IOCTL.
+ */
+typedef struct v4l2_enc_frame_ext_rps_ctrl_params_
+{
+    /** unique Id of current frame. */
+    __u32 nFrameId;
+    /** Boolean value indicating if current frame referenced or non-referenced. */
+    __u8 bRefFrame;
+    /** Boolean value indicating if current frame long Term Ref Flag. */
+    __u8 bLTRefFrame;
+   /** Max Number of reference frames to use for inter-motion search. */
+    __u32 nMaxRefFrames;
+    /** # of valid entries in RPS, 0 means IDR. */
+    __u32 nActiveRefFrames;;
+    /**  frame id of reference frame to be used for motion search, ignored for IDR. */
+    __u32 nCurrentRefFrameId;
+    /** Array of RPS */
+    v4l2_enc_frame_prop RPSList[V4L2_MAX_REF_FRAMES];
+}v4l2_enc_frame_ext_rps_ctrl_params;
+
+
+/**
+ * Holds the params to configure encoder for external rate control mode
+ * to be used with #V4L2_CID_MPEG_VIDEOENC_ENABLE_EXTERNAL_RATE_CONTROL IOCTL.
+ */
+typedef struct v4l2_enc_enable_ext_rate_ctrl_
+{
+    /** Boolean value indicating if enabled External Picture RC. */
+    __u8 bEnableExternalPictureRC;
+    /** Max QP per session when external picture RC enabled. */
+    __u32 nsessionMaxQP;
+}v4l2_enc_enable_ext_rate_ctr;
+
+/**
+ * Holds the encoder frame external rate control parameters
+ * to be used with #V4L2_CID_MPEG_VIDEOENC_INPUT_METADATA ioctl.
+ */
+typedef struct v4l2_enc_frame_ext_rate_ctrl_params_
+{
+    /** Target frame bits. */
+    __u32 nTargetFrameBits;
+    /** Frame start QP. */
+    __u32 nFrameQP;
+    /** Frame min QP. */
+    __u32 nFrameMinQp;
+    /** Frame max QP. */
+    __u32 nFrameMaxQp;
+    /** Frame min QP deviation. */
+    __u32 nMaxQPDeviation;
+}v4l2_enc_frame_ext_rate_ctrl_params;
+
+/**
+ * Holds the params to configure encoder for ROI parameters encoding
+ *
+ * Must be used with #V4L2_CID_MPEG_VIDEOENC_ENABLE_ROI_PARAM IOCTL.
+ */
+typedef struct v4l2_enc_enable_roi_param_
+{
+    /** Boolean value to indicating ROI param encoding. */
+    __u8 bEnableROI;
+}v4l2_enc_enable_roi_param;
+
+/**
+ * Holds the params to configure encoder for Reconstructed CRC encoding
+ *
+ * Must be used with #V4L2_CID_MPEG_VIDEOENC_ENABLE_RECONCRC_PARAM IOCTL.
+ */
+typedef struct v4l2_enc_enable_reconcrc_param_
+{
+    /** Boolean value to indicating Reconstructed CRC encoding. */
+    __u8 bEnableReconCRC;
+}v4l2_enc_enable_reconcrc_param;
+
+/**
+ * Holds the encoder frame Reconstructed CRC parameters.
+ *
+ * Must be used with #V4L2_CID_MPEG_VIDEOENC_INPUT_METADATA IOCTL.
+ */
+typedef struct v4l2_enc_frame_ReconCRC_params_
+{
+    /** Rectangle to specify the co-ordinates of the input frame
+    * used to calculate reconstructed picture CRC. */
+    struct v4l2_rect  ReconCRCRect;
+}v4l2_enc_frame_ReconCRC_params;
+
+/**
+ * Holds the encoder frame input metadata parameters.
+ *
+ * Must be used with #V4L2_CID_MPEG_VIDEOENC_INPUT_METADATA IOCTL.
+ */
+typedef struct v4l2_ctrl_videoenc_input_metadata_
+{
+    /** Flag to indicate which inputbuffer metadata is valid. */
+    __u32    flag;
+    /** Pointer to the ROI params structure when ROI param is in metadata_flag. */
+    v4l2_enc_frame_ROI_params *VideoEncROIParams;
+    /** Pointer to the Reconstructed CRC parameter structure when ReconCRC param is in
+    * metadata flag. */
+    v4l2_enc_frame_ReconCRC_params *VideoReconCRCParams;
+    /** Pointer to the GDR params structure when GDR param is in metadata_flag. */
+    v4l2_enc_gdr_params   *VideoEncGDRParams;
+    /** Pointer to the External RPL control parameter structure when RPS param is in
+    * metadata flag. */
+    v4l2_enc_frame_ext_rps_ctrl_params *VideoEncRPSParams;
+    /** Pointer to the External Rate control parameter structure when RC param is in
+    * metadata flag. */
+    v4l2_enc_frame_ext_rate_ctrl_params *VideoEncExtRCParams;
+    /** Config store integer to which these parameters are to be applied.
+     *  This must be same as the value of config store of queued v4l2_buffer
+     *   for which these parameters are valid. */
+    __u32    config_store;
+} v4l2_ctrl_videoenc_input_metadata;
+
+/**
+ * Setting Qp values in #v4l2_ctrl_video_qp_range to QP_RETAIN_VAL
+ * retains default or previously set QP values.
+ */
+#define QP_RETAIN_VAL -1
+
+/**
+ * Holds the encoder frame min/max QP parameters.
+ *
+ * Must be used with #V4L2_CID_MPEG_VIDEOENC_QP_RANGE IOCTL.
+ */
+typedef struct _v4l2_ctrl_video_qp_range
+{
+    /** Minimum QP value for I frame. */
+    __u32 MinQpI;
+    /** Maximum QP value for I frame. */
+    __u32 MaxQpI;
+    /** Minimum QP value for P frame. */
+    __u32 MinQpP;
+    /** Maximum QP value for P frame. */
+    __u32 MaxQpP;
+    /** Minimum QP value for B frame. */
+    __u32 MinQpB;
+    /** Maximum QP value for B frame. */
+    __u32 MaxQpB;
+} v4l2_ctrl_video_qp_range;
+/** @} */
+
+/** @addtogroup V4L2Conv */
+/** @{ */
+
+/**
+ * Enum specifying types of buffer layouts.
+ */
+enum v4l2_nv_buffer_layout {
+    V4L2_NV_BUFFER_LAYOUT_PITCH = 0,  /**< Pitch Linear Layout. */
+    V4L2_NV_BUFFER_LAYOUT_BLOCKLINEAR = 1, /**< Block Linear Layout. */
+};
+
+/**
+ * Specifies the types of rotation/flip algorithms.
+ */
+enum v4l2_flip_method {
+    V4L2_FLIP_METHOD_IDENTITY = 0, /**< Identity (no rotation). */
+    V4L2_FLIP_METHOD_90L = 1,      /**< Rotate counter-clockwise 90 degrees. */
+    V4L2_FLIP_METHOD_180 = 2,      /**< Rotate 180 degrees. */
+    V4L2_FLIP_METHOD_90R = 3,      /**< Rotate clockwise 90 degrees. */
+    V4L2_FLIP_METHOD_HORIZ = 4,    /**< Flip horizontally. */
+    V4L2_FLIP_METHOD_INVTRANS = 5, /**< Flip across upper right/lower left diagonal. */
+    V4L2_FLIP_METHOD_VERT = 6,     /**< Flip vertically. */
+    V4L2_FLIP_METHOD_TRANS = 7,    /**< Flip across upper left/lower right diagonal. */
+};
+
+/**
+ * Specifies the types of interpolation methods.
+ */
+enum v4l2_interpolation_method {
+  V4L2_INTERPOLATION_NEAREST = 1,   /**< Nearest interpolation method */
+  V4L2_INTERPOLATION_BILINEAR = 2,  /**< Bi-Linear interpolation method */
+  V4L2_INTERPOLATION_5_TAP = 3,     /**< 5-Tap interpolation method */
+  V4L2_INTERPOLATION_10_TAP = 4,    /**< 10-Tap interpolation method */
+  V4L2_INTERPOLATION_SMART = 5,     /**< Smart interpolation method */
+  V4L2_INTERPOLATION_NICEST = 6,    /**< Nicest interpolation method */
+};
+
+/**
+ * Specifies the types of TNR algorithms.
+ */
+enum v4l2_tnr_algorithm {
+  V4L2_TNR_ALGO_ORIGINAL = 0,           /**< Default TNR algorithm. */
+  V4L2_TNR_ALGO_OUTDOOR_LOW_LIGHT = 1,  /**< Outdoor Low Light TNR algorithm. */
+  V4L2_TNR_ALGO_OUTDOOR_MEDIUM_LIGHT = 2, /**< Outdoor Medium Light TNR algorithm. */
+  V4L2_TNR_ALGO_OUTDOOR_HIGH_LIGHT = 3, /**< Outdoor High Light TNR algorithm. */
+  V4L2_TNR_ALGO_INDOOR_LOW_LIGHT = 4, /**< Indoor Low Light TNR algorithm. */
+  V4L2_TNR_ALGO_INDOOR_MEDIUM_LIGHT = 5, /**< Indoor Medium Light TNR algorithm. */
+  V4L2_TNR_ALGO_INDOOR_HIGH_LIGHT = 6, /**< Indoor High Light TNR algorithm. */
+};
+
+/**
+ * Specifies the types of YUV rescale methods.
+ */
+enum v4l2_yuv_rescale_method {
+  /**< Disable */
+  V4L2_YUV_RESCALE_NONE = 0,
+  /**< Standard(limited range [16 235]) to extension(full range [0 255]) */
+  V4L2_YUV_RESCALE_STD_TO_EXT = 1,
+  /**< Extension(full range [0 255] to standard(limited range [16 235]) */
+  V4L2_YUV_RESCALE_EXT_TO_STD = 2,
+};
+
+typedef struct v4l2_ctrl_video_displaydata_
+{
+    __u32 masteringdisplaydatapresent;
+}v4l2_ctrl_video_displaydata;
+
+/**
+ * HDR Metadata.
+ */
+
+typedef struct _v4l2_ctrl_video_hdrmasteringdisplaydata
+{
+    // idx 0 : G, 1 : B, 2 : R
+    __u16 display_primaries_x[3];       // normalized x chromaticity cordinate. It shall be in the range of 0 to 50000
+    __u16 display_primaries_y[3];       // normalized y chromaticity cordinate. It shall be in the range of 0 to 50000
+    __u16 white_point_x;    // normalized x chromaticity cordinate of white point of mastering display
+    __u16 white_point_y;    // normalized y chromaticity cordinate of white point of mastering display
+    __u32 max_display_parameter_luminance;      // nominal maximum display luminance in units of 0.0001 candelas per square metre
+    __u32 min_display_parameter_luminance;      // nominal minimum display luminance in units of 0.0001 candelas per square metre
+} v4l2_ctrl_video_hdrmasteringdisplaydata;
+
+
+/**
+ * Poll device
+ */
+typedef struct _v4l2_ctrl_video_device_poll
+{
+    __u16 req_events;    // Requested events, a bitmask of POLLIN, POLLOUT, POLLERR, POLLPRI.
+    __u16 resp_events;    // Returned events a similar bitmask of above events.
+} v4l2_ctrl_video_device_poll;
+
+/** @} */
+
+
+
+/**
+ * @file
+ * <b>NVIDIA Multimedia Utilities: Buffering and Transform/Composition/Blending</b>
+ *
+ */
+
+/**
+ * Defines the maximum number of planes for a video frame.
+ */
+#define MAX_NUM_PLANES 4
+
+/**
+ * Defines NvBuffer Version.
+ */
+typedef enum
+{
+  /** L4T BSP r32.3.x - r32.4.x */
+  NvBufferPixFmtVersion_Legacy,
+  /** L4T BSP r32.5.x and newer */
+  NvBufferPixFmtVersion_New,
+} NvBufferPixFmtVersion;
+
+/**
+ * Defines Payload types for NvBuffer.
+ */
+typedef enum
+{
+  /** buffer payload with HW memory handle for set of planes. */
+  NvBufferPayload_SurfArray,
+  /** buffer payload with HW memory handle for specific memory size. */
+  NvBufferPayload_MemHandle,
+} NvBufferPayloadType;
+
+/**
+ * Defines Layout formats for NvBuffer video planes.
+ */
+typedef enum
+{
+  /** Pitch Layout. */
+  NvBufferLayout_Pitch,
+  /** BlockLinear Layout. */
+  NvBufferLayout_BlockLinear,
+} NvBufferLayout;
+
+/**
+ * Defines memory access flags for NvBuffer.
+ */
+typedef enum
+{
+  /** Memory read. */
+  NvBufferMem_Read,
+  /** Memory write. */
+  NvBufferMem_Write,
+  /** Memory read & write. */
+  NvBufferMem_Read_Write,
+} NvBufferMemFlags;
+
+/**
+ * Defines tags that identify the components requesting a memory allocation.
+ * The tags can be used later to identify the total memory allocated to
+ * particular types of components.
+ */
+typedef enum
+{
+  /** tag None. */
+  NvBufferTag_NONE            = 0x0,
+  /** tag for Camera. */
+  NvBufferTag_CAMERA          = 0x200,
+  /** tag for Jpeg Encoder/Decoder. */
+  NvBufferTag_JPEG            = 0x1500,
+  /** tag for VPR Buffers. */
+  NvBufferTag_PROTECTED       = 0x1504,
+  /** tag for H264/H265 Video Encoder. */
+  NvBufferTag_VIDEO_ENC       = 0x1200,
+  /** tag for H264/H265/VP9 Video Decoder. */
+  NvBufferTag_VIDEO_DEC       = 0x1400,
+  /** tag for Video Transform/Composite. */
+  NvBufferTag_VIDEO_CONVERT   = 0xf01,
+} NvBufferTag;
+
+/**
+ * Defines color formats for NvBuffer.
+ */
+typedef enum
+{
+  /** BT.601 colorspace - YUV420 multi-planar. */
+  NvBufferColorFormat_YUV420    = 0,
+  /** BT.601 colorspace - YUV420 ER multi-planar. */
+  NvBufferColorFormat_YUV420_ER = 2, /* BSP 32.5.0 and up: 3 */
+  /** BT.601 colorspace - Y/CbCr 4:2:0 multi-planar. */
+  NvBufferColorFormat_NV12      = 4, /* BSP 32.5.0 and up: 5 */
+  /** BT.601 colorspace - Y/CbCr ER 4:2:0 multi-planar. */
+  NvBufferColorFormat_NV12_ER   = 5, /* BSP 32.5.0 and up: 6 */
+  /** LegacyRGBA colorspace - BGRA-8-8-8-8 planar. */
+  NvBufferColorFormat_ABGR32    = 16, /* BSP 32.5.0 and up: 17 */
+  /** LegacyRGBA colorspace - XRGB-8-8-8-8 planar. */
+  NvBufferColorFormat_XRGB32    = 17, /* BSP 32.5.0 and up: 18 */
+  /** LegacyRGBA colorspace - ARGB-8-8-8-8 planar. */
+  NvBufferColorFormat_ARGB32    = 18, /* BSP 32.5.0 and up: 19 */
+  /** BT.601 colorspace - Y/CbCr 4:2:0 10-bit multi-planar. */
+  NvBufferColorFormat_NV12_10LE = 19, /* BSP 32.5.0 and up: 20 */
+  /** BT.601 colorspace - YUV444 multi-planar. */
+  NvBufferColorFormat_YUV444    = 35, /* BSP 32.5.0 and up: 36 */
+} NvBufferColorFormat;
+
+/**
+ * Defines video flip methods.
+ */
+typedef enum
+{
+  /** Video flip none. */
+  NvBufferTransform_None,
+  /** Video flip rotate 90 degree counter-clockwise. */
+  NvBufferTransform_Rotate90,
+  /** Video flip rotate 180 degree. */
+  NvBufferTransform_Rotate180,
+  /** Video flip rotate 270 degree counter-clockwise. */
+  NvBufferTransform_Rotate270,
+  /** Video flip with respect to X-axis. */
+  NvBufferTransform_FlipX,
+  /** Video flip with respect to Y-axis. */
+  NvBufferTransform_FlipY,
+  /** Video flip transpose. */
+  NvBufferTransform_Transpose,
+  /** Video flip inverse transpode. */
+  NvBufferTransform_InvTranspose,
+} NvBufferTransform_Flip;
+
+/**
+ * Defines transform video filter types.
+ */
+typedef enum
+{
+  /** transform filter nearest. */
+  NvBufferTransform_Filter_Nearest,
+  /** transform filter bilinear. */
+  NvBufferTransform_Filter_Bilinear,
+  /** transform filter 5 tap. */
+  NvBufferTransform_Filter_5_Tap,
+  /** transform filter 10 tap. */
+  NvBufferTransform_Filter_10_Tap,
+  /** transform filter smart. */
+  NvBufferTransform_Filter_Smart,
+  /** transform filter nicest. */
+  NvBufferTransform_Filter_Nicest,
+} NvBufferTransform_Filter;
+
+/**
+ * Defines flags to indicate for valid transform.
+ */
+typedef enum {
+  /** transform flag to crop source rectangle. */
+  NVBUFFER_TRANSFORM_CROP_SRC   = 1,
+  /** transform flag to crop destination rectangle. */
+  NVBUFFER_TRANSFORM_CROP_DST   = 1 << 1,
+  /** transform flag to set filter type. */
+  NVBUFFER_TRANSFORM_FILTER     = 1 << 2,
+  /** transform flag to set flip method. */
+  NVBUFFER_TRANSFORM_FLIP       = 1 << 3,
+} NvBufferTransform_Flag;
+
+/**
+ * Holds coordinates for a rectangle.
+ */
+typedef struct
+{
+  /** rectangle top. */
+  uint32_t top;
+  /** rectangle left. */
+  uint32_t left;
+  /** rectangle width. */
+  uint32_t width;
+  /** rectangle height. */
+  uint32_t height;
+}NvBufferRect;
+
+/**
+ * Holds an opaque NvBuffer session type required for parallel buffer
+ * tranformations and compositions. Operations using a single session are
+ * scheduled sequentially, after the previous operation finishes. Operations for
+ * multiple sessions are scheduled in parallel.
+ */
+typedef struct _NvBufferSession * NvBufferSession;
+
+
+/**
+ * Holds the input parameters for hardware buffer creation.
+ */
+typedef struct _NvBufferCreateParams
+{
+  /** width of the buffer. */
+  int32_t width;
+  /** height of the buffer. */
+  int32_t height;
+  /** payload type of the buffer. */
+  NvBufferPayloadType payloadType;
+  /** size of the memory.(Applicale for NvBufferPayload_MemHandle) */
+  int32_t memsize;
+  /** layout of the buffer. */
+  NvBufferLayout layout;
+  /** colorformat of the buffer. */
+  NvBufferColorFormat colorFormat;
+  /** tag to associate with the buffer. */
+  NvBufferTag nvbuf_tag;
+}NvBufferCreateParams;
+
+/**
+ * Holds parameters for a hardware buffer.
+ */
+typedef struct _NvBufferParams
+{
+  /** Holds the DMABUF FD of the hardware buffer. */
+  uint32_t dmabuf_fd;
+  /** pointer to hardware buffer memory. */
+  void *nv_buffer;
+  /** payload type of the buffer. */
+  NvBufferPayloadType payloadType;
+  /** size of the memory.(Applicale for NvBufferPayload_MemHandle) */
+  int32_t memsize;
+  /** size of hardware buffer. */
+  uint32_t nv_buffer_size;
+  /** video format type of hardware buffer. */
+  NvBufferColorFormat pixel_format;
+  /** number of planes of hardware buffer. */
+  uint32_t num_planes;
+  /** width of each planes of hardware buffer. */
+  uint32_t width[MAX_NUM_PLANES];
+  /** height of each planes of hardware buffer. */
+  uint32_t height[MAX_NUM_PLANES];
+  /** pitch of each planes of hardware buffer. */
+  uint32_t pitch[MAX_NUM_PLANES];
+  /** memory offset values of each video planes of hardware buffer. */
+  uint32_t offset[MAX_NUM_PLANES];
+  /** size of each video planes of hardware buffer. */
+  uint32_t psize[MAX_NUM_PLANES];
+  /** layout type of each planes of hardware buffer. */
+  uint32_t layout[MAX_NUM_PLANES];
+}NvBufferParams;
+
+/**
+ * Holds parameters for buffer transform functions.
+ */
+typedef struct _NvBufferTransformParams
+{
+  /** flag to indicate which of the transform parameters are valid. */
+  uint32_t transform_flag;
+  /** flip method. */
+  NvBufferTransform_Flip transform_flip;
+  /** transform filter. */
+  NvBufferTransform_Filter transform_filter;
+  /** source rectangle coordinates for crop opeartion. */
+  NvBufferRect src_rect;
+  /** destination rectangle coordinates for crop opeartion. */
+  NvBufferRect dst_rect;
+  /** NvBufferSession to be used for transform. If NULL, the default session
+   * is used. */
+  NvBufferSession session;
+}NvBufferTransformParams;
+
+/**
+ * Allocates a hardware buffer (deprecated).
+ *
+ * @deprecated Use NvBufferCreateEx() instead.
+ * @param[out] dmabuf_fd    Returns the DMABUF FD of the hardware buffer.
+ * @param[in]  width        Buffer width, in bytes.
+ * @param[in]  height       Buffer height, in bytes.
+ * @param[in]  layout       Layout of the buffer.
+ * @param[in]  colorFormat  Color format of the buffer.
+ *
+ * @return 0 if successful, or -1 otherwise.
+ */
+int NvBufferCreate (int *dmabuf_fd, int width, int height,
+    NvBufferLayout layout, NvBufferColorFormat colorFormat);
+
+/**
+ * Allocates a hardware buffer.
+ *
+ * @param[out] dmabuf_fd    Returns the DMABUF FD of the hardware buffer.
+ * @param[in]  input_params Input parameters for hardware buffer creation.
+ *
+ * @returns 0 for success, -1 for failure
+ */
+int NvBufferCreateEx (int *dmabuf_fd, NvBufferCreateParams *input_params);
+
+/**
+ * Gets buffer parameters.
+ * @param[in] dmabuf_fd `DMABUF FD` of buffer.
+ * @param[out] params A pointer to the structure to fill with parameters.
+ *
+ * @returns 0 for success, -1 for failure.
+ */
+int NvBufferGetParams (int dmabuf_fd, NvBufferParams *params);
+
+/**
+* Destroys a HW buffer.
+* @param[in] dmabuf_fd Specifies the `dmabuf_fd` `hw_buffer` to destroy.
+*
+* @returns 0 for success, -1 for failure.
+*/
+int NvBufferDestroy (int dmabuf_fd);
+
+/**
+* Syncs the HW memory cache for the CPU.
+*
+* \sa NvBufferMemMap for the purpose of the function
+*
+* @param[in] dmabuf_fd DMABUF FD of buffer.
+* @param[in] plane video frame plane.
+* @param[in] pVirtAddr Virtual Address pointer of the memory-mapped plane.
+*
+* @returns 0 for success, -1 for failure.
+
+*/
+int NvBufferMemSyncForCpu (int dmabuf_fd, unsigned int plane, void **pVirtAddr);
+
+/**
+* Syncs the hardware memory cache for the device.
+*
+* \sa NvBufferMemMap for the purpose of the function
+*
+* @param[in] dmabuf_fd DMABUF FD of buffer.
+* @param[in] plane video frame plane.
+* @param[in] pVirtAddr Virtual Address pointer of the memory-mapped plane.
+*
+* @returns 0 for success, -1 for failure.
+*/
+int NvBufferMemSyncForDevice (int dmabuf_fd, unsigned int plane, void **pVirtAddr);
+
+/**
+* Gets the memory-mapped virtual address of the plane.
+*
+* The client must call NvBufferMemSyncForCpu() with the virtual address returned
+* by this function before accessing the mapped memory in CPU.
+*
+* After memory mapping is complete, mapped memory modification
+* must be coordinated between the CPU and hardware device as
+* follows:
+* - CPU: If the CPU modifies any mapped memory, the client must call
+*   NvBufferMemSyncForDevice() before any hardware device accesses the memory.
+* - Hardware device: If the mapped memory is modified by any hardware device,
+*   the client must call NvBufferMemSyncForCpu() before CPU accesses the memory.
+*
+* @param[in] dmabuf_fd DMABUF FD of buffer.
+* @param[in] plane video frame plane.(Applies to @ref NvBufferPayload_SurfArray.)
+* @param[in] memflag NvBuffer memory flag.
+* @param[out] pVirtAddr Virtual Address pointer of the memory-mapped plane.
+*
+* @returns 0 for success, -1 for failure.
+*/
+int NvBufferMemMap (int dmabuf_fd, unsigned int plane, NvBufferMemFlags memflag, void **pVirtAddr);
+
+/**
+* Unmaps the mapped virtual address of the plane.
+*
+* If the following conditions are both true, the client must call
+* NvBufferMemSyncForDevice() before unmapping the memory:
+* - Mapped memory was modified by the CPU.
+* - Mapped memory will be accessed by a hardware device.
+*
+* @param[in] dmabuf_fd  DMABUF FD of the buffer.
+* @param[in] plane      Video frame plane. Applies to
+*                       @ref NvBufferPayload_SurfArray.
+* @param[in] pVirtAddr  Virtual address pointer to the memory-mapped plane.
+*
+* @returns 0 for success, -1 for failure.
+*/
+int NvBufferMemUnMap (int dmabuf_fd, unsigned int plane, void **pVirtAddr);
+
+/**
+* Copies the NvBuffer plane contents to a raw buffer plane.
+* @param[in] dmabuf_fd DMABUF FD of NvBuffer.
+* @param[in] plane video frame plane.
+* @param[in] out_width aligned width of the raw data plane.
+* @param[in] out_height aligned height of the raw data plane.
+* @param[in] ptr pointer to the output raw plane data.
+*
+* @returns 0 for success, -1 for failure.
+*/
+int NvBuffer2Raw (int dmabuf_fd, unsigned int plane, unsigned int out_width, unsigned int out_height, unsigned char *ptr);
+
+/**
+* Copies raw buffer plane contents to an NvBuffer plane.
+* @param[in] ptr pointer to the input raw plane data.
+* @param[in] plane video frame plane.
+* @param[in] in_width aligned width of the raw data plane.
+* @param[in] in_height aligned height of the raw data plane.
+* @param[in] dmabuf_fd DMABUF FD of NvBuffer.
+*
+* @returns 0 for success, -1 for failure.
+*/
+int Raw2NvBuffer (unsigned char *ptr, unsigned int plane, unsigned int in_width, unsigned int in_height, int dmabuf_fd);
+
+/**
+* Creates a new NvBufferSession for parallel scheduling of
+* buffer transformations and compositions.
+*
+* @returns A session pointer, NULL for failure.
+*/
+NvBufferSession NvBufferSessionCreate(void);
+
+/**
+* Destroys an existing \ref NvBufferSession.
+* @param[in] session    An existing NvBufferSession.
+*/
+void NvBufferSessionDestroy(NvBufferSession session);
+
+/**
+ * Transforms one DMA buffer to another DMA buffer.
+ * This function can support transforms for copying, scaling, fliping, rotating, and cropping.
+ * @param[in] src_dmabuf_fd DMABUF FD of source buffer
+ * @param[in] dst_dmabuf_fd DMABUF FD of destination buffer
+ * @param[in] transform_params transform parameters
+ *
+ * @return 0 for sucess, -1 for failure.
+ */
+int NvBufferTransform (int src_dmabuf_fd, int dst_dmabuf_fd, NvBufferTransformParams *transform_params);
+
+#endif /*__NVV4L2_EXT_UTILS_H__*/
diff -Naur ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2.h ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2.h
--- ffmpeg-4.4-N-Alpha1/libavcodec/nvv4l2.h	1970-01-01 01:00:00.000000000 +0100
+++ ffmpeg-4.4-N-Alpha1-2/libavcodec/nvv4l2.h	2022-04-20 03:49:41.823220489 +0200
@@ -0,0 +1,339 @@
+/*
+ * Copyright (c) 2021-2022, CTCaer <ctcaer@gmail.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+/**
+ * Specifies the decoder device node.
+ */
+#ifndef __NVV4L2_H__
+#define __NVV4L2_H__
+
+#include <stdlib.h>
+#include <stdint.h>
+#include <stdbool.h>
+#include <libv4l2.h>
+#include <linux/videodev2.h>
+#include "avcodec.h"
+
+#include "nvv4l2_ext_utils.h"
+
+#define NV_MAX_BUFFERS 32
+#define NV_MAX_PLANES 3
+
+/* Max timestamp accepted by NVV4L2 */
+#define NV_V4L2_TIMESTAMP_MAX_SEC ((int64_t)UINT64_C(0x1AD7F29ABCA))
+
+/* Custom values/flags to pass over info into capture plane */
+#define NV_V4L2_NOPTS_VALUE NV_V4L2_TIMESTAMP_MAX_SEC
+#define NV_V4L2_REORDERED_OPAQUE_FLAG ((int64_t)UINT64_C(0x10000000000))
+
+#define NVMIN(a,b) (((a) < (b)) ? (a) : (b))
+#define NVMAX(a, b) ((a) > (b) ? (a) : (b))
+
+/* Use app malloc/free implementation */
+#define NVMALLOC(size) (av_malloc((size)))
+#define NVCALLOC(num, size) (av_mallocz((num) * (size)))
+#define NVFREE(ptr) (av_free((ptr)))
+
+#define NVALIGN(x, a) (((x) + (a) - 1) & ~((a) - 1))
+
+typedef struct _queue {
+    uint32_t capacity;
+    uint32_t front;
+    uint32_t back;
+} NvQueues;
+
+typedef enum {
+    NV_PIX_NV12,
+    NV_PIX_YUV420
+} NvPixFormat;
+
+typedef struct _NVPACKET {
+    uint32_t flags;
+    uint32_t payload_size;
+    uint8_t *payload;
+    uint32_t width;
+    uint32_t height;
+    int64_t  pts;
+    int64_t  user_pts;
+} NvPacket;
+
+typedef struct _NVFRAME {
+    uint32_t flags;
+    uint32_t payload_size[3];
+    uint8_t *payload[3];
+    uint32_t width;
+    uint32_t height;
+    int64_t  pts;
+    int64_t  user_pts;
+} NvFrame;
+
+typedef enum {
+    NvVideoCodec_H264,              /**< H.264 */
+    NvVideoCodec_MPEG4,             /**< MPEG-4 */
+    NvVideoCodec_MPEG2,             /**< MPEG-2 */
+    NvVideoCodec_VP8,               /**< VP8 */
+    NvVideoCodec_VP9,               /**< VP9 */
+    NvVideoCodec_HEVC,              /**< H.265/HEVC */
+    NvVideoCodec_UNDEFINED,
+} NvCodingType;
+
+typedef struct {
+    uint32_t width;                 /**< Holds the width of the plane in pixels. */
+    uint32_t height;                /**< Holds the height of the plane in pixels. */
+
+    uint32_t bytesperpixel;         /**< Holds the bytes used to represent one
+                                         pixel in the plane. */
+    uint32_t stride;                /**< Holds the stride of the plane in bytes. */
+    uint32_t sizeimage;             /**< Holds the size of the plane in bytes. */
+} NvBufferPlaneFormat;
+
+    /**
+     * Holds the buffer plane parameters.
+     */
+
+typedef struct {
+    NvBufferPlaneFormat fmt;        /**< Holds the format of the plane. */
+    uint8_t *data;                  /**< Holds a pointer to the plane memory. */
+    uint32_t bytesused;             /**< Holds the number of valid bytes in the plane. */
+    int fd;                         /**< Holds the file descriptor (FD) of the plane of the
+                                     exported buffer, in the case of V4L2 MMAP buffers. */
+    uint32_t mem_offset;            /**< Holds the offset of the first valid byte
+                                         from the data pointer. */
+    uint32_t length;                /**< Holds the size of the buffer in bytes. */
+} NvBufferPlane;
+
+typedef struct {
+    enum v4l2_buf_type buf_type;    /**< Type of the buffer. */
+    enum v4l2_memory memory_type;   /**< Type of memory associated with the buffer. */
+    uint32_t index;                 /**< Holds the buffer index. */
+    uint32_t n_planes;              /**< Holds the number of planes in the buffer. */
+    NvBufferPlane planes[NV_MAX_PLANES];
+    bool mapped;
+} NvBuffer;
+
+typedef struct {
+    uint32_t width;
+    uint32_t height;
+    bool low_latency;
+    uint32_t profile;
+    uint32_t bitrate;
+    uint32_t level;
+    uint32_t tier;
+    uint32_t preset_type;
+    uint32_t lossless;
+    uint32_t twopass;
+    uint32_t iframe_interval;
+    uint32_t idr_interval;
+    uint32_t fps_n;
+    uint32_t fps_d;
+    int qmin;
+    int qmax;
+    int num_b_frames;
+    uint32_t num_ref;
+    bool sps_pps_at_idr;
+    uint32_t ratecontrol;
+} NvEncoder;
+
+/**
+ * @brief Struct defining the decoder context.
+ * The video decoder device node is `/dev/nvhost-nvdec`. The category name
+ * for the decoder is \c "NVDEC".
+ *
+ * The context stores the information for decoding.
+ * Refer to [V4L2 Video Decoder](group__V4L2Dec.html) for more information on the decoder.
+ */
+
+typedef struct {
+    uint32_t codec_width;
+    uint32_t codec_height;
+
+    NvBufferSession buf_session;
+    NvBufferPixFmtVersion pixfmt_list_ver;
+
+    uint32_t op_pixfmt;
+    uint32_t cp_pixfmt;
+    enum v4l2_memory op_mem_type;
+    enum v4l2_memory cp_mem_type;
+    enum v4l2_buf_type op_buf_type;
+    enum v4l2_buf_type cp_buf_type;
+    NvBufferPlaneFormat op_planefmts[NV_MAX_PLANES];
+    NvBufferPlaneFormat cp_planefmts[NV_MAX_PLANES];
+    uint32_t cp_num_planes;
+    uint32_t op_num_planes;
+    uint32_t cp_num_buffers;
+    uint32_t op_num_buffers;
+    NvQueues *export_pool;
+    NvBuffer **op_buffers;
+    NvBuffer **cp_buffers;
+    uint32_t num_active_op_buffers;
+    uint32_t num_queued_op_buffers;
+    uint32_t num_queued_cp_buffers;
+
+    pthread_mutex_t queue_lock;
+    pthread_cond_t queue_cond;
+    pthread_mutex_t frame_lock;
+    pthread_cond_t frame_cond;
+    pthread_t capture_thread;
+
+    bool in_error;
+    bool eos;
+    bool op_streamon;
+    bool cp_streamon;
+    bool draining_event;
+    bool low_latency;
+
+    int fd;
+    int out_dma_fd;
+    int dmabuff_fd[NV_MAX_BUFFERS];
+
+    int      plane_dma_fd[NV_MAX_BUFFERS];
+    uint32_t plane_width[MAX_NUM_PLANES];
+    uint32_t plane_height[MAX_NUM_PLANES];
+    uint32_t plane_width_aligned;
+    int64_t  frame_pts[NV_MAX_BUFFERS];
+    int64_t  frame_user_pts[NV_MAX_BUFFERS];
+
+    uint8_t *packet[NV_MAX_BUFFERS];
+    uint32_t packet_buf_size[NV_MAX_BUFFERS];
+    uint32_t packet_size[NV_MAX_BUFFERS];
+    bool packet_keyflag[NV_MAX_BUFFERS];
+
+    NvEncoder *enc;
+    AVCodecContext *avctx;
+} nvv4l2_ctx_t;
+
+/* NVV4L2 common functions */
+uint32_t nvv4l2_map_nvcodec_type(NvCodingType nv_codec_type);
+int
+nvv4l2_pool_idx_next(nvv4l2_ctx_t *ctx, NvQueues *q);
+void
+nvv4l2_pool_push(nvv4l2_ctx_t *ctx, NvQueues *q);
+int
+nvv4l2_pool_pop(nvv4l2_ctx_t *ctx, NvQueues *q);
+int
+nvv4l2_create_bufferfmt(NvBuffer *buffer, enum v4l2_buf_type buf_type,
+                     enum v4l2_memory memory_type, uint32_t n_planes,
+                     NvBufferPlaneFormat *fmt, uint32_t index);
+int
+nvv4l2_map_out(nvv4l2_ctx_t *ctx, struct v4l2_buffer *v4l2_buf,
+               enum v4l2_buf_type buf_type, enum v4l2_memory mem_type,
+               int dma_fd);
+int
+nvv4l2_unmap_out(nvv4l2_ctx_t *ctx, int index, enum v4l2_buf_type buf_type,
+                 enum v4l2_memory mem_type, int dma_fd);
+void
+nvv4l2_destroyBuffer(nvv4l2_ctx_t *ctx, NvBuffer *buffer);
+int
+nvv4l2_allocate_memory(nvv4l2_ctx_t *ctx, NvBuffer *buffer);
+int
+nvv4l2_map(nvv4l2_ctx_t *ctx, NvBuffer *buffer);
+void
+nvv4l2_unmap(nvv4l2_ctx_t *ctx, NvBuffer *buffer);
+int
+nvv4l2_query_buffer(nvv4l2_ctx_t *ctx, enum v4l2_buf_type buf_type,
+                    enum v4l2_memory memory_type, uint32_t num_planes,
+                    uint32_t index);
+int
+nvv4l2_export_buffer(nvv4l2_ctx_t *ctx, enum v4l2_buf_type buf_type,
+                     uint32_t num_planes, uint32_t index);
+int
+nvv4l2_fill_buffer_plane_format(nvv4l2_ctx_t *ctx,
+                                uint32_t *num_planes,
+                                NvBufferPlaneFormat *planefmts,
+                                uint32_t width, uint32_t height,
+                                uint32_t pixfmt);
+int
+nvv4l2_dq_event(nvv4l2_ctx_t *ctx, struct v4l2_event *event,
+                uint32_t max_wait_ms);
+int
+nvv4l2_dq_buffer(nvv4l2_ctx_t *ctx, struct v4l2_buffer *v4l2_buf,
+                 NvBuffer **buffer, enum v4l2_buf_type buf_type,
+                 enum v4l2_memory memory_type, uint32_t num_retries);
+int
+nvv4l2_q_buffer(nvv4l2_ctx_t *ctx, struct v4l2_buffer *v4l2_buf,
+                NvBuffer *buffer, enum v4l2_buf_type buf_type,
+                enum v4l2_memory memory_type, int num_planes);
+int
+nvv4l2_req_buffers_on_capture_plane(nvv4l2_ctx_t *ctx,
+                                    enum v4l2_buf_type buf_type,
+                                    enum v4l2_memory mem_type,
+                                    int num_buffers);
+int
+nvv4l2_req_buffers_on_output_plane(nvv4l2_ctx_t *ctx,
+                                   enum v4l2_buf_type buf_type,
+                                   enum v4l2_memory mem_type,
+                                   int num_buffers);
+int
+nvv4l2_set_ext_controls(int fd, uint32_t id,
+                        uint32_t class, uint32_t value);
+int
+nvv4l2_set_ext_control_qp_range(int fd, uint32_t qpmin,
+                                uint32_t qpmax);
+int
+nvv4l2_set_ext_control_constant_qp(int fd, uint32_t qpval);
+int
+nvv4l2_get_ext_control_metadata(int fd, uint32_t buffer_index,
+                    v4l2_ctrl_videoenc_outputbuf_metadata *enc_metadata);
+int
+nvv4l2_set_stream_control_framerate(int fd,  uint32_t buf_type,
+                                    uint32_t framerate_num,
+                                    uint32_t framerate_den);
+int
+nvv4l2_subscribe_event(int fd, uint32_t type, uint32_t id,
+                       uint32_t flags);
+
+NvBufferPixFmtVersion
+nvv4l2_get_pixfmt_list_version(nvv4l2_ctx_t *ctx);
+
+/* NVV4L2 debug functions */
+void
+nvv4l2_dbg_plane_supported_formats(nvv4l2_ctx_t *ctx,
+                                   uint32_t buf_type);
+
+/* NVV4L2 decoder functions */
+nvv4l2_ctx_t *nvv4l2_create_decoder(AVCodecContext *avctx,
+                                    NvCodingType nv_codec_type,
+                                    int pix_fmt);
+int
+nvv4l2_decoder_put_packet(AVCodecContext *avctx, nvv4l2_ctx_t *ctx,
+                          NvPacket *packet);
+int
+nvv4l2_decoder_get_frame(AVCodecContext *avctx, nvv4l2_ctx_t *ctx,
+                         int *buf_index, NvFrame *frame);
+int nvv4l2_decoder_close(AVCodecContext *avctx, nvv4l2_ctx_t *ctx);
+
+/* NVV4L2 encoder functions */
+nvv4l2_ctx_t *nvv4l2_create_encoder(AVCodecContext *avctx,
+                                    NvEncoder *enc,
+                                    NvCodingType codingType,
+                                    int pix_fmt);
+int
+nvv4l2_encoder_put_frame(AVCodecContext *avctx, nvv4l2_ctx_t *ctx,
+                         NvFrame *frame);
+int
+nvv4l2_encoder_get_packet(AVCodecContext *avctx,
+                          nvv4l2_ctx_t *ctx,
+                          NvPacket *packet);
+int
+nvv4l2_encoder_close(AVCodecContext *avctx, nvv4l2_ctx_t *ctx);
+
+#endif
